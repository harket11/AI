{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. 시스템 업데이트 및 언어 관련 패키지 설치\n",
        "# (실행 시 시간이 좀 걸릴 수 있어요!)\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install locales -qq\n",
        "\n",
        "# 2. 한국어 (ko_KR.UTF-8) locale 생성\n",
        "# 이 단계에서 오류가 나지 않아야 해요!\n",
        "!sudo locale-gen ko_KR.UTF-8\n",
        "\n",
        "# 3. 환경 변수 설정\n",
        "# 파이썬 코드 안에서 실행합니다.\n",
        "import os\n",
        "os.environ['LANG'] = 'ko_KR.UTF-8'\n",
        "os.environ['LC_ALL'] = 'ko_KR.UTF-8'\n",
        "os.environ['LC_CTYPE'] = 'ko_KR.UTF-8'\n",
        "os.environ['LANGUAGE'] = 'ko_KR.UTF-8'\n",
        "\n",
        "# 4. 런타임 다시 시작 (!!!! 아주 중요합니다 !!!!)\n",
        "# 이 셀을 실행한 후에는 반드시 콜랩 메뉴에서 런타임을 재시작해야 해요.\n",
        "# 메뉴: \"런타임(Runtime)\" -> \"런타임 다시 시작(Restart runtime)\" 클릭!\n",
        "# 재시작 후에는 이 위의 코드 셀들을 다시 실행할 필요 없어요.\n",
        "# 바로 다음 단계로 넘어가시면 됩니다.\n",
        "\n",
        "# 5. (선택 사항) 설정 확인 - 런타임 재시작 후 이 셀을 실행해보세요.\n",
        "# 'ko_KR.UTF-8' 관련 내용이 보이면 성공!\n",
        "# !locale"
      ],
      "metadata": {
        "id": "iwz23eBW8trJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "런타임 다시 시작"
      ],
      "metadata": {
        "id": "TFbp7QTs8vJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 나눔 폰트 설치 (Colab에서 한글 표시를 위해 가장 많이 사용돼요)\n",
        "!sudo apt-get install -y fonts-nanum > /dev/null 2>&1\n",
        "!sudo fc-cache -fv > /dev/null 2>&1\n",
        "\n",
        "# Matplotlib 등에서 한글 폰트 설정을 위한 코드 (streamlit과는 직접 관련 없을 수도 있지만,\n",
        "# 만약을 위해 환경 준비 차원에서 실행해주세요)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# 설치된 폰트 경로 확인\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # 나눔바른고딕 예시\n",
        "if os.path.exists(font_path):\n",
        "    fm.fontManager.addfont(font_path)\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
        "    print(\"한글 폰트 설정 완료: NanumBarunGothic\")\n",
        "else:\n",
        "    print(f\"Warning: 폰트 파일이 없습니다: {font_path}\")\n",
        "\n",
        "# (선택 사항) 시스템에 설치된 폰트 목록 확인\n",
        "# [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name]"
      ],
      "metadata": {
        "id": "BndvW1n98w-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경 점검 및 기본 설정\n",
        "import torch                      # 딥러닝 프레임워크 PyTorch\n",
        "import torch.nn as nn             # 신경망 모듈\n",
        "import torch.optim as optim       # 최적화 알고리즘\n",
        "from torchvision import datasets, transforms  # 데이터셋/전처리\n",
        "from torch.utils.data import DataLoader       # 데이터 로더\n",
        "import matplotlib.pyplot as plt    # 시각화\n",
        "import numpy as np                 # 수치 연산\n",
        "import random                      # 시드 고정\n",
        "\n",
        "print('PyTorch  :', torch.__version__)  # 파이토치 버전 출력\n",
        "import torchvision\n",
        "print('TorchVision :', torchvision.__version__)  # 토치비전 버전 출력\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부\n",
        "print('Device:', device)                                  # 디바이스 출력"
      ],
      "metadata": {
        "id": "5zEwV1W37528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재현성 확보 및 하이퍼파라미터\n",
        "SEED = 0                           # 임의성 제어용 시드\n",
        "random.seed(SEED)                  # 파이썬 시드 고정\n",
        "np.random.seed(SEED)               # 넘파이 시드 고정\n",
        "torch.manual_seed(SEED)            # 파이토치 CPU 시드 고정\n",
        "if torch.cuda.is_available():      # GPU 사용 시\n",
        "    torch.cuda.manual_seed_all(SEED)  # 모든 GPU 시드 고정\n",
        "\n",
        "BATCH_SIZE = 128                   # 배치 크기\n",
        "EPOCHS = 3                         # 학습 에폭(데모용)\n",
        "LR = 2e-3                          # 학습률\n",
        "NUM_WORKERS = 2                    # DataLoader 병렬 워커 수"
      ],
      "metadata": {
        "id": "K0R2HJVV79bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVHN 데이터셋 로드/전처리\n",
        "# SVHN 평균/표준편차 (경험치)\n",
        "mean = (0.4377, 0.4438, 0.4728)    # 채널별 평균\n",
        "std  = (0.1980, 0.2010, 0.1970)    # 채널별 표준편차\n",
        "\n",
        "# 학습/테스트 공통 정규화\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),         # 텐서 변환\n",
        "    transforms.Normalize(mean, std) # 정규화\n",
        "])\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "# SVHN 다운로드/구성 (CIFAR-10 금지 조건을 충족하기 위해 SVHN 사용)\n",
        "train_ds = datasets.SVHN(root='/content/data_svhn', split='train', download=True, transform=train_tf)\n",
        "test_ds  = datasets.SVHN(root='/content/data_svhn', split='test',  download=True, transform=test_tf)\n",
        "\n",
        "# 데이터로더 구성\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256,        shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print('학습 샘플 수:', len(train_ds))  # 학습 데이터 개수\n",
        "print('테스트 샘플 수:', len(test_ds)) # 테스트 데이터 개수"
      ],
      "metadata": {
        "id": "-iOl36DC807A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 미리보기\n",
        "# 배치 하나를 얻어 이미지/레이블 확인\n",
        "images, labels = next(iter(train_loader))      # 첫 미니배치\n",
        "print('배치 이미지 shape:', images.shape)      # (B, C, H, W)\n",
        "print('배치 레이블 shape:', labels.shape)      # (B,)\n",
        "\n",
        "# 16개 샘플 시각화\n",
        "grid = 16                                      # 표시 개수\n",
        "plt.figure(figsize=(8,8))                      # 도화지 크기\n",
        "for i in range(grid):                          # 16개 루프\n",
        "    plt.subplot(4,4,i+1)                       # 4x4 서브플롯\n",
        "    img = images[i].permute(1,2,0).cpu().numpy()     # (H,W,C)로 변환\n",
        "    img = (img * np.array(std) + np.array(mean))     # 정규화 역변환\n",
        "    img = np.clip(img, 0, 1)                         # 0~1로 클리핑\n",
        "    plt.imshow(img)                                   # 이미지 표시\n",
        "    plt.title(int(labels[i]))                         # 레이블 표시\n",
        "    plt.axis('off')                                   # 축 숨김\n",
        "plt.tight_layout()                                    # 레이아웃 정리\n",
        "plt.show()                                            # 출력"
      ],
      "metadata": {
        "id": "KBwyHrOl81tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 #1: nn.Sequential로 CNN 설계\n",
        "# Feature Extractor (특징추출) 파트\n",
        "seq_feature_extractor = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 3->32 채널, 3x3 필터\n",
        "    nn.ReLU(),                                   # 비선형 활성화\n",
        "    nn.MaxPool2d(2),                              # 공간 크기 절반\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, padding=1), # 32->64 채널\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=3, padding=1),# 64->128 채널\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)                               # 32->16->8->4\n",
        ")\n",
        "# Classifier (분류기) 파트\n",
        "seq_classifier = nn.Sequential(\n",
        "    nn.Flatten(),                                 # (B,128,4,4)->(B,2048)\n",
        "    nn.Linear(128*4*4, 256),                      # 완전연결층\n",
        "    nn.ReLU(),                                    # 활성화\n",
        "    nn.Linear(256, 10)                            # SVHN 10 클래스\n",
        ")\n",
        "# 전체 모델 결합\n",
        "seq_model = nn.Sequential(seq_feature_extractor, seq_classifier).to(device)\n",
        "\n",
        "# 더미 입력으로 shape 확인\n",
        "dummy = torch.randn(1, 3, 32, 32).to(device)     # 가짜 이미지 (배치, 채널수, 높이, 너비)\n",
        "out = seq_model(dummy)                            # 순전파\n",
        "print('Sequential 출력 shape:', out.shape)        # (1,10) 1이 가리키는 것은? Batch\n",
        "\n",
        "# 파라미터 수 계산 함수\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "print('학습 가능한 파라미터 수:', count_params(seq_model))  # 파라미터 총계"
      ],
      "metadata": {
        "id": "bajG49ql81wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 #2: 클래스형 CNN (forward 명확/확장 용이)\n",
        "class ClassCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 특징추출부\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64,128,3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        # 분류기\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*4*4, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "        # He(kaiming) 초기화로 안정적 학습 시작\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)     # 특징 추출\n",
        "        x = self.classifier(x)   # 분류\n",
        "        return x\n",
        "\n",
        "cls_model = ClassCNN().to(device)                 # 모델 인스턴스 생성\n",
        "print('ClassCNN 파라미터 수:', count_params(cls_model))  # 파라미터 수 출력\n",
        "\n",
        "# 레이어별 출력 shape 추적(후크)\n",
        "shapes = []                                       # shape 저장 리스트\n",
        "def hook(m, i, o):\n",
        "    if isinstance(o, torch.Tensor):\n",
        "        shapes.append(tuple(o.shape))             # 출력 shape 기록\n",
        "\n",
        "hooks = []\n",
        "for layer in cls_model.features:                  # 특징추출부 레이어 순회\n",
        "    if isinstance(layer, (nn.Conv2d, nn.MaxPool2d)):\n",
        "        hooks.append(layer.register_forward_hook(hook))  # 후크 등록\n",
        "_ = cls_model(dummy)                              # 더미 순전파로 후크 실행\n",
        "for h in hooks: h.remove()                        # 후크 해제\n",
        "print('features 출력 shapes:', shapes)            # 레이어별 shape 출력\n"
      ],
      "metadata": {
        "id": "6pcUWlyh9FB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습/평가 유틸 함수\n",
        "def accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)           # 예측 클래스\n",
        "    return (preds == targets).float().mean().item()  # 정확도\n",
        "\n",
        "# 1 에폭 학습\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()                           # 학습 모드\n",
        "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
        "    for x, y in loader:                     # 미니배치 반복\n",
        "        x, y = x.to(device), y.to(device)   # 디바이스 이동\n",
        "\n",
        "        optimizer.zero_grad()               # 기울기 초기화\n",
        "        out = model(x)                      # 순전파\n",
        "        loss = criterion(out, y)            # 손실 계산\n",
        "        loss.backward()                     # 역전파\n",
        "        optimizer.step()                    # 파라미터 갱신\n",
        "\n",
        "        tot_loss += loss.item() * y.size(0) # 손실 누적\n",
        "        tot_acc  += (out.argmax(1) == y).float().sum().item() # 정답수 누적\n",
        "        tot_cnt  += y.size(0)               # 샘플 수 누적\n",
        "    return tot_loss/tot_cnt, tot_acc/tot_cnt  # 평균 손실/정확도\n",
        "\n",
        "# 평가\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()                            # 평가 모드\n",
        "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
        "    with torch.no_grad():                   # 기울기 미계산\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            tot_loss += loss.item() * y.size(0)\n",
        "            tot_acc  += (out.argmax(1) == y).float().sum().item()\n",
        "            tot_cnt  += y.size(0)\n",
        "    return tot_loss/tot_cnt, tot_acc/tot_cnt"
      ],
      "metadata": {
        "id": "j0ANmskn9FEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential 모델 학습/그래프\n",
        "criterion = nn.CrossEntropyLoss()                # 다중분류 손실\n",
        "optimizer = optim.AdamW(seq_model.parameters(), lr=LR)  # AdamW 최적화기\n",
        "\n",
        "tr_hist, te_hist = [], []                        # 기록용 리스트\n",
        "for ep in range(1, EPOCHS+1):                    # 에폭 반복\n",
        "    tr_loss, tr_acc = train_one_epoch(seq_model, train_loader, optimizer, criterion)\n",
        "    te_loss, te_acc = evaluate(seq_model, test_loader, criterion)\n",
        "    tr_hist.append((tr_loss, tr_acc))\n",
        "    te_hist.append((te_loss, te_acc))\n",
        "    print(f\"[Sequential] Epoch {ep}/{EPOCHS} | train {tr_acc:.3f}/{tr_loss:.3f} | test {te_acc:.3f}/{te_loss:.3f}\")\n",
        "\n",
        "# 정확도 곡선\n",
        "plt.figure(); plt.plot([a for _,a in tr_hist], label='train acc'); plt.plot([a for _,a in te_hist], label='test acc')\n",
        "plt.legend(); plt.title('정확도 추세(Sequential)'); plt.show()\n",
        "\n",
        "# 손실 곡선\n",
        "plt.figure(); plt.plot([l for l,_ in tr_hist], label='train loss'); plt.plot([l for l,_ in te_hist], label='test loss')\n",
        "plt.legend(); plt.title('손실 추세(Sequential)'); plt.show()"
      ],
      "metadata": {
        "id": "TPtLCw7k9XzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsoQSM8y4Vg9"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 간단 실험\n",
        "class SmallExp(nn.Module):\n",
        "    def __init__(self, ch1=16, ch2=32, k=3, stride=1):\n",
        "        super().__init__()\n",
        "        pad = k//2                                 # 출력 사이즈 보존용 패딩\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3,  ch1, k, stride=stride, padding=pad), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(ch1, ch2, k, stride=1,      padding=pad), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(ch2*8*8, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "    def forward(self,x): return self.net(x)        # 순전파 정의\n",
        "\n",
        "def quick_eval(ch1, ch2, k, stride):\n",
        "    m = SmallExp(ch1, ch2, k, stride).to(device)   # 모델 생성/이동\n",
        "    opt = optim.AdamW(m.parameters(), lr=LR)       # 최적화기\n",
        "    crit = nn.CrossEntropyLoss()                   # 손실함수\n",
        "    for _ in range(2):                             # 데모용 2에폭만\n",
        "        train_one_epoch(m, train_loader, opt, crit)\n",
        "    _, acc = evaluate(m, test_loader, crit)        # 테스트 정확도\n",
        "    return acc\n",
        "\n",
        "settings = [                                      # 실험 설정들\n",
        "    {'ch1':16,'ch2':32,'k':3,'stride':1},\n",
        "    {'ch1':32,'ch2':64,'k':3,'stride':1},\n",
        "    {'ch1':32,'ch2':64,'k':5,'stride':1}\n",
        "]\n",
        "\n",
        "results = []\n",
        "for s in settings:                                 # 설정 반복\n",
        "    acc = quick_eval(**s)                          # 설정 실행\n",
        "    results.append((s, acc))                       # 결과 저장\n",
        "    print('설정:', s, '| 테스트 정확도:', round(acc,4))\n",
        "\n",
        "# 막대 그래프 표시\n",
        "labels = [f\"{r[0]['ch1']}/{r[0]['ch2']},k{r[0]['k']},s{r[0]['stride']}\" for r in results]\n",
        "vals   = [r[1] for r in results]\n",
        "plt.figure(figsize=(8,3)); plt.bar(range(len(vals)), vals)\n",
        "plt.xticks(range(len(vals)), labels, rotation=30, ha='right')\n",
        "plt.title('하이퍼파라미터 변화에 따른 정확도(간이)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyH6hkeY_Qsx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}