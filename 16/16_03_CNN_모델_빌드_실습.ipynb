{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FeoENr-7Vj"
      },
      "source": [
        "# 세션 16 — CNN 모델 빌드 실습 (SVHN)\n",
        "\n",
        "## 학습 목표\n",
        "- CNN 구조 설계부터 실험까지 end-to-end 경험\n",
        "- Feature Extractor와 Classifier 분리 설계\n",
        "- Conv/Pool/ReLU 조합과 파라미터 계산\n",
        "- Hook을 활용한 레이어 출력 shape 추적\n",
        "- 하이퍼파라미터 튜닝 경험\n",
        "\n",
        "## 데이터셋: SVHN (Street View House Numbers)\n",
        "- Google Street View에서 수집한 집 번호 이미지\n",
        "- 10개 클래스 (숫자 0-9)\n",
        "- 32×32 컬러 이미지\n",
        "- 학습: 73,257개, 테스트: 26,032개\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 시스템 업데이트 및 언어 관련 패키지 설치\n",
        "# (실행 시 시간이 좀 걸릴 수 있어요!)\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install locales -qq\n",
        "\n",
        "# 2. 한국어 (ko_KR.UTF-8) locale 생성\n",
        "# 이 단계에서 오류가 나지 않아야 해요!\n",
        "!sudo locale-gen ko_KR.UTF-8\n",
        "\n",
        "# 3. 환경 변수 설정\n",
        "# 파이썬 코드 안에서 실행합니다.\n",
        "import os\n",
        "os.environ['LANG'] = 'ko_KR.UTF-8'\n",
        "os.environ['LC_ALL'] = 'ko_KR.UTF-8'\n",
        "os.environ['LC_CTYPE'] = 'ko_KR.UTF-8'\n",
        "os.environ['LANGUAGE'] = 'ko_KR.UTF-8'\n",
        "\n",
        "# 4. 런타임 다시 시작 (!!!! 아주 중요합니다 !!!!)\n",
        "# 이 셀을 실행한 후에는 반드시 콜랩 메뉴에서 런타임을 재시작해야 해요.\n",
        "# 메뉴: \"런타임(Runtime)\" -> \"런타임 다시 시작(Restart runtime)\" 클릭!\n",
        "# 재시작 후에는 이 위의 코드 셀들을 다시 실행할 필요 없어요.\n",
        "# 바로 다음 단계로 넘어가시면 됩니다.\n",
        "\n",
        "# 5. (선택 사항) 설정 확인 - 런타임 재시작 후 이 셀을 실행해보세요.\n",
        "# 'ko_KR.UTF-8' 관련 내용이 보이면 성공!\n",
        "# !locale"
      ],
      "metadata": {
        "id": "v10bhODhI-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "런타임 다시 시작"
      ],
      "metadata": {
        "id": "J7RyIhbcJANk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 나눔 폰트 설치 (Colab에서 한글 표시를 위해 가장 많이 사용돼요)\n",
        "!sudo apt-get install -y fonts-nanum > /dev/null 2>&1\n",
        "!sudo fc-cache -fv > /dev/null 2>&1\n",
        "\n",
        "# Matplotlib 등에서 한글 폰트 설정을 위한 코드 (streamlit과는 직접 관련 없을 수도 있지만,\n",
        "# 만약을 위해 환경 준비 차원에서 실행해주세요)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# 설치된 폰트 경로 확인\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # 나눔바른고딕 예시\n",
        "if os.path.exists(font_path):\n",
        "    fm.fontManager.addfont(font_path)\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
        "    print(\"한글 폰트 설정 완료: NanumBarunGothic\")\n",
        "else:\n",
        "    print(f\"Warning: 폰트 파일이 없습니다: {font_path}\")\n",
        "\n",
        "# (선택 사항) 시스템에 설치된 폰트 목록 확인\n",
        "# [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name]"
      ],
      "metadata": {
        "id": "xKFw09gOJFl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--0kudMh-7Vt"
      },
      "source": [
        "## Section 1: 환경 설정 및 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94jeBypu-7Vw"
      },
      "outputs": [],
      "source": [
        "# PyTorch 및 관련 라이브러리 임포트\n",
        "import torch  # PyTorch 메인 라이브러리\n",
        "import torch.nn as nn  # 신경망 모듈 (레이어, 손실함수 등)\n",
        "import torch.optim as optim  # 최적화 알고리즘 (Adam, SGD 등)\n",
        "import torch.nn.functional as F  # 활성화 함수, Softmax 등\n",
        "from torch.utils.data import DataLoader  # 데이터 로더 (배치 처리)\n",
        "\n",
        "# torchvision: 컴퓨터 비전 관련 유틸리티\n",
        "import torchvision  # 비전 관련 전체 모듈\n",
        "import torchvision.transforms as transforms  # 이미지 전처리 및 증강\n",
        "from torchvision import datasets  # SVHN, CIFAR 등 표준 데이터셋\n",
        "\n",
        "# 데이터 처리 및 시각화\n",
        "import numpy as np  # 수치 연산 라이브러리\n",
        "import matplotlib.pyplot as plt  # 그래프 및 이미지 시각화\n",
        "from collections import OrderedDict  # 순서가 보장되는 딕셔너리\n",
        "\n",
        "# 진행 상황 표시 (선택사항)\n",
        "from tqdm import tqdm  # 진행률 표시줄 (progress bar)\n",
        "\n",
        "# GPU 사용 가능 여부 확인 및 디바이스 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# torch.cuda.is_available(): CUDA(GPU)가 사용 가능한지 확인\n",
        "# GPU 있으면 'cuda', 없으면 'cpu' 사용\n",
        "print(f'사용 디바이스: {device}')\n",
        "\n",
        "# 재현성을 위한 시드 고정\n",
        "torch.manual_seed(42)  # PyTorch 난수 시드 고정\n",
        "np.random.seed(42)  # NumPy 난수 시드 고정\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)  # CUDA 난수 시드 고정\n",
        "    torch.backends.cudnn.deterministic = True  # 결정적 알고리즘 사용\n",
        "    torch.backends.cudnn.benchmark = False  # 벤치마크 비활성화 (재현성 우선)\n",
        "\n",
        "print('환경 설정 완료!')\n",
        "print(f'PyTorch 버전: {torch.__version__}')\n",
        "print(f'Torchvision 버전: {torchvision.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUTRpd_Z-7V0"
      },
      "source": [
        "## Section 2: 데이터셋 로드 및 전처리\n",
        "\n",
        "SVHN 데이터셋을 다운로드하고 전처리 파이프라인을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSJ4bXsp-7V1"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 파이프라인 정의\n",
        "\n",
        "# 학습용 전처리 (데이터 증강 포함)\n",
        "\n",
        "# 코드 작성\n",
        "transform_train = transforms.Compose([\n",
        "    # RandomCrop: 이미지를 32x32 크기로 랜덤하게 크롭하되, 4픽셀 패딩 추가\n",
        "    # 패딩으로 36x36이 되고, 여기서 32x32를 랜덤 위치에서 자름 (위치 변화)\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "\n",
        "    # RandomHorizontalFlip: 50% 확률로 이미지를 좌우 반전\n",
        "    # 숫자 이미지에서 좌우 대칭은 의미가 있을 수 있음 (예: 6과 9는 다르지만)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "    # ColorJitter: 밝기, 대비, 채도를 랜덤하게 변경 (조명 조건 변화 시뮬레이션)\n",
        "    # brightness: 밝기를 ±20% 변경\n",
        "    # contrast: 대비를 ±20% 변경\n",
        "    # saturation: 채도를 ±20% 변경\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "\n",
        "    # ToTensor: PIL Image를 PyTorch Tensor로 변환\n",
        "    # (H, W, C) -> (C, H, W) 형태로 변경\n",
        "    # 픽셀 값을 [0, 255] -> [0.0, 1.0] 범위로 정규화\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # Normalize: 각 채널을 평균 0.5, 표준편차 0.5로 정규화\n",
        "    # 실제로는 [0, 1] -> [-1, 1] 범위로 변환하는 효과\n",
        "    # 공식: normalized = (pixel - mean) / std\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 테스트용 전처리 (증강 없음)\n",
        "transform_test = transforms.Compose([\n",
        "    # ToTensor: 이미지를 텐서로 변환 (증강 없이)\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # Normalize: 학습 데이터와 동일한 정규화 적용 (중요!)\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "print('데이터 전처리 파이프라인 정의 완료!')\n",
        "print('\\n학습용 전처리 단계:')\n",
        "print('  1. RandomCrop(32, padding=4) - 위치 변화')\n",
        "print('  2. RandomHorizontalFlip - 좌우 반전')\n",
        "print('  3. ColorJitter - 색상 변화')\n",
        "print('  4. ToTensor - 텐서 변환')\n",
        "print('  5. Normalize - 정규화')\n",
        "print('\\n테스트용 전처리 단계:')\n",
        "print('  1. ToTensor - 텐서 변환')\n",
        "print('  2. Normalize - 정규화 (학습과 동일)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAR_7mz1-7V3"
      },
      "outputs": [],
      "source": [
        "# SVHN 데이터셋 다운로드 및 로드\n",
        "\n",
        "print('SVHN 데이터셋 다운로드 중...')\n",
        "print('(처음 실행 시 다운로드에 시간이 걸릴 수 있습니다)\\n')\n",
        "\n",
        "# 학습 데이터셋 로드\n",
        "train_dataset = datasets.SVHN(\n",
        "    root='./data',  # 데이터를 저장할 디렉토리 경로\n",
        "    split='train',  # 'train' 또는 'test' 선택\n",
        "    download=True,  # 데이터가 없으면 자동 다운로드\n",
        "    transform=transform_train  # 학습용 전처리 적용\n",
        ")\n",
        "\n",
        "# 테스트 데이터셋 로드\n",
        "test_dataset = datasets.SVHN(\n",
        "    root='./data',  # 동일한 디렉토리 사용\n",
        "    split='test',  # 테스트 데이터 사용\n",
        "    download=True,  # 없으면 다운로드\n",
        "    transform=transform_test  # 테스트용 전처리 적용\n",
        ")\n",
        "\n",
        "# 데이터셋 정보 출력\n",
        "print('='*60)\n",
        "print('데이터셋 정보')\n",
        "print('='*60)\n",
        "print(f'학습 데이터: {len(train_dataset):,}개')\n",
        "print(f'테스트 데이터: {len(test_dataset):,}개')\n",
        "print(f'클래스 수: 10개 (숫자 0-9)')\n",
        "print(f'이미지 크기: 32×32×3 (컬러)')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V03xNDdZ-7V4"
      },
      "outputs": [],
      "source": [
        "# 데이터 로더 생성\n",
        "# DataLoader: 배치 단위로 데이터를 로드하고, 셔플링, 병렬 처리 등을 수행\n",
        "\n",
        "# 배치 크기 설정\n",
        "batch_size = 128  # 한 번에 처리할 이미지 개수\n",
        "# 배치 크기가 클수록: 학습 속도 빠름, GPU 메모리 많이 사용\n",
        "# 배치 크기가 작을수록: 학습 불안정, GPU 메모리 적게 사용\n",
        "\n",
        "# 학습용 데이터 로더\n",
        "# 코드 작성\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        "\n",
        ")\n",
        "\n",
        "# 테스트용 데이터 로더\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,  # 테스트 데이터셋\n",
        "    batch_size=batch_size,  # 배치 크기 (평가 시에는 더 크게 해도 됨)\n",
        "    shuffle=False,  # 테스트 시에는 순서를 섞지 않음\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# 데이터 로더 정보 출력\n",
        "print('\\n데이터 로더 생성 완료!')\n",
        "print(f'\\n학습 데이터 로더:')\n",
        "print(f'  - 배치 크기: {batch_size}')\n",
        "print(f'  - 배치 수: {len(train_loader)}개')\n",
        "print(f'  - 총 샘플: {len(train_dataset):,}개')\n",
        "print(f'\\n테스트 데이터 로더:')\n",
        "print(f'  - 배치 크기: {batch_size}')\n",
        "print(f'  - 배치 수: {len(test_loader)}개')\n",
        "print(f'  - 총 샘플: {len(test_dataset):,}개')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApOkRQxW-7V6"
      },
      "outputs": [],
      "source": [
        "# 샘플 이미지 시각화\n",
        "# 데이터셋이 제대로 로드되었는지 확인\n",
        "\n",
        "# 클래스 이름 (SVHN은 0-9 숫자)\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "# 학습 데이터에서 16개 샘플 가져오기\n",
        "# 코드 작성\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# 데이터 로더를 이터레이터로 변환\n",
        "# 첫 번째 배치 가져오기\n",
        "\n",
        "# 이미지를 [-1, 1] 범위에서 [0, 1]로 변환 (시각화용)\n",
        "def denormalize(tensor):\n",
        "    # 정규화 역변환: pixel = (normalized * std) + mean\n",
        "    # 우리는 mean=0.5, std=0.5로 정규화했으므로\n",
        "    # 코드 작성\n",
        "    return tensor * 0.5 + 0.5\n",
        "\n",
        "# 16개 이미지를 4x4 그리드로 시각화\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)  # 4x4 그리드의 i+1번째 위치\n",
        "\n",
        "    # 이미지를 (C, H, W) -> (H, W, C) 형태로 변환\n",
        "    img = denormalize(images[i]).cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "    # 이미지 표시\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Label: {class_names[labels[i]]}')  # 레이블 표시\n",
        "    plt.axis('off')  # 축 숨기기\n",
        "\n",
        "plt.tight_layout()  # 레이아웃 자동 조정\n",
        "plt.suptitle('SVHN 학습 데이터 샘플', y=1.02, fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "print('\\n샘플 이미지 시각화 완료!')\n",
        "print('SVHN 데이터는 실제 Street View에서 수집된 집 번호 이미지입니다.')\n",
        "print('다양한 조명, 각도, 배경을 가지고 있어 실전적인 학습이 가능합니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovLudxn8-7V7"
      },
      "source": [
        "## Section 3: CNN 모델 정의\n",
        "\n",
        "Feature Extractor와 Classifier를 분리하여 설계합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c327FoTt-7V9"
      },
      "outputs": [],
      "source": [
        "# CNN 모델 클래스 정의\n",
        "# Feature Extractor와 Classifier를 명확히 분리\n",
        "\n",
        "class SVHN_CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    SVHN 숫자 분류를 위한 CNN 모델\n",
        "\n",
        "    구조:\n",
        "        Feature Extractor:\n",
        "            - Conv Block 1: Conv(32) + ReLU + MaxPool\n",
        "            - Conv Block 2: Conv(64) + ReLU + MaxPool\n",
        "            - Conv Block 3: Conv(128) + ReLU + MaxPool\n",
        "\n",
        "        Classifier:\n",
        "            - Flatten\n",
        "            - FC1: 2048 -> 512\n",
        "            - FC2: 512 -> 10\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        모델 초기화\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): 출력 클래스 수 (기본값: 10)\n",
        "        \"\"\"\n",
        "        super(SVHN_CNN, self).__init__()  # nn.Module 초기화\n",
        "\n",
        "        # ===== Feature Extractor =====\n",
        "        # 입력 이미지에서 유용한 특징을 추출하는 부분\n",
        "\n",
        "        # Conv Block 1: 입력 채널 3 (RGB) -> 출력 채널 32\n",
        "        self.conv1 = nn.Conv2d(\n",
        "          # 코드 작성\n",
        "          in_channels=3, # RGB\n",
        "          out_channels=32, # 출력 채널 수 (필터 개수)\n",
        "          kernel_size=3, # 필터 크기 3*3\n",
        "          padding=1 # 출력 크기 유지: 32*32\n",
        "        )\n",
        "        # 파라미터 수: (3*3*3 + 1) * 32 = 28 * 32 = 896개\n",
        "        # 출력 크기: [batch, 32, 32, 32]\n",
        "\n",
        "        # MaxPool1: 공간 해상도 절반으로 축소\n",
        "        self.pool1 = nn.MaxPool2d(\n",
        "          # 코드 작성\n",
        "          kernel_size=2, # 2*2 영역에서 최대값 선택\n",
        "          stride=2       # 2칸씩 이동\n",
        "\n",
        "        )\n",
        "        # 출력 크기: [batch, 32, 16, 16]\n",
        "\n",
        "        # Conv Block 2: 32 채널 -> 64 채널\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=32,     # 이전 레이어 출력 채널\n",
        "            out_channels=64,    # 출력 채널 수 (더 많은 필터)\n",
        "            kernel_size=3,\n",
        "            padding=1\n",
        "        )\n",
        "        # 파라미터 수: (3*3*32 + 1) * 64 = 289 * 64 = 18,496개\n",
        "        # 출력 크기: [batch, 64, 16, 16]\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 출력 크기: [batch, 64, 8, 8]\n",
        "\n",
        "        # Conv Block 3: 64 채널 -> 128 채널\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,   # 가장 높은 수준의 특징 추출\n",
        "            kernel_size=3,\n",
        "            padding=1\n",
        "        )\n",
        "        # 파라미터 수: (3*3*64 + 1) * 128 = 577 * 128 = 73,856개\n",
        "        # 출력 크기: [batch, 128, 8, 8]\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 출력 크기: [batch, 128, 4, 4]\n",
        "        # Flatten 후: [batch, 128*4*4] = [batch, 2048]\n",
        "\n",
        "        # ===== Classifier =====\n",
        "        # 추출된 특징을 바탕으로 최종 분류\n",
        "\n",
        "        # Fully Connected Layer 1: 2048 -> 512\n",
        "        self.fc1 = nn.Linear(\n",
        "            # 코드 작성\n",
        "            in_features=128 * 4 * 4,\n",
        "            out_features=512\n",
        "\n",
        "        )\n",
        "        # 파라미터 수: (2048 + 1) * 512 = 1,049,088개\n",
        "\n",
        "        # Dropout: 과적합 방지 (학습 시 50% 뉴런 랜덤 비활성화)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        # Fully Connected Layer 2: 512 -> 10 (출력층)\n",
        "        self.fc2 = nn.Linear(\n",
        "            in_features=512,\n",
        "            out_features=num_classes   # 클래스 수 (0-9 숫자)\n",
        "        )\n",
        "        # 파라미터 수: (512 + 1) * 10 = 5,130개\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        순전파 함수\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): 입력 이미지 [batch, 3, 32, 32]\n",
        "\n",
        "        Returns:\n",
        "            Tensor: 클래스별 로짓 [batch, 10]\n",
        "        \"\"\"\n",
        "        # ===== Feature Extractor =====\n",
        "\n",
        "        # Conv Block 1\n",
        "        x = self.conv1(x)           # [batch, 3, 32, 32] -> [batch, 32, 32, 32]\n",
        "        x = F.relu(x)               # ReLU 활성화: 음수는 0, 양수는 그대로\n",
        "        x = self.pool1(x)           # [batch, 32, 32, 32] -> [batch, 32, 16, 16]\n",
        "\n",
        "        # Conv Block 2\n",
        "        x = self.conv2(x)           # [batch, 32, 16, 16] -> [batch, 64, 16, 16]\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)           # [batch, 64, 16, 16] -> [batch, 64, 8, 8]\n",
        "\n",
        "        # Conv Block 3\n",
        "        x = self.conv3(x)           # [batch, 64, 8, 8] -> [batch, 128, 8, 8]\n",
        "        x = F.relu(x)\n",
        "        x = self.pool3(x)           # [batch, 128, 8, 8] -> [batch, 128, 4, 4]\n",
        "\n",
        "        # ===== Classifier =====\n",
        "\n",
        "        # Flatten: 다차원 텐서를 1차원으로 펼침\n",
        "        x = x.view(x.size(0), -1)   # [batch, 128, 4, 4] -> [batch, 2048]\n",
        "        # x.size(0): 배치 크기\n",
        "        # -1: 나머지 차원을 자동으로 계산 (128*4*4 = 2048)\n",
        "\n",
        "        # Fully Connected Layer 1\n",
        "        x = self.fc1(x)             # [batch, 2048] -> [batch, 512]\n",
        "        x = F.relu(x)               # ReLU 활성화\n",
        "        x = self.dropout(x)         # Dropout (학습 시에만 적용)\n",
        "\n",
        "        # Fully Connected Layer 2 (출력층)\n",
        "        x = self.fc2(x)             # [batch, 512] -> [batch, 10]\n",
        "        # Softmax는 CrossEntropyLoss에 포함되어 있으므로 여기서는 생략\n",
        "\n",
        "        return x  # 로짓(logit) 반환\n",
        "\n",
        "print('CNN 모델 클래스 정의 완료!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5gkCFk9-7V-"
      },
      "outputs": [],
      "source": [
        "# 모델 인스턴스 생성 및 디바이스로 이동\n",
        "\n",
        "model = SVHN_CNN(num_classes=10)  # 10개 클래스 (0-9)\n",
        "model = model.to(device)  # 모델을 GPU 또는 CPU로 이동\n",
        "\n",
        "print('모델 생성 완료!')\n",
        "print(f'모델이 {device}에 로드되었습니다.\\n')\n",
        "\n",
        "# 모델 구조 출력\n",
        "print('='*60)\n",
        "print('모델 구조')\n",
        "print('='*60)\n",
        "print(model)\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrYsPz6x-7V_"
      },
      "source": [
        "## Section 4: 파라미터 계산 및 모델 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04Ezer72-7WA"
      },
      "outputs": [],
      "source": [
        "# 모델의 총 파라미터 수 계산 함수\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    모델의 학습 가능한 파라미터 수를 계산\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): PyTorch 모델\n",
        "\n",
        "    Returns:\n",
        "        int: 총 파라미터 수\n",
        "    \"\"\"\n",
        "    # p.numel(): 파라미터 텐서의 원소 개수 (number of elements)\n",
        "    # p.requires_grad: 그래디언트 계산이 필요한지 여부 (학습 가능 여부)\n",
        "    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total\n",
        "\n",
        "# 레이어별 파라미터 수 계산 및 출력\n",
        "def print_parameter_details(model):\n",
        "    \"\"\"\n",
        "    레이어별 파라미터 수와 출력 크기를 상세히 출력\n",
        "    \"\"\"\n",
        "    print('\\n레이어별 파라미터 수:')\n",
        "    print('='*70)\n",
        "    print(f'{\"레이어\":<20} {\"파라미터 수\":>15} {\"출력 크기\":>25}')\n",
        "    print('-'*70)\n",
        "\n",
        "    # Conv1 파라미터 계산\n",
        "    # (kernel_size * kernel_size * in_channels + 1) * out_channels\n",
        "    conv1_params = (3 * 3 * 3 + 1) * 32\n",
        "    print(f'{\"Conv1\":<20} {conv1_params:>15,} {\"[B, 32, 32, 32]\":>25}')\n",
        "    print(f'{\"Pool1 (MaxPool)\":<20} {0:>15,} {\"[B, 32, 16, 16]\":>25}')\n",
        "\n",
        "    # Conv2 파라미터 계산\n",
        "    conv2_params = (3 * 3 * 32 + 1) * 64\n",
        "    print(f'{\"Conv2\":<20} {conv2_params:>15,} {\"[B, 64, 16, 16]\":>25}')\n",
        "    print(f'{\"Pool2 (MaxPool)\":<20} {0:>15,} {\"[B, 64, 8, 8]\":>25}')\n",
        "\n",
        "    # Conv3 파라미터 계산\n",
        "    conv3_params = (3 * 3 * 64 + 1) * 128\n",
        "    print(f'{\"Conv3\":<20} {conv3_params:>15,} {\"[B, 128, 8, 8]\":>25}')\n",
        "    print(f'{\"Pool3 (MaxPool)\":<20} {0:>15,} {\"[B, 128, 4, 4]\":>25}')\n",
        "\n",
        "    print(f'{\"Flatten\":<20} {0:>15,} {\"[B, 2048]\":>25}')\n",
        "\n",
        "    # FC1 파라미터 계산\n",
        "    # (in_features + 1) * out_features\n",
        "    fc1_params = (2048 + 1) * 512\n",
        "    print(f'{\"FC1\":<20} {fc1_params:>15,} {\"[B, 512]\":>25}')\n",
        "    print(f'{\"Dropout\":<20} {0:>15,} {\"[B, 512]\":>25}')\n",
        "\n",
        "    # FC2 파라미터 계산\n",
        "    fc2_params = (512 + 1) * 10\n",
        "    print(f'{\"FC2\":<20} {fc2_params:>15,} {\"[B, 10]\":>25}')\n",
        "\n",
        "    print('='*70)\n",
        "\n",
        "    # 총 파라미터 수\n",
        "    total = conv1_params + conv2_params + conv3_params + fc1_params + fc2_params\n",
        "    print(f'{\"총 파라미터 수\":<20} {total:>15,}')\n",
        "    print('='*70)\n",
        "\n",
        "    return total\n",
        "\n",
        "# 파라미터 수 계산 및 출력\n",
        "total_params = count_parameters(model)\n",
        "print(f'\\n모델 총 파라미터 수: {total_params:,}개')\n",
        "\n",
        "# 레이어별 상세 정보 출력\n",
        "calculated_total = print_parameter_details(model)\n",
        "\n",
        "# 계산 검증\n",
        "print(f'\\n검증: 계산된 총 파라미터 수 = {calculated_total:,}개')\n",
        "print(f'      실제 모델 파라미터 수 = {total_params:,}개')\n",
        "print(f'      일치 여부: {\"✓\" if calculated_total == total_params else \"✗\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtcb5JAE-7WB"
      },
      "source": [
        "## Section 5: Hook을 사용한 레이어 출력 Shape 추적\n",
        "\n",
        "Forward Hook을 사용하여 각 레이어의 출력 크기를 실시간으로 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17gIMsKe-7WB"
      },
      "outputs": [],
      "source": [
        "# Hook 함수 정의\n",
        "# Hook: 모델의 중간 레이어 출력을 가로채는 메커니즘\n",
        "\n",
        "# 레이어별 출력을 저장할 딕셔너리\n",
        "layer_outputs = OrderedDict()\n",
        "\n",
        "def register_hooks(model):\n",
        "    \"\"\"\n",
        "    모델의 모든 레이어에 forward hook을 등록\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch 모델\n",
        "\n",
        "    Returns:\n",
        "        list: hook handle 리스트 (나중에 제거용)\n",
        "    \"\"\"\n",
        "    handles = []  # hook handle을 저장할 리스트\n",
        "\n",
        "    def hook_fn(module, input, output):\n",
        "        \"\"\"\n",
        "        Forward hook 함수\n",
        "\n",
        "        Args:\n",
        "            module: 현재 레이어 객체\n",
        "            input: 레이어 입력 (튜플)\n",
        "            output: 레이어 출력 (텐서)\n",
        "        \"\"\"\n",
        "        # 레이어 이름 생성 (클래스 이름 사용)\n",
        "        layer_name = module.__class__.__name__\n",
        "\n",
        "        # 동일한 레이어 타입이 여러 개 있을 경우 번호 추가\n",
        "        count = sum(1 for k in layer_outputs.keys() if layer_name in k)\n",
        "        if count > 0:\n",
        "            layer_name = f\"{layer_name}_{count+1}\"\n",
        "\n",
        "        # 출력 크기를 딕셔너리에 저장\n",
        "        layer_outputs[layer_name] = output.shape\n",
        "\n",
        "    # 모든 하위 모듈에 hook 등록\n",
        "    for name, module in model.named_modules():\n",
        "        # 전체 모델 자체는 제외 (하위 레이어만 등록)\n",
        "        if len(list(module.children())) == 0 and module != model:\n",
        "            # register_forward_hook: forward pass 시 hook_fn 실행\n",
        "            handle = module.register_forward_hook(hook_fn)\n",
        "            handles.append(handle)\n",
        "\n",
        "    return handles\n",
        "\n",
        "# Hook 등록\n",
        "print('모든 레이어에 Hook 등록 중...')\n",
        "hook_handles = register_hooks(model)\n",
        "print(f'총 {len(hook_handles)}개의 Hook이 등록되었습니다.\\n')\n",
        "\n",
        "# 더미 입력으로 순전파 실행 (hook 트리거)\n",
        "# 입력: [배치=1, 채널=3, 높이=32, 너비=32]\n",
        "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "# randn: 표준 정규분포(평균 0, 표준편차 1)에서 랜덤 샘플링\n",
        "\n",
        "print('더미 입력으로 순전파 실행 중...')\n",
        "with torch.no_grad():  # 그래디언트 계산 비활성화 (메모리 절약)\n",
        "    output = model(dummy_input)\n",
        "\n",
        "print('\\n순전파 완료! 각 레이어의 출력 크기:\\n')\n",
        "\n",
        "# 레이어별 출력 크기 출력\n",
        "print('='*60)\n",
        "print(f'{\"레이어 이름\":<25} {\"출력 Shape\":>30}')\n",
        "print('-'*60)\n",
        "print(f'{\"입력 이미지\":<25} {str(dummy_input.shape):>30}')\n",
        "print('-'*60)\n",
        "\n",
        "for layer_name, shape in layer_outputs.items():\n",
        "    print(f'{layer_name:<25} {str(tuple(shape)):>30}')\n",
        "\n",
        "print('='*60)\n",
        "\n",
        "# Hook 제거 (메모리 정리)\n",
        "print('\\nHook 제거 중...')\n",
        "for handle in hook_handles:\n",
        "    handle.remove()  # hook 등록 해제\n",
        "print('모든 Hook이 제거되었습니다.')\n",
        "\n",
        "# 출력 크기 해석\n",
        "print('\\n출력 크기 해석:')\n",
        "print('  - 형식: [배치 크기, 채널 수, 높이, 너비]')\n",
        "print('  - Conv 후: 채널 수 증가, 공간 크기는 padding으로 유지')\n",
        "print('  - MaxPool 후: 채널 수 유지, 공간 크기 절반으로 축소')\n",
        "print('  - Flatten 후: [배치 크기, 총 특징 수]로 1차원화')\n",
        "print('  - FC 후: [배치 크기, 출력 뉴런 수]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdxdjm1G-7WD"
      },
      "source": [
        "## Section 6: 학습 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN8YKHDi-7WD"
      },
      "outputs": [],
      "source": [
        "# 학습 함수 정의\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    1 에폭 동안 모델을 학습\n",
        "\n",
        "    Args:\n",
        "        model: 학습할 모델\n",
        "        train_loader: 학습 데이터 로더\n",
        "        criterion: 손실 함수\n",
        "        optimizer: 옵티마이저\n",
        "        device: 디바이스 (cuda 또는 cpu)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (평균 손실, 정확도)\n",
        "    \"\"\"\n",
        "    model.train()  # 모델을 학습 모드로 설정 (Dropout, BatchNorm 활성화)\n",
        "\n",
        "    running_loss = 0.0  # 에폭 전체의 손실 누적\n",
        "    correct = 0  # 맞춘 샘플 수\n",
        "    total = 0  # 전체 샘플 수\n",
        "\n",
        "    # tqdm: 진행률 표시줄 생성\n",
        "    pbar = tqdm(train_loader, desc='학습 중', leave=False)\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(pbar):\n",
        "        # 데이터를 디바이스로 이동\n",
        "        inputs = inputs.to(device)  # [batch, 3, 32, 32]\n",
        "        labels = labels.to(device)  # [batch]\n",
        "\n",
        "        # 그래디언트 초기화 (이전 배치의 그래디언트 제거)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 (Forward Pass)\n",
        "        outputs = model(inputs)  # [batch, 10]\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "        # CrossEntropyLoss: Softmax + NLL Loss\n",
        "        # 입력: 로짓(logit), 정답 레이블\n",
        "\n",
        "        # 역전파 (Backward Pass)\n",
        "        loss.backward()  # 그래디언트 계산\n",
        "\n",
        "        # 가중치 업데이트\n",
        "        optimizer.step()  # 계산된 그래디언트로 파라미터 업데이트\n",
        "\n",
        "        # 통계 업데이트\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        # loss.item(): 텐서에서 스칼라 값 추출\n",
        "        # inputs.size(0): 현재 배치 크기\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = outputs.max(1)\n",
        "        # max(1): dim=1(클래스 차원)에서 최댓값과 인덱스 반환\n",
        "        # _: 최댓값은 무시\n",
        "        # predicted: 최댓값의 인덱스 (예측 클래스)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        # eq(): 예측과 정답이 같으면 True\n",
        "        # sum(): True의 개수\n",
        "\n",
        "        # 진행률 표시줄 업데이트\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    # 에폭 평균 손실 및 정확도 계산\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "print('학습 함수 정의 완료!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCZp4c---7WF"
      },
      "source": [
        "## Section 7: 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwrOyhAa-7WF"
      },
      "outputs": [],
      "source": [
        "# 평가 함수 정의\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    테스트 데이터로 모델 평가\n",
        "\n",
        "    Args:\n",
        "        model: 평가할 모델\n",
        "        test_loader: 테스트 데이터 로더\n",
        "        criterion: 손실 함수\n",
        "        device: 디바이스\n",
        "\n",
        "    Returns:\n",
        "        tuple: (평균 손실, 정확도)\n",
        "    \"\"\"\n",
        "    model.eval()  # 모델을 평가 모드로 설정 (Dropout 비활성화, BatchNorm은 학습 통계 사용)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # 그래디언트 계산 비활성화 (평가 시에는 역전파 불필요)\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(test_loader, desc='평가 중', leave=False)\n",
        "\n",
        "        for inputs, labels in pbar:\n",
        "            # 데이터를 디바이스로 이동\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 순전파만 수행 (역전파 없음)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 통계 업데이트\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # 예측값 계산\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # 진행률 업데이트\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "\n",
        "    # 평균 손실 및 정확도 계산\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "print('평가 함수 정의 완료!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqHCZml-7WG"
      },
      "source": [
        "## Section 8: 학습 설정 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIxrLvzl-7WG"
      },
      "outputs": [],
      "source": [
        "# 학습 설정\n",
        "\n",
        "# 손실 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# CrossEntropyLoss: 다중 클래스 분류의 표준 손실 함수\n",
        "# 내부적으로 Softmax + Negative Log-Likelihood 결합\n",
        "# 입력: 로짓(logit), 정답 레이블(정수)\n",
        "\n",
        "# 옵티마이저 정의\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),  # 최적화할 파라미터\n",
        "    lr=0.001,  # 학습률 (learning rate)\n",
        "    weight_decay=1e-4  # L2 정규화 계수 (과적합 방지)\n",
        ")\n",
        "# Adam: Adaptive Moment Estimation\n",
        "# - 모멘텀과 RMSProp을 결합한 최적화 알고리즘\n",
        "# - 각 파라미터마다 적응적 학습률 사용\n",
        "# - 일반적으로 좋은 성능\n",
        "\n",
        "# 학습 에폭 수\n",
        "num_epochs = 10\n",
        "# 에폭(epoch): 전체 학습 데이터를 한 번 완전히 순회\n",
        "\n",
        "# 학습 히스토리 저장용\n",
        "train_losses = []  # 에폭별 학습 손실\n",
        "train_accs = []  # 에폭별 학습 정확도\n",
        "test_losses = []  # 에폭별 테스트 손실\n",
        "test_accs = []  # 에폭별 테스트 정확도\n",
        "\n",
        "print('학습 설정 완료!')\n",
        "print('='*60)\n",
        "print('학습 하이퍼파라미터')\n",
        "print('='*60)\n",
        "print(f'에폭 수: {num_epochs}')\n",
        "print(f'배치 크기: {batch_size}')\n",
        "print(f'학습률: {optimizer.param_groups[0][\"lr\"]}')\n",
        "print(f'가중치 감쇠: {optimizer.param_groups[0][\"weight_decay\"]}')\n",
        "print(f'옵티마이저: {optimizer.__class__.__name__}')\n",
        "print(f'손실 함수: {criterion.__class__.__name__}')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h06CX60w-7WH"
      },
      "outputs": [],
      "source": [
        "# 학습 루프 실행\n",
        "\n",
        "print('\\n학습 시작!\\n')\n",
        "print('='*70)\n",
        "\n",
        "# 최고 정확도 추적 (모델 저장용)\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
        "    print('-'*70)\n",
        "\n",
        "    # 1. 학습 단계\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, criterion, optimizer, device\n",
        "    )\n",
        "\n",
        "    # 2. 평가 단계\n",
        "    test_loss, test_acc = evaluate(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # 3. 결과 저장\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    # 4. 에폭 결과 출력\n",
        "    print(f'\\n학습 - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%')\n",
        "    print(f'테스트 - Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%')\n",
        "\n",
        "    # 5. 최고 성능 모델 저장\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        # 모델 가중치 저장\n",
        "        torch.save(model.state_dict(), 'best_svhn_model.pth')\n",
        "        # state_dict(): 모델의 모든 파라미터를 딕셔너리로 반환\n",
        "        print(f'  → 최고 성능 모델 저장! (정확도: {best_acc:.2f}%)')\n",
        "\n",
        "print('\\n')\n",
        "print('='*70)\n",
        "print('학습 완료!')\n",
        "print(f'최고 테스트 정확도: {best_acc:.2f}%')\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNBKaRs-7WI"
      },
      "source": [
        "## Section 9: 학습 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVU8pCSc-7WI"
      },
      "outputs": [],
      "source": [
        "# 학습 곡선 그리기\n",
        "\n",
        "# 에폭 번호 (x축)\n",
        "epochs_range = range(1, num_epochs + 1)\n",
        "\n",
        "# 2x1 서브플롯 생성\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# 왼쪽 그래프: 손실 곡선\n",
        "ax1.plot(epochs_range, train_losses, 'b-', label='학습 손실', marker='o')\n",
        "ax1.plot(epochs_range, test_losses, 'r-', label='테스트 손실', marker='s')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('손실 곡선 (Loss Curve)', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 오른쪽 그래프: 정확도 곡선\n",
        "ax2.plot(epochs_range, train_accs, 'b-', label='학습 정확도', marker='o')\n",
        "ax2.plot(epochs_range, test_accs, 'r-', label='테스트 정확도', marker='s')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('정확도 곡선 (Accuracy Curve)', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 최종 성능 요약\n",
        "print('\\n최종 성능 요약:')\n",
        "print('='*60)\n",
        "print(f'최종 학습 손실: {train_losses[-1]:.4f}')\n",
        "print(f'최종 학습 정확도: {train_accs[-1]:.2f}%')\n",
        "print(f'최종 테스트 손실: {test_losses[-1]:.4f}')\n",
        "print(f'최종 테스트 정확도: {test_accs[-1]:.2f}%')\n",
        "print(f'최고 테스트 정확도: {best_acc:.2f}%')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xXdL7gn-7WI"
      },
      "outputs": [],
      "source": [
        "# 예측 결과 시각화\n",
        "# 테스트 데이터에서 예측 결과 확인\n",
        "\n",
        "# 최고 성능 모델 로드\n",
        "model.load_state_dict(torch.load('best_svhn_model.pth'))\n",
        "# load_state_dict(): 저장된 파라미터를 모델에 로드\n",
        "model.eval()  # 평가 모드\n",
        "\n",
        "# 테스트 데이터에서 배치 하나 가져오기\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 모델로 예측\n",
        "images = images.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "    _, predicted = outputs.max(1)\n",
        "\n",
        "# CPU로 이동 및 역정규화\n",
        "images = images.cpu()\n",
        "predicted = predicted.cpu()\n",
        "labels = labels.cpu()\n",
        "\n",
        "# 16개 샘플 시각화\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "\n",
        "    # 이미지 역정규화 및 차원 변환\n",
        "    img = denormalize(images[i]).numpy().transpose(1, 2, 0)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # 정답과 예측 표시\n",
        "    true_label = class_names[labels[i]]\n",
        "    pred_label = class_names[predicted[i]]\n",
        "\n",
        "    # 정답이면 파란색, 오답이면 빨간색\n",
        "    color = 'blue' if true_label == pred_label else 'red'\n",
        "    plt.title(f'실제: {true_label} / 예측: {pred_label}', color=color, fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('테스트 데이터 예측 결과 (파란색: 정답, 빨간색: 오답)',\n",
        "             fontsize=14, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 정확도 계산\n",
        "correct = (predicted == labels).sum().item()\n",
        "total = labels.size(0)\n",
        "print(f'\\n현재 배치 정확도: {100.*correct/total:.2f}% ({correct}/{total})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTUB_2Kx-7WI"
      },
      "source": [
        "## Section 10: 혼동 행렬 (Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDP_mWB1-7WJ"
      },
      "outputs": [],
      "source": [
        "# 혼동 행렬 계산 및 시각화\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# 전체 테스트 데이터에 대한 예측\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc='혼동 행렬 계산 중'):\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('예측 레이블', fontsize=12)\n",
        "plt.ylabel('실제 레이블', fontsize=12)\n",
        "plt.title('혼동 행렬 (Confusion Matrix)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 클래스별 정확도 계산\n",
        "print('\\n클래스별 정확도:')\n",
        "print('='*60)\n",
        "print(f'{\"숫자\":<10} {\"정확도\":>15} {\"샘플 수\":>15}')\n",
        "print('-'*60)\n",
        "\n",
        "for i in range(10):\n",
        "    # 해당 클래스의 정확도 계산\n",
        "    class_correct = cm[i, i]  # 대각선 원소 (정답)\n",
        "    class_total = cm[i].sum()  # 해당 행의 합 (전체)\n",
        "    class_acc = 100.0 * class_correct / class_total if class_total > 0 else 0\n",
        "    print(f'{class_names[i]:<10} {class_acc:>14.2f}% {class_total:>15}')\n",
        "\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PimxD6s0-7WJ"
      },
      "source": [
        "## Section 11: 실습 요약 및 개선 아이디어"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwBW5RWn-7WK"
      },
      "outputs": [],
      "source": [
        "# 실습 요약 출력\n",
        "\n",
        "print('\\n')\n",
        "print('='*70)\n",
        "print('CNN 모델 빌드 실습 요약')\n",
        "print('='*70)\n",
        "\n",
        "print('\\n1. 데이터셋: SVHN (Street View House Numbers)')\n",
        "print(f'   - 학습 데이터: {len(train_dataset):,}개')\n",
        "print(f'   - 테스트 데이터: {len(test_dataset):,}개')\n",
        "print(f'   - 클래스 수: 10개 (0-9 숫자)')\n",
        "\n",
        "print('\\n2. 모델 아키텍처:')\n",
        "print('   Feature Extractor:')\n",
        "print('     - Conv1(32) + ReLU + MaxPool')\n",
        "print('     - Conv2(64) + ReLU + MaxPool')\n",
        "print('     - Conv3(128) + ReLU + MaxPool')\n",
        "print('   Classifier:')\n",
        "print('     - Flatten')\n",
        "print('     - FC1(2048->512) + ReLU + Dropout(0.5)')\n",
        "print('     - FC2(512->10)')\n",
        "\n",
        "print(f'\\n3. 총 파라미터 수: {total_params:,}개')\n",
        "\n",
        "print('\\n4. 학습 설정:')\n",
        "print(f'   - 에폭: {num_epochs}')\n",
        "print(f'   - 배치 크기: {batch_size}')\n",
        "print(f'   - 옵티마이저: Adam (lr=0.001)')\n",
        "print(f'   - 손실 함수: CrossEntropyLoss')\n",
        "\n",
        "print('\\n5. 최종 성능:')\n",
        "print(f'   - 최고 테스트 정확도: {best_acc:.2f}%')\n",
        "print(f'   - 최종 테스트 정확도: {test_accs[-1]:.2f}%')\n",
        "print(f'   - 최종 테스트 손실: {test_losses[-1]:.4f}')\n",
        "\n",
        "print('\\n6. 주요 학습 내용:')\n",
        "print('   ✓ CNN 아키텍처 설계 (Feature Extractor + Classifier 분리)')\n",
        "print('   ✓ 파라미터 수 계산 및 모델 크기 파악')\n",
        "print('   ✓ Hook을 사용한 레이어 출력 shape 추적')\n",
        "print('   ✓ 데이터 증강을 통한 성능 향상')\n",
        "print('   ✓ 학습 곡선 및 혼동 행렬 분석')\n",
        "\n",
        "print('\\n')\n",
        "print('='*70)\n",
        "print('실습 완료!')\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jKttkSq-7WK"
      },
      "source": [
        "## 개선 아이디어 및 추가 실습\n",
        "\n",
        "### 1. 더 깊은 네트워크\n",
        "- Conv 블록을 4-5개로 증가\n",
        "- Batch Normalization 추가\n",
        "- Residual Connection 도입\n",
        "\n",
        "### 2. 정규화 기법\n",
        "- Batch Normalization 추가\n",
        "- Layer Normalization 실험\n",
        "- L2 정규화 강도 조정\n",
        "\n",
        "### 3. 데이터 증강 강화\n",
        "- RandomRotation 추가\n",
        "- RandomErasing 적용\n",
        "- Mixup, CutMix 기법\n",
        "\n",
        "### 4. 학습률 스케줄링\n",
        "- StepLR: 일정 에폭마다 학습률 감소\n",
        "- CosineAnnealingLR: Cosine 함수로 학습률 조정\n",
        "- ReduceLROnPlateau: 성능 정체 시 학습률 감소\n",
        "\n",
        "### 5. 앙상블\n",
        "- 여러 모델의 예측 결합\n",
        "- Test Time Augmentation (TTA)\n",
        "\n",
        "### 6. 전이학습\n",
        "- 사전학습된 ResNet, VGG 모델 활용\n",
        "- Fine-tuning 실험\n",
        "\n",
        "### 7. 하이퍼파라미터 튜닝\n",
        "- 배치 크기 실험 (64, 128, 256)\n",
        "- 학습률 범위 탐색 (1e-5 ~ 1e-2)\n",
        "- Dropout 비율 조정 (0.3, 0.5, 0.7)\n",
        "\n",
        "### 8. 시각화 확장\n",
        "- Feature Map 시각화\n",
        "- Grad-CAM (Class Activation Mapping)\n",
        "- 필터 시각화\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vOCduLZ_YbX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}