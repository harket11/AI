{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XbGVizibXRh"
      },
      "source": [
        "# 당뇨병 예측 시스템 (실무형)\n",
        "\n",
        "\n",
        "\n",
        "##  학습 목표\n",
        "1. 전체 ML 파이프라인 구축\n",
        "2. DataLoader를 사용한 배치 학습\n",
        "3. Early Stopping 구현\n",
        "4. Learning Rate Scheduler 활용\n",
        "5. 모델 저장 및 로드\n",
        "6. 실무 코드 구조\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9KpHH0lbXRj"
      },
      "source": [
        "## 1. 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itppqQR6bXRj"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch scikit-learn matplotlib pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzhgvnmnbXRk"
      },
      "source": [
        "## 2. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBeeETg8bXRk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import json\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['axes.grid'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joL2Cdy6bXRl"
      },
      "source": [
        "## 3. Config 클래스 (설정 관리)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v98iaYjIbXRl"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.test_size = 0.2\n",
        "        self.val_size = 0.2\n",
        "        self.random_state = 42\n",
        "        self.input_dim = 10\n",
        "        self.hidden_dims = [64, 32, 16]\n",
        "        self.dropout_rate = 0.3\n",
        "        self.batch_size = 32\n",
        "        self.num_epochs = 200\n",
        "        self.learning_rate = 0.001\n",
        "        self.weight_decay = 0.0001\n",
        "        self.patience = 20\n",
        "        self.min_delta = 0.001\n",
        "        self.scheduler_step_size = 30\n",
        "        self.scheduler_gamma = 0.5\n",
        "\n",
        "config = Config()\n",
        "print('Config 생성 완료!')\n",
        "print(f'Batch Size: {config.batch_size}')\n",
        "print(f'Learning Rate: {config.learning_rate}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPNArcy2bXRl"
      },
      "source": [
        "## 4. DataPreprocessor 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQNoISa2bXRl"
      },
      "outputs": [],
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_and_prepare_data(self):\n",
        "        diabetes = load_diabetes()\n",
        "        X = diabetes.data\n",
        "        y_regression = diabetes.target\n",
        "        median = np.median(y_regression)\n",
        "        y = (y_regression > median).astype(int)\n",
        "\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=self.config.test_size, stratify=y, random_state=self.config.random_state\n",
        "        )\n",
        "        # Train - Test 분류\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=self.config.val_size,\n",
        "            stratify=y_train_val, random_state=self.config.random_state\n",
        "        )\n",
        "        # Train data set 을 Train - Validation 분류\n",
        "\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        #fit_transform(X_train) 훈련하니깐 fit_transform 이야\n",
        "        X_val = self.scaler.transform(X_val)\n",
        "        X_test = self.scaler.transform(X_test)\n",
        "\n",
        "        print('데이터 준비 완료')\n",
        "        print(f'Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}')\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def create_dataloaders(self, X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "        train_dataset = TensorDataset(\n",
        "            torch.FloatTensor(X_train),\n",
        "            torch.FloatTensor(y_train).view(-1, 1)\n",
        "            # 파이토치가 2차원 구조 기대 (batch_size, features)\n",
        "        )\n",
        "        val_dataset = TensorDataset(\n",
        "            torch.FloatTensor(X_val),\n",
        "            torch.FloatTensor(y_val).view(-1, 1)\n",
        "        )\n",
        "        test_dataset = TensorDataset(\n",
        "            torch.FloatTensor(X_test),\n",
        "            torch.FloatTensor(y_test).view(-1, 1)\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
        "\n",
        "        print(f'DataLoader 생성 완료 (Batch Size: {self.config.batch_size})')\n",
        "\n",
        "        return train_loader, val_loader, test_loader\n",
        "\n",
        "print('DataPreprocessor 클래스 정의 완료!')\n",
        "\n",
        "# 파이토치 해주세요. 데이터를 텐서 데이터셋으로 변경해주시구요, 이 친구를 데이터로더에 올려주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3AieuBcbXRl"
      },
      "source": [
        "## 5. 데이터 준비 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpDx_PvjbXRm"
      },
      "outputs": [],
      "source": [
        "preprocessor = DataPreprocessor(config)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.load_and_prepare_data()\n",
        "train_loader, val_loader, test_loader = preprocessor.create_dataloaders(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYCH7TxfbXRm"
      },
      "source": [
        "## 6. 모델 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8iHFnIobXRm"
      },
      "outputs": [],
      "source": [
        "class DiabetesClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3):\n",
        "        super(DiabetesClassifier, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, 1))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "model = DiabetesClassifier(\n",
        "    input_dim=config.input_dim,\n",
        "    hidden_dims=config.hidden_dims,\n",
        "    dropout_rate=config.dropout_rate\n",
        ")\n",
        "\n",
        "print('모델 생성 완료!')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK3an7gEbXRm"
      },
      "source": [
        "## ⏱7. EarlyStopping 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BBFvJicbXRm"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model_state = model.state_dict()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model_state = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "print('EarlyStopping 클래스 정의 완료!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XngZsOOAbXRm"
      },
      "source": [
        "## 8. Trainer 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk0UmdO-bXRm"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, config, device='cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=config.learning_rate,\n",
        "            weight_decay=config.weight_decay\n",
        "        )\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(\n",
        "            self.optimizer,\n",
        "            step_size=config.scheduler_step_size,\n",
        "            gamma=config.scheduler_gamma\n",
        "        )\n",
        "        self.early_stopping = EarlyStopping(\n",
        "            patience=config.patience,\n",
        "            min_delta=config.min_delta\n",
        "        )\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'val_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_acc': [],\n",
        "            'learning_rate': []\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_X.size(0)\n",
        "            predicted = (outputs >= 0.0).float()\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "                total_loss += loss.item() * batch_X.size(0)\n",
        "                predicted = (outputs >= 0.0).float()\n",
        "                total += batch_y.size(0)\n",
        "                correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    def fit(self, train_loader, val_loader):\n",
        "        print('학습 시작...')\n",
        "\n",
        "        for epoch in range(self.config.num_epochs):\n",
        "            train_loss, train_acc = self.train_epoch(train_loader)\n",
        "            val_loss, val_acc = self.validate(val_loader)\n",
        "            self.scheduler.step()\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['learning_rate'].append(current_lr)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1:3d}/{self.config.num_epochs}] \"\n",
        "                      f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
        "                      f\"LR: {current_lr:.6f}\")\n",
        "\n",
        "            self.early_stopping(val_loss, self.model)\n",
        "            if self.early_stopping.early_stop:\n",
        "                print(f\"Early Stopping at Epoch {epoch+1}\")\n",
        "                self.model.load_state_dict(self.early_stopping.best_model_state)\n",
        "                break\n",
        "\n",
        "        print('\\n학습 완료!')\n",
        "\n",
        "print('Trainer 클래스 정의 완료!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJfLgYfxbXRm"
      },
      "source": [
        "## 9. 모델 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_DbF0P8bXRn"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model, config)\n",
        "trainer.fit(train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60pYXzM4bXRn"
      },
      "source": [
        "## 10. 학습 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI41ePQGbXRn"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "axes[0, 0].plot(trainer.history['train_loss'], label='Train Loss')\n",
        "axes[0, 0].plot(trainer.history['val_loss'], label='Val Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Loss Curve')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "axes[0, 1].plot(trainer.history['train_acc'], label='Train Acc')\n",
        "axes[0, 1].plot(trainer.history['val_acc'], label='Val Acc')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].set_title('Accuracy Curve')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "axes[1, 0].plot(trainer.history['learning_rate'], color='orange')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Learning Rate')\n",
        "axes[1, 0].set_title('Learning Rate Schedule')\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "axes[1, 1].plot(trainer.history['train_loss'], label='Train', alpha=0.7)\n",
        "axes[1, 1].plot(trainer.history['val_loss'], label='Val', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].set_title('Train vs Val Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip6DwT4_bXRn"
      },
      "source": [
        "## 11. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Eu0PqmbXRn"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            outputs = model(batch_X)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (outputs >= 0.0).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(batch_y.numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds).flatten()\n",
        "    all_probs = np.array(all_probs).flatten()\n",
        "    all_labels = np.array(all_labels).flatten()\n",
        "\n",
        "    return all_labels, all_preds, all_probs\n",
        "\n",
        "all_labels, all_preds, all_probs = evaluate_model(model, test_loader)\n",
        "\n",
        "print('[Classification Report]')\n",
        "print(classification_report(all_labels, all_preds, target_names=['Low Risk', 'High Risk']))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print('\\n[Confusion Matrix]')\n",
        "print(f'              Predicted')\n",
        "print(f'            Low  High')\n",
        "print(f'Actual Low  {cm[0,0]:3d}  {cm[0,1]:3d}')\n",
        "print(f'       High {cm[1,0]:3d}  {cm[1,1]:3d}')\n",
        "\n",
        "auc = roc_auc_score(all_labels, all_probs)\n",
        "print(f'\\nAUC: {auc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDP6tjr4bXRn"
      },
      "source": [
        "## 12. Precision-Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBDi8E4mbXRn"
      },
      "outputs": [],
      "source": [
        "precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, linewidth=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eos"
      ],
      "metadata": {
        "id": "6P35ESzdfUoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8F5cGHufVbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}