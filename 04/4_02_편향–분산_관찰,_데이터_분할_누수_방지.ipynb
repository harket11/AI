{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WH61XoKlOSx"
      },
      "outputs": [],
      "source": [
        "# 4차시 보강 실습: Bias-Variance 감각 익히기 (편ba 분va )\n",
        "import torch, math, random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) 데이터: 사인파 + 잡음 -> 회귀 문제\n",
        "torch.manual_seed(0)\n",
        "N = 600\n",
        "x = torch.linspace(-3*math.pi, 3*math.pi, N).unsqueeze(1)\n",
        "y = torch.sin(x) + 0.2*torch.randn_like(x)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(x.numpy(), y.numpy(), test_size=0.4, random_state=42)\n",
        "X_val,   X_test, y_val,   y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val,   y_val   = torch.tensor(X_val,   dtype=torch.float32), torch.tensor(y_val,   dtype=torch.float32)\n",
        "X_test,  y_test  = torch.tensor(X_test,  dtype=torch.float32), torch.tensor(y_test,  dtype=torch.float32)\n",
        "\n",
        "# 2) 두 모델: 저용량(작은 MLP) vs 고용량(큰 MLP)\n",
        "def make_mlp(hidden):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(1, hidden), nn.ReLU(),\n",
        "        nn.Linear(hidden, hidden), nn.ReLU(),\n",
        "        nn.Linear(hidden, 1)\n",
        "    )\n",
        "\n",
        "small = make_mlp(hidden=8)   # 고편향/저분산 경향\n",
        "big   = make_mlp(hidden=128) # 저편향/고분산 경향\n",
        "\n",
        "def train(model, Xtr, ytr, Xva, yva, epochs=600, lr=1e-3):\n",
        "    # lr = [0.001,0.01,0.1] for i in lr 가장 성능 좋게 나온 lr >> lr = lr\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    tr_hist, va_hist = [], []\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        pred = model(Xtr) # 반드시 훈련용 데이터로 학습(**) >> 예측 값\n",
        "        loss = loss_fn(pred, ytr)\n",
        "        loss.backward()   # w1 = w0 - lr(diff_y / diff_xtr)\n",
        "        opt.step()\n",
        "\n",
        "        # transfer learning(전이 학습)\n",
        "        # 잘 된 모델(오픈소스 제공 모델)을 활용, 내 모델에 적용하는 것\n",
        "        model.eval()  # eval : evaluation 평가\n",
        "        with torch.no_grad():\n",
        "            v = loss_fn(model(Xva), yva).item()\n",
        "        tr_hist.append(loss.item()); va_hist.append(v)\n",
        "    return tr_hist, va_hist\n",
        "\n",
        "tr_s, va_s = train(small, X_train, y_train, X_val, y_val, epochs=400)\n",
        "tr_b, va_b = train(big, X_train, y_train, X_val, y_val, epochs=400)\n",
        "\n",
        "plt.figure(); plt.plot(tr_s, label='small-train'); plt.plot(va_s, label='small-val')\n",
        "plt.plot(tr_b, label='big-train'); plt.plot(va_b, label='big-val'); plt.legend(); plt.title('Bias-Variance')\n",
        "plt.show()\n",
        "\n",
        "# 최종 테스트 MSE\n",
        "def mse(model, X, y):\n",
        "    with torch.no_grad():\n",
        "        return nn.MSELoss()(model(X), y).item()\n",
        "print(\"Small Test MSE:\", mse(small, X_test, y_test))\n",
        "print(\"Big   Test MSE:\", mse(big,   X_test, y_test))\n"
      ]
    }
  ]
}