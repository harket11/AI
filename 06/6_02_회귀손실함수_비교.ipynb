{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGxnvwt0VCWQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Part 1: 회귀 손실함수 비교\n",
        "- MSE (Mean Squared Error)\n",
        "- MAE (Mean Absolute Error)\n",
        "- Huber Loss\n",
        "\n",
        "독립적으로 실행 가능합니다.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 재현성을 위한 시드 고정\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Part 1: 회귀 손실함수 비교\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 실습 1-1: 손실함수의 동작 원리 이해\n",
        "# =====================================================================\n",
        "print(\"\\n[실습 1-1] 손실함수 동작 원리\")\n",
        "\n",
        "# 간단한 예측값과 실제값\n",
        "y_true = torch.tensor([10.0, 20.0, 30.0])\n",
        "y_pred = torch.tensor([12.0, 19.0, 35.0])\n",
        "\n",
        "# MSE 계산\n",
        "mse_loss = nn.MSELoss()\n",
        "mse_value = mse_loss(y_pred, y_true)\n",
        "\n",
        "# MAE 계산\n",
        "mae_loss = nn.L1Loss()  # L1Loss = MAE\n",
        "mae_value = mae_loss(y_pred, y_true)\n",
        "\n",
        "# Huber Loss 계산\n",
        "huber_loss = nn.HuberLoss(delta=1.0)\n",
        "huber_value = huber_loss(y_pred, y_true)\n",
        "\n",
        "print(\"\\n예측값:\", y_pred.numpy())\n",
        "print(\"실제값:\", y_true.numpy())\n",
        "print(\"오차:  \", (y_pred - y_true).numpy())\n",
        "\n",
        "print(f\"\\nMSE:   {mse_value.item():.4f}\")\n",
        "print(f\"MAE:   {mae_value.item():.4f}\")\n",
        "print(f\"Huber: {huber_value.item():.4f}\")\n",
        "\n",
        "# 수동 계산으로 검증\n",
        "errors = (y_pred - y_true).numpy()\n",
        "print(\"\\n수동 계산:\")\n",
        "print(f\"MSE:   {np.mean(errors**2):.4f}\")\n",
        "print(f\"MAE:   {np.mean(np.abs(errors)):.4f}\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 실습 1-2: 이상치가 있을 때 손실함수 비교\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[실습 1-2] 이상치에 대한 민감도 비교\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 정상 데이터 + 이상치\n",
        "y_true_with_outlier = torch.tensor([10.0, 20.0, 30.0, 40.0, 50.0])\n",
        "y_pred_normal = torch.tensor([11.0, 19.0, 31.0, 39.0, 51.0])  # 정상 예측\n",
        "y_pred_with_outlier = torch.tensor([11.0, 19.0, 31.0, 100.0, 51.0])  # 이상치 포함\n",
        "\n",
        "print(\"\\n정상 예측 (오차 모두 작음):\")\n",
        "print(\"실제:\", y_true_with_outlier.numpy())\n",
        "print(\"예측:\", y_pred_normal.numpy())\n",
        "\n",
        "mse_normal = mse_loss(y_pred_normal, y_true_with_outlier)\n",
        "mae_normal = mae_loss(y_pred_normal, y_true_with_outlier)\n",
        "huber_normal = huber_loss(y_pred_normal, y_true_with_outlier)\n",
        "\n",
        "print(f\"\\nMSE:   {mse_normal.item():.4f}\")\n",
        "print(f\"MAE:   {mae_normal.item():.4f}\")\n",
        "print(f\"Huber: {huber_normal.item():.4f}\")\n",
        "\n",
        "print(\"\\n이상치 포함 예측 (하나의 큰 오차):\")\n",
        "print(\"실제:\", y_true_with_outlier.numpy())\n",
        "print(\"예측:\", y_pred_with_outlier.numpy())\n",
        "print(\"오차:\", (y_pred_with_outlier - y_true_with_outlier).numpy())\n",
        "\n",
        "mse_outlier = mse_loss(y_pred_with_outlier, y_true_with_outlier)\n",
        "mae_outlier = mae_loss(y_pred_with_outlier, y_true_with_outlier)\n",
        "huber_outlier = huber_loss(y_pred_with_outlier, y_true_with_outlier)\n",
        "\n",
        "print(f\"\\nMSE:   {mse_outlier.item():.4f} (증가율: {mse_outlier/mse_normal:.1f}배)\")\n",
        "print(f\"MAE:   {mae_outlier.item():.4f} (증가율: {mae_outlier/mae_normal:.1f}배)\")\n",
        "print(f\"Huber: {huber_outlier.item():.4f} (증가율: {huber_outlier/huber_normal:.1f}배)\")\n",
        "\n",
        "print(\"\\n분석:\")\n",
        "print(\"  MSE는 이상치에 매우 민감 (제곱 때문)\")\n",
        "print(\"  MAE는 이상치에 강건 (절댓값만 고려)\")\n",
        "print(\"  Huber는 중간 (작은 오차는 제곱, 큰 오차는 선형)\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 실습 1-3: 손실함수별 학습 비교\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[실습 1-3] 실제 회귀 문제에서 손실함수 비교\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 회귀 데이터 생성 (일부러 이상치 추가)\n",
        "print(\"\\n데이터 생성 중...\")\n",
        "X, y = make_regression(n_samples=500, n_features=10, noise=10.0, random_state=42)\n",
        "\n",
        "# 이상치 추가 (10%의 데이터에 큰 노이즈)\n",
        "n_outliers = int(0.1 * len(y))\n",
        "outlier_indices = np.random.choice(len(y), n_outliers, replace=False)\n",
        "y[outlier_indices] += np.random.randn(n_outliers) * 50  # 큰 노이즈\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 텐서 변환\n",
        "X_train_t = torch.FloatTensor(X_train)\n",
        "y_train_t = torch.FloatTensor(y_train).unsqueeze(1)\n",
        "X_test_t = torch.FloatTensor(X_test)\n",
        "y_test_t = torch.FloatTensor(y_test).unsqueeze(1)\n",
        "\n",
        "print(f\"훈련 데이터: {X_train.shape}, 이상치: {n_outliers}개\")\n",
        "\n",
        "\n",
        "# 간단한 회귀 모델\n",
        "class RegressionModel(nn.Module):\n",
        "    \"\"\"간단한 회귀 신경망\"\"\"\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(10, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "# 세 가지 손실함수로 각각 학습\n",
        "loss_functions = {\n",
        "    'MSE': nn.MSELoss(),\n",
        "    'MAE': nn.L1Loss(),\n",
        "    'Huber': nn.HuberLoss(delta=1.0)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for loss_name, criterion in loss_functions.items():\n",
        "    print(f\"\\n{loss_name}로 학습 중...\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = RegressionModel()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # 학습\n",
        "    train_losses = []\n",
        "    num_epochs = 100\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(X_train_t)\n",
        "        loss = criterion(output, y_train_t)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    # 테스트\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_pred = model(X_test_t)\n",
        "\n",
        "        # 모든 지표로 평가\n",
        "        test_mse = nn.MSELoss()(test_pred, y_test_t).item()\n",
        "        test_mae = nn.L1Loss()(test_pred, y_test_t).item()\n",
        "        test_huber = nn.HuberLoss()(test_pred, y_test_t).item()\n",
        "\n",
        "    results[loss_name] = {\n",
        "        'train_losses': train_losses,\n",
        "        'test_mse': test_mse,\n",
        "        'test_mae': test_mae,\n",
        "        'test_huber': test_huber,\n",
        "        'predictions': test_pred\n",
        "    }\n",
        "\n",
        "    print(f\"  최종 훈련 손실: {train_losses[-1]:.4f}\")\n",
        "    print(f\"  테스트 MSE: {test_mse:.4f}\")\n",
        "    print(f\"  테스트 MAE: {test_mae:.4f}\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 실습 1-4: 결과 시각화\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[실습 1-4] 결과 시각화\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. 학습 곡선 비교\n",
        "ax1 = axes[0, 0]\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "for (loss_name, result), color in zip(results.items(), colors):\n",
        "    ax1.plot(result['train_losses'], label=loss_name, linewidth=2, color=color)\n",
        "\n",
        "ax1.set_xlabel('Epoch', fontsize=11)\n",
        "ax1.set_ylabel('Training Loss', fontsize=11)\n",
        "ax1.set_title('Training Loss Comparison', fontsize=12, weight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. 테스트 성능 비교 (MAE 기준)\n",
        "ax2 = axes[0, 1]\n",
        "loss_names = list(results.keys())\n",
        "test_maes = [results[name]['test_mae'] for name in loss_names]\n",
        "\n",
        "bars = ax2.bar(loss_names, test_maes, color=colors, edgecolor='black', alpha=0.7)\n",
        "ax2.set_ylabel('Test MAE', fontsize=11)\n",
        "ax2.set_title('Test MAE Comparison', fontsize=12, weight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 값 표시\n",
        "for bar, mae in zip(bars, test_maes):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{mae:.2f}', ha='center', va='bottom', fontsize=10, weight='bold')\n",
        "\n",
        "# 3. 예측 vs 실제 (MAE 모델)\n",
        "ax3 = axes[1, 0]\n",
        "mae_predictions = results['MAE']['predictions'].numpy().flatten()\n",
        "ax3.scatter(y_test, mae_predictions, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "         'r--', linewidth=2, label='Perfect Prediction')\n",
        "ax3.set_xlabel('True Values', fontsize=11)\n",
        "ax3.set_ylabel('Predicted Values', fontsize=11)\n",
        "ax3.set_title('MAE Model: Prediction vs True', fontsize=12, weight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. 오차 분포 비교\n",
        "ax4 = axes[1, 1]\n",
        "for loss_name, color in zip(loss_names, colors):\n",
        "    predictions = results[loss_name]['predictions'].numpy().flatten()\n",
        "    errors = y_test - predictions\n",
        "    ax4.hist(errors, bins=30, alpha=0.5, label=loss_name, color=color)\n",
        "\n",
        "ax4.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
        "ax4.set_xlabel('Prediction Error', fontsize=11)\n",
        "ax4.set_ylabel('Frequency', fontsize=11)\n",
        "ax4.set_title('Error Distribution', fontsize=12, weight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('part1_regression_loss_comparison.png', dpi=150, bbox_inches='tight')\n",
        "print(\"\\n저장: part1_regression_loss_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 실습 1-5: Huber Loss의 delta 파라미터 영향\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[실습 1-5] Huber Loss의 delta 파라미터 영향\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 다양한 delta 값으로 테스트\n",
        "delta_values = [0.5, 1.0, 2.0, 5.0]\n",
        "\n",
        "# 오차 범위\n",
        "errors = torch.linspace(-10, 10, 200)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Huber Loss 계산\n",
        "for delta in delta_values:\n",
        "    huber = nn.HuberLoss(delta=delta, reduction='none')\n",
        "    # 0을 실제값으로, errors를 예측값으로 설정\n",
        "    loss_values = huber(errors, torch.zeros_like(errors))\n",
        "    plt.plot(errors.numpy(), loss_values.numpy(),\n",
        "             label=f'delta={delta}', linewidth=2)\n",
        "\n",
        "# MSE와 MAE 비교\n",
        "mse_values = 0.5 * errors**2\n",
        "mae_values = torch.abs(errors)\n",
        "\n",
        "plt.plot(errors.numpy(), mse_values.numpy(),\n",
        "         'k--', linewidth=2, label='MSE', alpha=0.5)\n",
        "plt.plot(errors.numpy(), mae_values.numpy(),\n",
        "         'k:', linewidth=2, label='MAE', alpha=0.5)\n",
        "\n",
        "plt.xlabel('Prediction Error', fontsize=12)\n",
        "plt.ylabel('Loss Value', fontsize=12)\n",
        "plt.title('Huber Loss with Different Delta Values', fontsize=14, weight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(0, 50)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('part1_huber_delta_effect.png', dpi=150, bbox_inches='tight')\n",
        "print(\"\\n저장: part1_huber_delta_effect.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n분석:\")\n",
        "print(\"  delta가 작을수록 MSE에 가까움 (작은 오차에 민감)\")\n",
        "print(\"  delta가 클수록 MAE에 가까움 (큰 오차에 관대)\")\n",
        "print(\"  delta=1.0이 일반적으로 좋은 기본값\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 최종 요약\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Part 1 완료\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n핵심 개념:\")\n",
        "print(\"\\n1. MSE (Mean Squared Error)\")\n",
        "print(\"   - 큰 오차에 큰 페널티\")\n",
        "print(\"   - 이상치에 매우 민감\")\n",
        "print(\"   - 가장 널리 사용\")\n",
        "\n",
        "print(\"\\n2. MAE (Mean Absolute Error)\")\n",
        "print(\"   - 모든 오차를 동등하게 취급\")\n",
        "print(\"   - 이상치에 강건\")\n",
        "print(\"   - 해석이 직관적\")\n",
        "\n",
        "print(\"\\n3. Huber Loss\")\n",
        "print(\"   - MSE + MAE의 장점 결합\")\n",
        "print(\"   - delta로 경계 조절\")\n",
        "print(\"   - 로봇공학, 강화학습에서 선호\")\n",
        "\n",
        "print(\"\\n실전 가이드:\")\n",
        "print(\"  - 일반적인 경우: MSE\")\n",
        "print(\"  - 이상치 많음: MAE 또는 Huber\")\n",
        "print(\"  - 빠른 수렴 필요: MSE\")\n",
        "print(\"  - 강건성 필요: Huber (delta=1.0)\")\n",
        "\n",
        "print(\"\\n생성된 파일:\")\n",
        "print(\"  1. part1_regression_loss_comparison.png - 손실함수 비교\")\n",
        "print(\"  2. part1_huber_delta_effect.png - Huber delta 영향\")\n",
        "\n",
        "print(\"\\n다음: Part 2 - 분류 손실함수\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ]
}