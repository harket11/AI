{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 14차시 보강: 전이학습 전략 비교 실습\n",
        "\n",
        "이 실습에서는 **3가지 전이학습 전략**을 비교합니다:\n",
        "1. **Freeze (전체 동결)**: 백본 전체를 고정하고 분류기만 학습\n",
        "2. **Partial (부분 해제)**: 마지막 블록(layer4)과 분류기만 학습\n",
        "3. **Full (전체 해제)**: 모든 층을 학습\n",
        "\n",
        "**목표**: 소규모 데이터셋(3,000개)에서 각 전략의 성능을 비교하고 최적 전략을 찾기"
      ],
      "metadata": {
        "id": "cVkcZRLc2Fll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJc4E2771r38"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 라이브러리 설치\n",
        "\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "metadata": {
        "id": "ZSRLI5be2XTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "런타임 다시 시작하세요."
      ],
      "metadata": {
        "id": "Fy0iErn32fGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib\n",
        "\n",
        "# 나눔고딕 폰트 경로 설정\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "fontprop = fm.FontProperties(fname=font_path)\n",
        "\n",
        "# matplotlib 기본 폰트로 지정\n",
        "matplotlib.rc('font', family='NanumGothic')\n",
        "\n",
        "# 마이너스 부호 깨짐 방지\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"한글 폰트 설정 완료:\", matplotlib.rcParams['font.family'])"
      ],
      "metadata": {
        "id": "ur1WDFjH2gx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 라이브러리 임포트 및 환경설정"
      ],
      "metadata": {
        "id": "NtM_Xy4A2oJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필수 라이브러리 임포트\n",
        "import torch  # PyTorch 메인 라이브러리\n",
        "import torch.nn as nn  # 신경망 모듈\n",
        "import torch.optim as optim  # 최적화 알고리즘\n",
        "from torchvision import datasets, transforms, models  # 비전 관련 도구\n",
        "from torch.utils.data import DataLoader, Subset  # 데이터 로더\n",
        "import numpy as np  # 수치 연산\n",
        "import random  # 랜덤 함수\n",
        "\n",
        "# GPU 사용 가능 여부 확인 및 디바이스 설정\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'사용 디바이스: {device}')\n",
        "\n",
        "# 재현성을 위한 시드 설정 (매번 동일한 결과를 얻기 위함)\n",
        "torch.manual_seed(0)  # PyTorch 시드\n",
        "np.random.seed(0)  # NumPy 시드\n",
        "random.seed(0)  # Python random 시드\n",
        "\n",
        "# CUDA 사용 시 추가 재현성 설정\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)  # CUDA 시드\n",
        "    torch.backends.cudnn.deterministic = True  # 결정적 알고리즘 사용\n",
        "    torch.backends.cudnn.benchmark = False  # 벤치마크 비활성화\n",
        "\n",
        "print('환경 설정 완료!')\n",
        "print(f'PyTorch 버전: {torch.__version__}')"
      ],
      "metadata": {
        "id": "fTIsVLt12naS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "tdeJsn4h28TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "                  transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n",
        "                  # 이미지의 60-100% 영역을 무작위로 잘라 224*224 이미지로 조정\n",
        "                  transforms.RandomHorizontalFlip(),\n",
        "                  # 50%확률로 좌우 반전\n",
        "\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize(mean = (0.485, 0.456, 0.406),\n",
        "                                      std = (0.229, 0.224, 0.225))\n",
        "                  # RGB 각 채널의 평균과 표준편차\n",
        "              ]\n",
        "              )\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                  transforms.Resize(256), # 이미지를 256*256 사이즈로 변형\n",
        "                  transforms.CenterCrop(224),\n",
        "                  # 중앙을 224 * 224 이미지로 잘라냄 (증강 없이 고정된 영역 사용)\n",
        "\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize(mean = (0.485, 0.456, 0.406),\n",
        "                                      std = (0.229, 0.224, 0.225))\n",
        "                  # RGB 각 채널의 평균과 표준편차\n",
        "              ]\n",
        "              )"
      ],
      "metadata": {
        "id": "vGxWGvib26G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cifar-10 데이터셋 다운로드"
      ],
      "metadata": {
        "id": "ml2unIqc5bl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train_full =  datasets.CIFAR10(\n",
        "                      root = '/tmp/cifar.tl',\n",
        "                      train = True,\n",
        "                      download=True,\n",
        "                      transform = transform_train\n",
        "                  )\n",
        "\n",
        "dataset_test       =  datasets.CIFAR10(\n",
        "                      root = '/tmp/cifar.tl',\n",
        "                      train = False,\n",
        "                      download=True,\n",
        "                      transform = transform_test\n",
        "                  )"
      ],
      "metadata": {
        "id": "NuHJModu5TfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'전체 학습 데이터: {len(dataset_train_full):,}개')\n",
        "print(f'전체 테스트 데이터: {len(dataset_test):,}개')\n",
        "print(f'클래스 수: 10개 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)')"
      ],
      "metadata": {
        "id": "12xingP16AWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "소규모 서브셋 생성\n",
        "\n",
        "- 전체 50,000개 중 각 클래스 당 300개씩, 총 3,000개만 사용하여 소규모 데이터 셋 상황 어떻게 문제 해결할 것인가?"
      ],
      "metadata": {
        "id": "jFSrVGpE6qJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 클래스별로 300개씩 선택 >> 총 3000개 서브셋 생성\n",
        "\n",
        "selected_indices = []\n",
        "\n",
        "# 각 클래스(0-9) 별로 카운트 저장할 딕셔너리 초기화\n",
        "class_counts = {i: 0 for i in range(10)}\n",
        "\n",
        "# class_counts\n",
        "# {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "\n",
        "# 전체 학습 데이터 돌면서 각 클래스 당 300개씩 선택\n",
        "for idx, (image, label) in enumerate(dataset_train_full):\n",
        "  # 조건 1: 해당 클래스 현재 개수가 300개 미만이면\n",
        "  if class_counts[label] < 300:\n",
        "    selected_indices.append(idx)\n",
        "    class_counts[label] += 1\n",
        "\n",
        "  # 조건 2: 중지조건\n",
        "  # 총 3000개 모두 선택하면 중지\n",
        "  if len(selected_indices) >= 3000:\n",
        "    break\n",
        "\n",
        "# print(selected_indices)\n",
        "\n",
        "# 선택된 인덱스(selected_indices) >> 서브셋 생성\n",
        "dataset_train_small = Subset(dataset_train_full, selected_indices)\n",
        "\n",
        "print(len(dataset_train_small))\n"
      ],
      "metadata": {
        "id": "Peee7LqR634m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_counts\n",
        "for class_id, count in class_counts.items():\n",
        "  class_name = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                'dog','frog','horse','ship','truck'][class_id]\n",
        "  print(f'{class_id} ({class_name}): {count}개')"
      ],
      "metadata": {
        "id": "UJnf0YRD7crF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 로더 생성"
      ],
      "metadata": {
        "id": "ffmLG1LqMImM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader =  DataLoader(\n",
        "                dataset_train_small,\n",
        "                batch_size = 64,\n",
        "                shuffle=True,\n",
        "                # 한번 학습할 때 마다(매 epoch) 무작위 데이터 순서를 섞어줌 (과적합 방지)\n",
        "                num_workers=2,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "\n",
        "test_loader =   DataLoader(\n",
        "                dataset_test,\n",
        "                batch_size = 128,\n",
        "                # 일반적으로 평가할 때 조금 더 큰 배치 사용 가능\n",
        "                shuffle=False,\n",
        "                # 평가시 순서 섞지 않음\n",
        "                num_workers=2,\n",
        "                pin_memory=True\n",
        "            )"
      ],
      "metadata": {
        "id": "vHyZ2x4I9GEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더 정보 출력\n",
        "print(f'\\n학습 데이터:')\n",
        "print(f'  - 총 샘플 수: {len(dataset_train_small):,}개')\n",
        "print(f'  - 배치 크기: 64')\n",
        "print(f'  - 배치 수: {len(train_loader)}개')\n",
        "print(f'\\n테스트 데이터:')\n",
        "print(f'  - 총 샘플 수: {len(dataset_test):,}개')\n",
        "print(f'  - 배치 크기: 128')\n",
        "print(f'  - 배치 수: {len(test_loader)}개')"
      ],
      "metadata": {
        "id": "CPhGCJQLNZGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 빌드 함수 정의"
      ],
      "metadata": {
        "id": "UJcZX5A1Ng_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3가지 전략 (freeze, partial, full)\n",
        "\n",
        "def build_model(strategy = 'freeze'):\n",
        "   model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "   # 사전 학습(pre-trained)된 모델의 가중치(weights) 사용\n",
        "\n",
        "   # 원래 resnet18의 분류기 입력 특징 차원 저장\n",
        "   in_features = model.fc.in_features # 512차원\n",
        "\n",
        "   # 분류기를 CIFAR 10 에 맞게 교체 (1000 클래스 >> 10 클래스)\n",
        "   model.fc = nn.Linear(in_features, 10)\n",
        "\n",
        "   # 전략에 따라 파라미터 동결 설정\n",
        "   if strategy == 'freeze':\n",
        "     # 전략 1: 백본 전체를 동결 >> 분류기만 학습시키는 전략\n",
        "      print('[freeze 전략]: 백본 전체를 동결 >> 분류기만 학습')\n",
        "\n",
        "      # layer1,2,3,4 모두 동결\n",
        "      for param in model.layer1.parameters():\n",
        "        param.requires_grad = False # 기울기(gradient) 계산 비활성화\n",
        "      for param in model.layer2.parameters():\n",
        "        param.requires_grad = False # 기울기(gradient) 계산 비활성화\n",
        "      for param in model.layer3.parameters():\n",
        "        param.requires_grad = False # 기울기(gradient) 계산 비활성화\n",
        "      for param in model.layer4.parameters():\n",
        "        param.requires_grad = False # 기울기(gradient) 계산 비활성화\n",
        "\n",
        "      # fc(분류기: classifier) 새로 생성했기 때문에 자동으로 requires_grad = True\n",
        "   elif strategy == 'partial':\n",
        "      # 전략 2: 마지막 블록(layer4)과 분류기만 학습\n",
        "       print('[partial 전략]: 마지막 블록(layer4)과 분류기만 학습')\n",
        "\n",
        "       # 먼저, 모든 파라미터 동결\n",
        "       for param in model.parameters():\n",
        "         param.requires_grad = False\n",
        "\n",
        "       # layer4와 fc(분류기) 만 해제\n",
        "       for param in model.layer4.parameters():\n",
        "         param.requires_grad = True    # 기울기(gradient) 계산 활성화\n",
        "       for param in model.fc.parameters():\n",
        "         param.requires_grad = True\n",
        "\n",
        "   elif strategy == 'full':\n",
        "      # 전략 3: 모든 층을 학습\n",
        "       print('[full 전략]: 모든 층을 학습')\n",
        "\n",
        "       for param in model.parameters():\n",
        "         param.requires_grad = True\n",
        "\n",
        "   else:\n",
        "    raise ValueError('지원되지 않는 전략입니다.')\n",
        "\n",
        "   model = model.to(device)\n",
        "\n",
        "   # 학습 가능한 파라미터 수 계산\n",
        "   trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "   total_params = sum(p.numel() for p in model.parameters())\n",
        "   print(f'학습 가능한 파라미터 : {trainable_params:,} / {total_params:,}')\n",
        "\n",
        "   return model"
      ],
      "metadata": {
        "id": "-3zdj0adNURl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 및 평가 함수 정의"
      ],
      "metadata": {
        "id": "lTNgmIQQZPkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(strategy):\n",
        "\n",
        "  # 1.전략에 맞는 모델 생성\n",
        "  model = build_model(strategy)\n",
        "\n",
        "  # 2.최적화 함수 설정(차등 학습률 적용)\n",
        "  # 헤드(분류기)와 백본의 파라미터 분리\n",
        "  head_params = list(model.fc.parameters()) # 분류기 파라미터\n",
        "\n",
        "  # 백본 파라미터 (fc 아니면서 학습가능한 파라미터)\n",
        "  backbone_params = [\n",
        "      param for name, param in model.named_parameters()\n",
        "      if 'fc' not in name and param.requires_grad\n",
        "  ]\n",
        "\n",
        "  # 파라미터 그룹 구성(차등 학습률)\n",
        "  param_groups = []\n",
        "\n",
        "  # 백본 파라미터가 있다면\n",
        "  if backbone_params:\n",
        "    param_groups.append({\n",
        "        'params': backbone_params,\n",
        "        'lr': 1e-4 # 백본은 낮은 학습률(0.0001)\n",
        "    }\n",
        "\n",
        "    )\n",
        "\n",
        "  # 헤드(분류기) 파라미터가 있다면\n",
        "  if head_params:\n",
        "    param_groups.append({\n",
        "        'params': head_params,\n",
        "        'lr': 1e-3 # 헤드(분류기) 높은 학습률 (0.001, 백본의 10배)\n",
        "    })\n",
        "\n",
        "  # AdamW 옵티마이저 사용(가중치 감쇠 포함)\n",
        "  optimizer = optim.AdamW(param_groups, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "  # 손실 함수 정의\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # 3. 학습 루프\n",
        "  num_epoch = 10\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0 # 에폭별 손실 누적\n",
        "    correct = 0 # 맞춘 개수\n",
        "    total = 0   # 전체 샘플 수\n",
        "\n",
        "    # 배치 별 학습\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # 가중치 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 통계 업데이트\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # 에폭별 결과 출력\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "    print(f'Epoch [({epoch+1}/{num_epoch}]'\n",
        "          f'Loss: {epoch_loss:.4f}, '\n",
        "          f'Train_Acc: {epoch_acc:.2f}%')\n",
        "\n",
        "  model.eval() # 평가 모드로 전환\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # 그래디언트 계산 비활성화(평가시에는 불필요)\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # 순전파\n",
        "          outputs = model(inputs)\n",
        "\n",
        "            # 예측값 계산\n",
        "          predicted = outputs.argmax(dim=1)\n",
        "\n",
        "            # 정확도 계산\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # 최종 테스트 정확도 계산\n",
        "  test_accuracy = correct / total\n",
        "\n",
        "  print(f'테스트 정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
        "\n",
        "  return test_accuracy"
      ],
      "metadata": {
        "id": "Q29MqN5qZHEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험1 : Freeze 전략"
      ],
      "metadata": {
        "id": "yfijSke4mjhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_freeze = train_and_evaluate('freeze')"
      ],
      "metadata": {
        "id": "_2dt9pb3maEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험 2: Partial 전략"
      ],
      "metadata": {
        "id": "4gKe4obBonLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_partial = train_and_evaluate('partial')"
      ],
      "metadata": {
        "id": "gZGGAWXnms6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_full = train_and_evaluate('full')"
      ],
      "metadata": {
        "id": "02KThEKMouSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 결과 비교 및 분석"
      ],
      "metadata": {
        "id": "3qrHWKWspcSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Freeze (백본 전체 동결)': acc_freeze,\n",
        "    'Partial (layer4, fc 해제)': acc_partial,\n",
        "    'Full(모든 층 학습)': acc_full\n",
        "}\n",
        "\n",
        "print(f'\\n{\"전략\":<30} {\"테스트 정확도\":>15}')\n",
        "print('='*70)\n",
        "\n",
        "for strategy_name, accuracy in results.items():\n",
        "    print(f'{strategy_name:<30} {accuracy*100:>14.2f}%')"
      ],
      "metadata": {
        "id": "uuyk8OS4pUpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최고 성능 전략 찾기\n",
        "best_strategy = max(results, key=results.get)\n",
        "print(best_strategy)\n",
        "best_accuracy = results[best_strategy]\n",
        "print(best_accuracy)"
      ],
      "metadata": {
        "id": "evRatghjqvCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matplotlib 라이브러리 임포트\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 전략 이름과 정확도\n",
        "strategies = ['Freeze\\n(백본 동결)', 'Partial\\n(layer4 해제)', 'Full\\n(전체 학습)']\n",
        "accuracies = [acc_freeze * 100, acc_partial * 100, acc_full * 100]\n",
        "\n",
        "# 막대 그래프 생성\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(strategies, accuracies, color=['#3498db', '#2ecc71', '#e74c3c'],\n",
        "               alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# 각 막대 위에 정확도 값 표시\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.2f}%',\n",
        "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 그래프 설정\n",
        "plt.ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "plt.title('Transfer Learning Strategy Comparison', fontsize=14, fontweight='bold')\n",
        "plt.ylim([0, max(accuracies) * 1.15])  # Y축 범위 설정\n",
        "plt.grid(True, axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# 그래프 표시\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J5YAomE-rh2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}