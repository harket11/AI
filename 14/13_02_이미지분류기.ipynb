{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 나만의 이미지 분류기 만들기 (초급)\n",
        "\n",
        "##  학습 목표\n",
        "이 실습에서는 인공지능이 이미지를 어떻게 분류하는지 배웁니다!\n",
        "\n",
        "**배울 내용:**\n",
        "1. 사전 학습된 AI 모델 사용하기\n",
        "2. 이미지 데이터 준비하기\n",
        "3. 모델 학습시키기\n",
        "4. 결과 확인하기\n",
        "\n",
        "\n",
        "### 사전 학습 모델이란?\n",
        "\n",
        "마치 이미 많은 그림을 본 화가처럼, 이 AI 모델은 이미 수백만 장의 이미지로 학습되어 있습니다.\n",
        "\n",
        "우리는 이 똑똑한 모델을 가져와서 우리의 문제(CIFAR-10 이미지 분류)에 맞게 **약간만 조정**하면 됩니다!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ],
      "metadata": {
        "id": "0To5DqxHx-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 라이브러리 설치\n",
        "\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "metadata": {
        "id": "gmmFnP6GGY9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "런타임 다시 시작하세요"
      ],
      "metadata": {
        "id": "mKyu_f9jGetH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib\n",
        "\n",
        "# 나눔고딕 폰트 경로 설정\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "fontprop = fm.FontProperties(fname=font_path)\n",
        "\n",
        "# matplotlib 기본 폰트로 지정\n",
        "matplotlib.rc('font', family='NanumGothic')\n",
        "\n",
        "# 마이너스 부호 깨짐 방지\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"한글 폰트 설정 완료:\", matplotlib.rcParams['font.family'])\n"
      ],
      "metadata": {
        "id": "oevhVWnTyBWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1단계: 필요한 도구 준비하기\n",
        "\n",
        "요리를 시작하기 전에 재료와 도구를 준비하는 것처럼,\n",
        "AI 모델을 만들기 전에 필요한 라이브러리를 불러옵니다."
      ],
      "metadata": {
        "id": "section1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 가져오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision  # 이미지 처리 도구\n",
        "import torchvision.transforms as transforms  # 이미지 변환 도구\n",
        "import torchvision.models as models  # 사전 학습된 모델\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # 숫자 계산\n",
        "from tqdm import tqdm  # 진행 상태 표시\n",
        "\n",
        "# 결과를 항상 같게 만들기 (재현성)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# GPU 사용 가능한지 확인\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('준비 완료!')\n",
        "print(f'사용할 장치: {device}')\n",
        "if device.type == 'cuda':\n",
        "    print(f'GPU 이름: {torch.cuda.get_device_name(0)}')\n",
        "    print('GPU로 빠르게 학습할 수 있어요!')\n",
        "else:\n",
        "    print('CPU로 학습합니다. 조금 느릴 수 있어요.')"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2단계: 이미지 데이터 준비하기\n",
        "\n",
        "**CIFAR-10 데이터셋:**\n",
        "- 10가지 종류의 물체 사진 (비행기, 자동차, 새, 고양이 등)\n",
        "- 총 60,000장의 작은 이미지 (32x32 픽셀)\n",
        "- 50,000장으로 학습, 10,000장으로 테스트\n",
        "\n",
        "**이미지 변환:**\n",
        "- 크기를 112x112로 키웁니다 (더 자세하게 볼 수 있도록)\n",
        "- 좌우 반전으로 데이터를 늘립니다 (데이터 증강)\n",
        "- 숫자로 변환하고 정규화합니다"
      ],
      "metadata": {
        "id": "section2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 변환하는 방법 정의\n",
        "# 훈련용 이미지 변환 (데이터를 늘리기 위한 증강 포함)\n",
        "train_transform = transforms.Compose([\n",
        "    # 코드 작성\n",
        "    # 크기를 112x112로 조정\n",
        "    transforms.Resize(112),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # 50% 확률로 좌우 반전\n",
        "    # 이미지를 숫자(텐서)로 변환\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],   # RGB 평균값으로 정규화\n",
        "        std=[0.229, 0.224, 0.225]     # RGB 표준편차로 정규화\n",
        "    )\n",
        "])\n",
        "\n",
        "# 테스트용 이미지 변환 (증강 없음)\n",
        "test_transform = transforms.Compose([\n",
        "    # 코드 작성\n",
        "    # 크기를 112x112로 조정\n",
        "    transforms.Resize(112),\n",
        "    # 이미지를 숫자(텐서)로 변환\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "# 훈련 데이터 다운로드 및 준비\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # 데이터를 저장할 폴더\n",
        "    train=True,     # 훈련 데이터 사용\n",
        "    download=True,  # 없으면 다운로드\n",
        "    transform=train_transform  # 위에서 정의한 변환 적용\n",
        ")\n",
        "\n",
        "# 테스트 데이터 다운로드 및 준비\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,    # 테스트 데이터 사용\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "# 데이터 로더 생성 (배치로 묶어서 제공)\n",
        "train_loader  = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size = 64,\n",
        "                shuffle = True,  # 데이터 섞기\n",
        "                num_workers=2    # 병렬 처리\n",
        "            )\n",
        "\n",
        "\n",
        "test_loader  = DataLoader(\n",
        "               test_dataset,\n",
        "               batch_size = 64,\n",
        "               shuffle = False,  # 데이터 섞지 않음\n",
        "               num_workers=2    # 병렬 처리\n",
        "            )\n",
        "\n",
        "# 클래스 이름 (10가지 물체)\n",
        "classes = ['비행기', '자동차', '새', '고양이', '사슴',\n",
        "           '개', '개구리', '말', '배', '트럭']\n",
        "\n",
        "print(f'   훈련 이미지: {len(train_dataset):,}장')\n",
        "print(f'   테스트 이미지: {len(test_dataset):,}장')\n",
        "print(f'   분류할 종류: {len(classes)}가지')\n",
        "print(f'   배치 크기: {train_loader.batch_size}장씩')"
      ],
      "metadata": {
        "id": "data_preparation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1단계: 데이터 미리보기\n",
        "\n",
        "어떤 이미지로 학습하는지 확인해봅시다!"
      ],
      "metadata": {
        "id": "section2_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지 보기\n",
        "def show_sample_images(loader, classes, num_images=8):\n",
        "    \"\"\"\n",
        "    데이터에서 샘플 이미지를 보여주는 함수\n",
        "    \"\"\"\n",
        "    # 데이터 가져오기\n",
        "    images, labels = next(iter(loader))\n",
        "\n",
        "    # 정규화 해제(다시 원래 이미지로) >> [0,1] 범위로 복원하는 과정\n",
        "    # 정규화 : x_norm = (x - x_mean) / sigma(std)\n",
        "    # 정규화 해제: x = x_norm * std + mean\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "    # 채널별 평균(mean) 텐서 생성 : [3,1,1] (브로드캐스팅으로 각 픽셀에 채널별 평균을 적용하려고)\n",
        "    std = torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
        "    # 채널별 표준편차(std) 텐서 생성 : [3,1,1] (브로드캐스팅으로 각 픽셀에 채널별 표준편차를 적용하려고)\n",
        "    images = images * std + mean\n",
        "\n",
        "    # 값 범위 고정(clamp): 시각화/저장 전에 안전하게 [0,1] 구간으로 잘라냄\n",
        "    # >> 픽셀(pixel) 범위 [0.1] 로 제한\n",
        "    images = torch.clamp(images, 0, 1)\n",
        "\n",
        "    # 그리드로 표시\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    # 배치 이미지 텐서를 2×4 격자(grid)로 시각화하는 예시\n",
        "    axes = axes.ravel()\n",
        "    # axes는 2×4 배열 형태이므로, 편하게 1차원으로 평탄화\n",
        "    # print(axes)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # 이미지를 화면에 표시할 수 있는 형태로 변환\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        # permute(1, 2, 0) : (CHW→HWC) PyTorch 텐서 이미지는 보통 CHW.\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'{classes[labels[i]]}', fontsize=12)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print('샘플 이미지를 확인:')\n",
        "show_sample_images(train_loader, classes)"
      ],
      "metadata": {
        "id": "show_samples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3단계: AI 모델 만들기\n",
        "\n",
        "**MobileNetV2 모델:**\n",
        "- 이미 수백만 장의 이미지로 학습된 똑똑한 모델\n",
        "- 가볍고 빠른 모델 (모바일에서도 사용 가능)\n",
        "- 마지막 부분만 우리 문제에 맞게 바꿔요\n",
        "\n",
        "**왜 사전 학습 모델을 사용할까?**\n",
        "- 처음부터 학습하면 시간이 너무 오래 걸려요 (몇 주일!)\n",
        "- 이미 학습된 모델은 이미지의 기본 특징을 알고 있어요\n",
        "- 우리는 마지막 부분만 조정하면 돼요 (몇 분!)"
      ],
      "metadata": {
        "id": "section3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 학습된 MobileNetV2 모델 불러오기\n",
        "# 전이학습(Transfer Learning)\n",
        "model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "# 모델의 마지막 부분 확인\n",
        "print('\\n원래 모델의 마지막 부분:')\n",
        "print(f'  출력: {model.classifier[1].out_features}개 (ImageNet의 1000개 클래스)')\n",
        "# model.classifier[1]은 그 중 마지막 선형 계층(Linear Layer) 을 의미\n",
        "# out_features는 출력 노드의 개수, 즉 분류할 클래스 개수를 나타냄\n",
        "\n",
        "# 마지막 레이어를 우리 문제에 맞게 교체\n",
        "# CIFAR-10은 10개 클래스만 있으므로\n",
        "num_features = model.classifier[1].in_features  # 입력 특징 개수\n",
        "# MobileNetV2에서는 일반적으로 1280차원임\n",
        "model.classifier[1] = nn.Linear(num_features, 10)  # 10개 클래스로 변경\n",
        "\n",
        "print('\\n수정된 모델의 마지막 부분:')\n",
        "print(f'  출력: 10개 (CIFAR-10의 10개 클래스)')\n",
        "\n",
        "# 모델을 GPU로 이동 (있으면)\n",
        "model = model.to(device)\n",
        "\n",
        "# 모델 파라미터 개수 확인\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "# p.numel() : 각 파라미터 텐서의 원소(숫자) 개수를 반환\n",
        "print(f'\\n모델 파라미터 개수: {total_params:,}개')\n",
        "print('(약 230만 개의 숫자를 학습합니다!)')"
      ],
      "metadata": {
        "id": "model_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4단계: 학습 설정하기\n",
        "\n",
        "모델을 학습시키기 위해 필요한 것들:\n",
        "\n",
        "1. **손실 함수 (Loss Function):**\n",
        "   - 모델이 얼마나 틀렸는지 계산\n",
        "   - 숫자가 작을수록 잘 맞춘 것!\n",
        "\n",
        "2. **최적화 함수 (Optimizer):**\n",
        "   - 모델을 어떻게 개선할지 결정\n",
        "   - SGD (Stochastic Gradient Descent) 사용\n",
        "\n",
        "3. **학습률 (Learning Rate):**\n",
        "   - 한 번에 얼마나 많이 배울지 조절\n",
        "   - 0.001 = 천천히 조심스럽게 학습"
      ],
      "metadata": {
        "id": "section4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 손실 함수: 모델이 얼마나 틀렸는지 계산\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 2. 최적화 함수: 모델을 어떻게 개선할지\n",
        "# 코드 작성\n",
        "optimizer = optim.SGD(\n",
        "            model.parameters(), # 학습할 파라미터(학습 대상)\n",
        "            lr = 0.001,         # 학습률\n",
        "            momentum=0.9        # 관성 반영(더 안정적으로 학습)\n",
        "        )\n",
        "# 학습 설정\n",
        "num_epochs = 30  # 전체 데이터를 30번 반복해서 학습\n",
        "\n",
        "print('학습 설정 완료!')\n",
        "print(f'  손실 함수: {criterion.__class__.__name__}')\n",
        "print(f'  최적화 함수: {optimizer.__class__.__name__}')\n",
        "print(f'  학습률: {optimizer.param_groups[0][\"lr\"]}')\n",
        "# optimizer.param_groups[0] → 첫 번째 파라미터 그룹의 학습률(learning rate) 값\n",
        "print(f'  학습 횟수: {num_epochs}번')"
      ],
      "metadata": {
        "id": "training_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5단계: 모델 학습시키기\n",
        "\n",
        "드디어 모델을 학습시킬 시간입니다!\n",
        "\n",
        "**학습 과정:**\n",
        "1. 이미지를 모델에 입력\n",
        "2. 모델이 예측\n",
        "3. 정답과 비교해서 오차 계산\n",
        "4. 오차를 줄이는 방향으로 모델 조정\n",
        "5. 반복!\n",
        "\n",
        "**진행 상태:**\n",
        "- `loss`: 손실 (작을수록 좋음)\n",
        "- `acc`: 정확도 (클수록 좋음, 100%가 완벽)"
      ],
      "metadata": {
        "id": "section5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 기록을 저장할 리스트\n",
        "train_losses = []  # 훈련 손실\n",
        "train_accs = []    # 훈련 정확도\n",
        "test_accs = []     # 테스트 정확도\n",
        "\n",
        "print('학습 시작!')\n",
        "print('=' * 60)\n",
        "\n",
        "\n",
        "# 에폭마다 반복\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\n에폭 {epoch+1}/{num_epochs}')\n",
        "\n",
        "    # ===== 훈련 단계 =====\n",
        "\n",
        "    # 코드 작성\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0 # 손실 누적\n",
        "    correct = 0        # 맞춘 개수\n",
        "    total = 0          # 전체 개수\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=\"훈련\"):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # 1. 기울기 초기화\n",
        "      optimizer.zero_grad()\n",
        "      # 2. 순전파 : 모델이 예측\n",
        "      outputs = model(images)\n",
        "      # 3. 손실 계산\n",
        "      loss = criterion(outputs, labels)\n",
        "      # 4. 역전파 : 기울기 계산\n",
        "      loss.backward()\n",
        "      # 5. 가중치 업데이트\n",
        "      optimizer.step()\n",
        "\n",
        "      # 6. 통계계산\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "      # loss.item() : 현재 배치 평균 손실 값을 파이썬 숫자로 꺼냄\n",
        "      # images.size(0) : 배치 크기\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      # torch.max(outputs, 1) 각 샘플에 대해 가장 큰 로짓값(모델이 예측한 값)과 그 인덱스(예측 클래스) 반환\n",
        "      total  += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # epoch 단위 평균 손실/정확도 계산\n",
        "    # 에폭 평균 계산\n",
        "    # running loss >> 배치 손실 + 배치 크기 합 >> total (전체 샘플 수)로 나눠 에폭 평균 손실\n",
        "\n",
        "    epoch_loss  = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accs.append(epoch_acc)\n",
        "\n",
        "    # ===== 테스트 단계 =====\n",
        "    model.eval()  # 모델을 평가 모드로(Dropout 비활성, BatchNorm 고정)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # 코드 작성\n",
        "    with torch.no_grad():   # 기울기 계산 안 함 (평가만)\n",
        "      for images, labels in tqdm(test_loader, desc=\"테스트\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f'\\n에폭 {epoch+1} 결과:')\n",
        "    print(f'  훈련 손실: {epoch_loss:.4f}')\n",
        "    print(f'  훈련 정확도: {epoch_acc:.2f}%')\n",
        "    print(f'  테스트 정확도: {test_acc:.2f}%')\n",
        "    print('-' * 60)\n",
        "\n",
        "print('\\n학습 완료!')\n",
        "print('=' * 60)\n",
        "print(f'최종 테스트 정확도: {test_accs[-1]:.2f}%')\n",
        "print('=' * 60)"
      ],
      "metadata": {
        "id": "training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  6단계: 학습 결과 확인하기\n",
        "\n",
        "학습이 잘 되었는지 그래프로 확인해봅시다!"
      ],
      "metadata": {
        "id": "section6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선 그리기\n",
        "def plot_results(train_losses, train_accs, test_accs):\n",
        "    \"\"\"\n",
        "    학습 결과를 그래프로 그리는 함수\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # 손실 그래프\n",
        "    axes[0].plot(epochs, train_losses, 'b-o', linewidth=2, markersize=8, label='훈련 손실')\n",
        "    axes[0].set_xlabel('에폭', fontsize=12)\n",
        "    axes[0].set_ylabel('손실', fontsize=12)\n",
        "    axes[0].set_title('손실 변화', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 정확도 그래프\n",
        "    axes[1].plot(epochs, train_accs, 'g-o', linewidth=2, markersize=8, label='훈련 정확도')\n",
        "    axes[1].plot(epochs, test_accs, 'r-s', linewidth=2, markersize=8, label='테스트 정확도')\n",
        "    axes[1].set_xlabel('에폭', fontsize=12)\n",
        "    axes[1].set_ylabel('정확도 (%)', fontsize=12)\n",
        "    axes[1].set_title('정확도 변화 (클수록 좋음)', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(fontsize=11)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 결과 요약\n",
        "    print('\\n학습 결과 요약')\n",
        "    print('=' * 60)\n",
        "    print(f'시작 정확도: {test_accs[0]:.2f}%')\n",
        "    print(f'최종 정확도: {test_accs[-1]:.2f}%')\n",
        "    print(f'향상도: {test_accs[-1] - test_accs[0]:+.2f}%p')\n",
        "    print('=' * 60)\n",
        "\n",
        "    # 해석\n",
        "    if test_accs[-1] >= 85:\n",
        "        print('훌륭해요! 85% 이상의 정확도를 달성했습니다!')\n",
        "    elif test_accs[-1] >= 75:\n",
        "        print('좋아요! 75% 이상의 정확도를 달성했습니다!')\n",
        "    else:\n",
        "        print('괜찮아요! 더 많은 에폭으로 학습하면 더 좋아질 거예요!')\n",
        "\n",
        "# 그래프 그리기\n",
        "plot_results(train_losses, train_accs, test_accs)"
      ],
      "metadata": {
        "id": "plot_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  7단계: 실제 예측 확인하기\n",
        "\n",
        "우리 모델이 실제로 이미지를 어떻게 분류하는지 확인해봅시다!"
      ],
      "metadata": {
        "id": "section7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Permute'는 영어 동사로, 어떤 항목들(원소, 요소, 차원 등)의 순서나 위치를 서로 교환하여 새로운 배열을 만드는 행위를 의미합니다."
      ],
      "metadata": {
        "id": "MVnXnLqSF7L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 결과 시각화\n",
        "def show_predictions(model, loader, classes, device, num_images=12):\n",
        "    \"\"\"\n",
        "    모델의 예측 결과를 시각화하는 함수\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 데이터 가져오기\n",
        "    images, labels = next(iter(loader))\n",
        "    images = images.to(device)\n",
        "\n",
        "    # 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # CPU로 이동\n",
        "    images = images.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "\n",
        "    # 정규화 해제\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    images = images * std + mean\n",
        "    images = torch.clamp(images, 0, 1)\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in range(num_images):\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        axes[i].imshow(img)\n",
        "\n",
        "        # 정답과 예측 비교\n",
        "        true_label = classes[labels[i]]\n",
        "        pred_label = classes[predicted[i]]\n",
        "\n",
        "        # 맞으면 초록색, 틀리면 빨간색\n",
        "        if labels[i] == predicted[i]:\n",
        "            color = 'green'\n",
        "\n",
        "        else:\n",
        "            color = 'red'\n",
        "\n",
        "        axes[i].set_title(\n",
        "            f'정답: {true_label}\\n예측: {pred_label}',\n",
        "            color=color,\n",
        "            fontsize=11,\n",
        "            fontweight='bold'\n",
        "        )\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 정확도 계산\n",
        "    correct = (predicted[:num_images] == labels[:num_images]).sum().item()\n",
        "    accuracy = 100 * correct / num_images\n",
        "\n",
        "    print(f'\\n이 샘플에서 {num_images}개 중 {correct}개를 맞췄어요!')\n",
        "    print(f'정확도: {accuracy:.1f}%')\n",
        "\n",
        "show_predictions(model, test_loader, classes, device, num_images=12)"
      ],
      "metadata": {
        "id": "show_predictions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8단계: 클래스별 성능 확인\n",
        "\n",
        "어떤 물체를 잘 맞추고, 어떤 물체를 어려워하는지 확인해봅시다!"
      ],
      "metadata": {
        "id": "section8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls = [\"사람\", \"고양이\",\"개\"]\n",
        "[0] * len(cls)"
      ],
      "metadata": {
        "id": "DNX80eO8QxRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스별 정확도 계산\n",
        "def evaluate_per_class(model, loader, classes, device):\n",
        "    \"\"\"\n",
        "    클래스별 성능을 평가하는 함수\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 클래스별 맞춘 개수와 전체 개수\n",
        "    class_correct = [0] * len(classes)\n",
        "    class_total = [0] * len(classes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc='클래스별 평가'):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 클래스별로 집계\n",
        "            c = (predicted == labels)\n",
        "            for i in range(len(labels)):\n",
        "               label = labels[i]\n",
        "               class_correct[label] += c[i].item()\n",
        "               class_total[label] += 1\n",
        "\n",
        "            # 코드 작성\n",
        "\n",
        "    # 결과 출력\n",
        "    print('\\n클래스별 정확도')\n",
        "    print('=' * 50)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    # 코드 작성\n",
        "    for i, class_name in enumerate(classes):\n",
        "        if class_total[i] > 0 :\n",
        "          acc =100 * class_correct[i] / class_total[i]\n",
        "          accuracies.append(acc)\n",
        "\n",
        "          print(f'{class_name:8s} {acc:5.1f}%')\n",
        "\n",
        "    print('=' * 50)\n",
        "    print(f'평균 정확도: {np.mean(accuracies):.2f}%')\n",
        "\n",
        "    # 가장 잘 맞추는 것과 어려워하는 것\n",
        "\n",
        "    # 코드 작성\n",
        "    best_idx = np.argmax(accuracies)\n",
        "    worst_idx = np.argmin(accuracies)\n",
        "\n",
        "    print(f'\\n가장 잘 맞추는 것: {classes[best_idx]} ({accuracies[best_idx]:.1f}%)')\n",
        "    print(f'가장 어려워하는 것: {classes[worst_idx]} ({accuracies[worst_idx]:.1f}%)')\n",
        "\n",
        "# 클래스별 평가\n",
        "evaluate_per_class(model, test_loader, classes, device)"
      ],
      "metadata": {
        "id": "class_accuracy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9단계: 모델 저장하기 (선택사항)\n",
        "\n",
        "학습한 모델을 저장하면 나중에 다시 사용할 수 있어요!"
      ],
      "metadata": {
        "id": "section9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "model_path = \"my_image_classifer.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "# 코드 작성\n",
        "\n",
        "print(f'모델 저장 완료: {model_path}')\n",
        "print('\\n나중에 이 모델을 불러오려면:')\n",
        "print('```python')\n",
        "print('model = models.mobilenet_v2()')\n",
        "print('model.classifier[1] = nn.Linear(1280, 10)')\n",
        "print(f'model.load_state_dict(torch.load(\"{model_path}\"))')\n",
        "print('model.eval()')\n",
        "print('```')"
      ],
      "metadata": {
        "id": "save_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10단계: 학습 정리 및 복습\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### 오늘 배운 내용\n",
        "\n",
        "1. **사전 학습 모델 사용하기**\n",
        "   - 이미 똑똑한 MobileNetV2 모델을 가져왔어요\n",
        "   - 마지막 부분만 우리 문제에 맞게 바꿨어요\n",
        "\n",
        "2. **이미지 데이터 준비하기**\n",
        "   - CIFAR-10 데이터셋 사용 (10가지 물체)\n",
        "   - 이미지 크기 조정, 좌우 반전 등 데이터 증강\n",
        "   - 배치로 묶어서 효율적으로 처리\n",
        "\n",
        "3. **모델 학습시키기**\n",
        "   - 순전파: 모델이 예측\n",
        "   - 손실 계산: 얼마나 틀렸는지\n",
        "   - 역전파: 어떻게 고칠지\n",
        "   - 가중치 업데이트: 실제로 고치기\n",
        "\n",
        "4. **결과 확인하기**\n",
        "   - 학습 곡선으로 진행 상황 확인\n",
        "   - 예측 결과를 눈으로 확인\n",
        "   - 클래스별 성능 분석\n",
        "\n",
        "---\n",
        "\n",
        "### 핵심 개념 정리\n",
        "\n",
        "| 개념 | 설명 | 비유 |\n",
        "|------|------|------|\n",
        "| **사전 학습 모델** | 이미 학습된 모델 | 경험 많은 선생님  |\n",
        "| **파인 튜닝** | 마지막 부분만 조정 | 새로운 과목만 공부하기 |\n",
        "| **손실 함수** | 틀린 정도 측정 | 시험 점수  |\n",
        "| **최적화 함수** | 개선 방법 | 공부 방법 |\n",
        "| **에폭** | 전체 데이터 1회 학습 | 교과서 1번 읽기  |\n",
        "\n",
        "---\n",
        "\n",
        "### 더 나아가기\n",
        "\n",
        "**이 모델을 더 좋게 만들려면?**\n",
        "\n",
        "1. **더 많이 학습하기**\n",
        "   - `num_epochs`를 10이나 20으로 늘려보세요\n",
        "   - 정확도가 더 올라갈 거예요!\n",
        "\n",
        "2. **더 강력한 데이터 증강**\n",
        "   - 회전, 색상 변경, 자르기 등 추가\n",
        "   - 모델이 더 다양한 상황에 대응할 수 있어요\n",
        "\n",
        "3. **다른 모델 시도하기**\n",
        "   - ResNet-18, ResNet-50, EfficientNet 등\n",
        "   - 더 복잡한 모델은 더 정확할 수 있어요\n",
        "\n",
        "4. **학습률 조정하기**\n",
        "   - 학습률 스케줄러 사용\n",
        "   - 학습 초반은 빠르게, 후반은 천천히\n",
        "\n"
      ],
      "metadata": {
        "id": "summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eos\n",
        "# google authenticator 다운로드 받아주세요"
      ],
      "metadata": {
        "id": "pqJYBW5HHEcy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}