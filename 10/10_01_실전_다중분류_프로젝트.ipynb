{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9bip_EXBWZ6"
      },
      "source": [
        "# 심화 실습 2: 실전 다중 분류 프로젝트 - 성능 분석과 시각화\n",
        "\n",
        "## 학습 목표\n",
        "- 실전 데이터셋으로 완전한 머신러닝 파이프라인 구축\n",
        "- 혼동 행렬(Confusion Matrix)을 통한 세밀한 성능 분석\n",
        "- Precision, Recall, F1-Score 등 다양한 평가 지표 이해\n",
        "- 모델 저장 및 불러오기\n",
        "- 실전 예측 시스템 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT47OGtRBWZ-"
      },
      "source": [
        "## 1. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9jZid09BWZ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_digits  # 손글씨 숫자 데이터 (0~9)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# 한글 폰트 및 그래프 스타일 설정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"NumPy 버전: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoJ-xheTBWZ_"
      },
      "source": [
        "## 2. 데이터 로드 및 탐색\n",
        "\n",
        "**Digits 데이터셋**: 8x8 픽셀 손글씨 숫자 이미지 (0~9)\n",
        "- 총 1,797개 샘플\n",
        "- 각 샘플은 64개 특성 (8x8 픽셀)\n",
        "- 10개 클래스 (0, 1, 2, ..., 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtq4AsGGBWZ_"
      },
      "outputs": [],
      "source": [
        "def load_and_explore_data():\n",
        "    \"\"\"\n",
        "    데이터를 로드하고 기본 정보를 출력하는 함수\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X, y, digits)\n",
        "    \"\"\"\n",
        "    # 데이터 로드\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data, digits.target\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"데이터셋 정보\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"전체 샘플 수: {X.shape[0]:,}개\")\n",
        "    print(f\"특성(Feature) 수: {X.shape[1]}개 (8x8 픽셀)\")\n",
        "    print(f\"클래스 수: {len(np.unique(y))}개 (0~9)\")\n",
        "    print(f\"특성값 범위: [{X.min():.1f}, {X.max():.1f}]\")\n",
        "\n",
        "    # 클래스별 분포\n",
        "    print(\"\\n클래스별 샘플 수:\")\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    for digit, count in zip(unique, counts):\n",
        "        print(f\"  숫자 {digit}: {count}개\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return X, y, digits\n",
        "\n",
        "# 데이터 로드\n",
        "X, y, digits = load_and_explore_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N37EFN9rBWZ_"
      },
      "source": [
        "## 3. 샘플 이미지 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0P0n9ePBWaA"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(digits, n_samples=10):\n",
        "    \"\"\"\n",
        "    랜덤 샘플 이미지를 시각화하는 함수\n",
        "\n",
        "    Args:\n",
        "        digits: digits 데이터셋 객체\n",
        "        n_samples: 표시할 샘플 수\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    # 랜덤 인덱스 선택\n",
        "    random_indices = np.random.choice(len(digits.images), n_samples, replace=False)\n",
        "\n",
        "    for idx, ax_idx in enumerate(random_indices):\n",
        "        axes[idx].imshow(digits.images[ax_idx], cmap='gray')\n",
        "        axes[idx].set_title(f'Label: {digits.target[ax_idx]}', fontsize=12, fontweight='bold')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.suptitle('Sample Handwritten Digits', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 샘플 시각화\n",
        "visualize_samples(digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih1m9lB7BWaA"
      },
      "source": [
        "## 4. 데이터 전처리 및 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u0b0VOeBWaA"
      },
      "outputs": [],
      "source": [
        "def prepare_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    데이터를 전처리하고 Train/Validation/Test로 분할\n",
        "\n",
        "    Args:\n",
        "        X: 입력 데이터\n",
        "        y: 레이블 데이터\n",
        "        test_size: 테스트 데이터 비율\n",
        "        val_size: 검증 데이터 비율 (훈련 데이터 중)\n",
        "        random_state: 랜덤 시드\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test, scaler)\n",
        "    \"\"\"\n",
        "    # Train+Val과 Test 분리\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train과 Validation 분리\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size, random_state=random_state, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # 표준화 (평균=0, 표준편차=1)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"데이터 분할 결과\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"훈련 데이터: {X_train.shape[0]}개 ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"검증 데이터: {X_val.shape[0]}개 ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"테스트 데이터: {X_test.shape[0]}개 ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"\\n표준화 후 훈련 데이터 통계:\")\n",
        "    print(f\"  평균: {X_train.mean():.4f}\")\n",
        "    print(f\"  표준편차: {X_train.std():.4f}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler\n",
        "\n",
        "# 데이터 준비\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, scaler = prepare_data(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II5-nwG9BWaA"
      },
      "source": [
        "## 5. PyTorch 텐서 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aicw6xmjBWaA"
      },
      "outputs": [],
      "source": [
        "def numpy_to_tensor(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"\n",
        "    NumPy 배열을 PyTorch 텐서로 변환\n",
        "    \"\"\"\n",
        "    # 입력: float32\n",
        "    train_inputs = torch.FloatTensor(X_train)\n",
        "    val_inputs = torch.FloatTensor(X_val)\n",
        "    test_inputs = torch.FloatTensor(X_test)\n",
        "\n",
        "    # 레이블: long (int64)\n",
        "    train_labels = torch.LongTensor(y_train)\n",
        "    val_labels = torch.LongTensor(y_val)\n",
        "    test_labels = torch.LongTensor(y_test)\n",
        "\n",
        "    print(\"\\n텐서 변환 완료\")\n",
        "    print(f\"  훈련 입력 shape: {train_inputs.shape}, dtype: {train_inputs.dtype}\")\n",
        "    print(f\"  훈련 레이블 shape: {train_labels.shape}, dtype: {train_labels.dtype}\")\n",
        "\n",
        "    return train_inputs, val_inputs, test_inputs, train_labels, val_labels, test_labels\n",
        "\n",
        "# 텐서 변환\n",
        "train_inputs, val_inputs, test_inputs, train_labels, val_labels, test_labels = numpy_to_tensor(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYl7CwcBWaB"
      },
      "source": [
        "## 6. 개선된 신경망 모델 정의\n",
        "\n",
        "### 모델 특징\n",
        "- **Batch Normalization**: 각 층의 출력을 정규화하여 학습 안정화\n",
        "- **3-Layer Architecture**: 입력층 → 은닉층1 → 은닉층2 → 출력층\n",
        "- **Dropout**: 과적합 방지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPHt78bEBWaB"
      },
      "outputs": [],
      "source": [
        "class AdvancedClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes, dropout_rate=0.4):\n",
        "        \"\"\"\n",
        "        고급 다중 분류 신경망\n",
        "\n",
        "        Args:\n",
        "            input_size: 입력 특성 수\n",
        "            hidden1_size: 첫 번째 은닉층 크기\n",
        "            hidden2_size: 두 번째 은닉층 크기\n",
        "            num_classes: 출력 클래스 수\n",
        "            dropout_rate: 드롭아웃 비율\n",
        "        \"\"\"\n",
        "        super(AdvancedClassifier, self).__init__()\n",
        "\n",
        "        # 첫 번째 블록: Linear → BatchNorm → ReLU → Dropout\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden1_size)  # 배치 정규화\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # 두 번째 블록\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # 출력층\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        순전파\n",
        "        \"\"\"\n",
        "        # 첫 번째 블록\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # 두 번째 블록\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # 출력층 (logits)\n",
        "        logits = self.fc3(x)\n",
        "        return logits\n",
        "\n",
        "# 모델 하이퍼파라미터\n",
        "input_size = train_inputs.shape[1]  # 64\n",
        "hidden1_size = 128\n",
        "hidden2_size = 64\n",
        "num_classes = 10  # 0~9\n",
        "dropout_rate = 0.4\n",
        "\n",
        "# 모델 생성\n",
        "model = AdvancedClassifier(input_size, hidden1_size, hidden2_size, num_classes, dropout_rate)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"모델 구조\")\n",
        "print(\"=\" * 60)\n",
        "print(model)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 파라미터 수 계산\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
        "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jH_71fBWaB"
      },
      "source": [
        "## 7. 손실 함수 및 옵티마이저"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnJtKX5gBWaB"
      },
      "outputs": [],
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저: Adam\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 학습률 스케줄러: 검증 손실이 개선되지 않으면 학습률 감소\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',           # 손실을 최소화\n",
        "    factor=0.5,           # 학습률을 0.5배로 감소\n",
        "    patience=10,          # 10 에포크 동안 개선 없으면 감소\n",
        "\n",
        ")\n",
        "\n",
        "print(f\"손실 함수: {criterion}\")\n",
        "print(f\"옵티마이저: {optimizer.__class__.__name__}\")\n",
        "print(f\"초기 학습률: {learning_rate}\")\n",
        "print(f\"학습률 스케줄러: ReduceLROnPlateau\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56OrgtrcBWaB"
      },
      "source": [
        "## 8. 평가 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27I6qD2nBWaB"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, inputs, labels):\n",
        "    \"\"\"\n",
        "    모델 평가 함수\n",
        "\n",
        "    Returns:\n",
        "        tuple: (loss, accuracy, predictions)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "      # _ : 최대값 >> 여기서는 인덱스만 필요하니깐 필요없어서 무시(_)\n",
        "      # predicted: 인덱스(클래스 번호)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        accuracy = correct / len(labels)\n",
        "\n",
        "    return loss.item(), accuracy, predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu7sWo-KBWaB"
      },
      "source": [
        "## 9. 학습 루프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf0ElS9SBWaB"
      },
      "outputs": [],
      "source": [
        "def train_with_early_stopping(model, train_inputs, train_labels, val_inputs, val_labels,\n",
        "                               num_epochs=300, patience=30, print_interval=20):\n",
        "    \"\"\"\n",
        "    Early Stopping을 포함한 학습 함수\n",
        "\n",
        "    Args:\n",
        "        model: 학습할 모델\n",
        "        train_inputs, train_labels: 훈련 데이터\n",
        "        val_inputs, val_labels: 검증 데이터\n",
        "        num_epochs: 최대 에포크 수\n",
        "        patience: Early Stopping을 위한 인내 에포크\n",
        "        print_interval: 출력 간격\n",
        "\n",
        "    Returns:\n",
        "        dict: 학습 이력\n",
        "    \"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"{'Epoch':^8} | {'Train Loss':^12} | {'Train Acc':^10} | {'Val Loss':^12} | {'Val Acc':^10} | {'Status':^12}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 학습 단계\n",
        "        model.train()\n",
        "\n",
        "        outputs = model(train_inputs)\n",
        "        loss = criterion(outputs, train_labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 평가 단계\n",
        "        train_loss, train_acc, _ = evaluate(model, train_inputs, train_labels)\n",
        "        val_loss, val_acc, _ = evaluate(model, val_inputs, val_labels)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # 학습률 스케줄러 업데이트\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early Stopping 체크\n",
        "        status = \"\"\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            status = \"✓ Best\"\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            status = f\"({epochs_no_improve}/{patience})\"\n",
        "\n",
        "        # 출력\n",
        "        if (epoch + 1) % print_interval == 0 or epoch == 0:\n",
        "            print(f\"{epoch+1:^8} | {train_loss:^12.4f} | {train_acc:^10.4f} | {val_loss:^12.4f} | {val_acc:^10.4f} | {status:^12}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"Early Stopping at Epoch {epoch+1}\")\n",
        "            print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "            break\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"학습 완료!\")\n",
        "\n",
        "    # 최고 성능 모델 복원\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"최고 성능 모델로 복원 (검증 손실: {best_val_loss:.4f})\")\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_accs': val_accs\n",
        "    }\n",
        "\n",
        "# 모델 학습\n",
        "history = train_with_early_stopping(\n",
        "    model,\n",
        "    train_inputs, train_labels,\n",
        "    val_inputs, val_labels,\n",
        "    num_epochs=300,\n",
        "    patience=30,\n",
        "    print_interval=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mb1XFJGBWaC"
      },
      "source": [
        "## 10. 학습 과정 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSqGv8haBWaC"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"\n",
        "    학습 이력 시각화\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Loss 그래프\n",
        "    axes[0].plot(history['train_losses'], label='Train Loss', linewidth=2.5, color='#3498db')\n",
        "    axes[0].plot(history['val_losses'], label='Validation Loss', linewidth=2.5, color='#e74c3c')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=13, fontweight='bold')\n",
        "    axes[0].set_ylabel('Loss', fontsize=13, fontweight='bold')\n",
        "    axes[0].set_title('Training and Validation Loss', fontsize=15, fontweight='bold')\n",
        "    axes[0].legend(fontsize=12, loc='upper right')\n",
        "    axes[0].grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    # Accuracy 그래프\n",
        "    axes[1].plot(history['train_accs'], label='Train Accuracy', linewidth=2.5, color='#3498db')\n",
        "    axes[1].plot(history['val_accs'], label='Validation Accuracy', linewidth=2.5, color='#e74c3c')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=13, fontweight='bold')\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=13, fontweight='bold')\n",
        "    axes[1].set_title('Training and Validation Accuracy', fontsize=15, fontweight='bold')\n",
        "    axes[1].legend(fontsize=12, loc='lower right')\n",
        "    axes[1].grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 시각화\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9exM8JOcBWaC"
      },
      "source": [
        "## 11. 테스트 데이터 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv6ursAhBWaC"
      },
      "outputs": [],
      "source": [
        "# 테스트 평가\n",
        "test_loss, test_acc, test_predictions = evaluate(model, test_inputs, test_labels)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"최종 테스트 결과\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"테스트 손실: {test_loss:.4f}\")\n",
        "print(f\"테스트 정확도: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scpFn03eBWaC"
      },
      "source": [
        "## 12. 혼동 행렬 (Confusion Matrix) 시각화\n",
        "\n",
        "### 혼동 행렬이란?\n",
        "- 각 클래스별 예측 성능을 한눈에 파악할 수 있는 표\n",
        "- 행(row): 실제 레이블\n",
        "- 열(column): 예측 레이블\n",
        "- 대각선: 정확히 예측한 샘플 수\n",
        "- 대각선 외: 잘못 예측한 샘플 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ujnP-hBWaC"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    혼동 행렬 시각화 함수\n",
        "\n",
        "    Args:\n",
        "        true_labels: 실제 레이블 (텐서)\n",
        "        predicted_labels: 예측 레이블 (텐서)\n",
        "    \"\"\"\n",
        "    # 텐서를 NumPy로 변환\n",
        "    y_true = true_labels.numpy()\n",
        "    y_pred = predicted_labels.numpy()\n",
        "\n",
        "    # 혼동 행렬 계산\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,           # 숫자 표시\n",
        "        fmt='d',              # 정수 형식\n",
        "        cmap='Blues',         # 색상\n",
        "        square=True,          # 정사각형 셀\n",
        "        cbar_kws={'shrink': 0.8},\n",
        "        linewidths=1,\n",
        "        linecolor='gray'\n",
        "    )\n",
        "\n",
        "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
        "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "    # 축 레이블 설정\n",
        "    plt.xticks(np.arange(10) + 0.5, range(10), fontsize=11)\n",
        "    plt.yticks(np.arange(10) + 0.5, range(10), fontsize=11, rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 클래스별 정확도 출력\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"클래스별 정확도\")\n",
        "    print(\"=\" * 60)\n",
        "    for i in range(10):\n",
        "        class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
        "        print(f\"숫자 {i}: {class_acc:.4f} ({class_acc*100:.2f}%) - {cm[i, i]}/{cm[i].sum()}개\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plot_confusion_matrix(test_labels, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4l1yR1DBWaC"
      },
      "source": [
        "## 13. 상세 성능 지표 (Classification Report)\n",
        "\n",
        "### 주요 지표 설명\n",
        "- **Precision (정밀도)**: 양성으로 예측한 것 중 실제 양성의 비율\n",
        "  - \"이 숫자가 5라고 예측했을 때, 실제로 5일 확률\"\n",
        "  - Precision = TP / (TP + FP)\n",
        "\n",
        "- **Recall (재현율)**: 실제 양성 중 양성으로 예측한 비율\n",
        "  - \"실제 5인 숫자 중에서 5로 올바르게 예측한 비율\"\n",
        "  - Recall = TP / (TP + FN)\n",
        "\n",
        "- **F1-Score**: Precision과 Recall의 조화 평균\n",
        "  - F1 = 2 × (Precision × Recall) / (Precision + Recall)\n",
        "\n",
        "- **Support**: 각 클래스의 실제 샘플 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKuY-NICBWaC"
      },
      "outputs": [],
      "source": [
        "def print_classification_report(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    상세 성능 보고서 출력\n",
        "    \"\"\"\n",
        "    y_true = true_labels.numpy()\n",
        "    y_pred = predicted_labels.numpy()\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"상세 성능 보고서 (Classification Report)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=[f'Digit {i}' for i in range(10)],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    # 전체 지표\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"전체 평균 지표 (Macro Average)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# 성능 보고서 출력\n",
        "print_classification_report(test_labels, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fXuwE8BWaC"
      },
      "source": [
        "## 14. 잘못 예측한 샘플 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIiC0lckBWaC"
      },
      "outputs": [],
      "source": [
        "def analyze_misclassifications(true_labels, predicted_labels, test_data, n_samples=10):\n",
        "    \"\"\"\n",
        "    잘못 예측한 샘플 분석 및 시각화\n",
        "\n",
        "    Args:\n",
        "        true_labels: 실제 레이블\n",
        "        predicted_labels: 예측 레이블\n",
        "        test_data: 테스트 입력 데이터 (표준화 전)\n",
        "        n_samples: 표시할 샘플 수\n",
        "    \"\"\"\n",
        "    y_true = true_labels.numpy()\n",
        "    y_pred = predicted_labels.numpy()\n",
        "\n",
        "    # 잘못 예측한 인덱스 찾기\n",
        "    misclassified_indices = np.where(y_true != y_pred)[0]\n",
        "\n",
        "    print(f\"\\n총 {len(misclassified_indices)}개의 샘플이 잘못 예측되었습니다.\")\n",
        "    print(f\"오분류율: {len(misclassified_indices)/len(y_true)*100:.2f}%\\n\")\n",
        "\n",
        "    if len(misclassified_indices) == 0:\n",
        "        print(\"완벽한 예측! 잘못 예측한 샘플이 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 랜덤 샘플 선택\n",
        "    sample_size = min(n_samples, len(misclassified_indices))\n",
        "    sample_indices = np.random.choice(misclassified_indices, sample_size, replace=False)\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        # 이미지 데이터 복원 (8x8)\n",
        "        image = test_data[idx].reshape(8, 8)\n",
        "\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(\n",
        "            f'True: {y_true[idx]} | Pred: {y_pred[idx]}',\n",
        "            fontsize=11,\n",
        "            color='red',\n",
        "            fontweight='bold'\n",
        "        )\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle('Misclassified Samples', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 오분류 샘플 분석\n",
        "analyze_misclassifications(test_labels, test_predictions, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvWheDxtBWaC"
      },
      "source": [
        "## 15. 모델 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSaVNxWzBWaD"
      },
      "outputs": [],
      "source": [
        "def save_model(model, filepath='digit_classifier.pth'):\n",
        "    \"\"\"\n",
        "    모델을 파일로 저장\n",
        "\n",
        "    Args:\n",
        "        model: 저장할 모델\n",
        "        filepath: 저장 경로\n",
        "    \"\"\"\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'model_architecture': {\n",
        "            'input_size': input_size,\n",
        "            'hidden1_size': hidden1_size,\n",
        "            'hidden2_size': hidden2_size,\n",
        "            'num_classes': num_classes,\n",
        "            'dropout_rate': dropout_rate\n",
        "        }\n",
        "    }, filepath)\n",
        "    print(f\"\\n모델이 '{filepath}'에 저장되었습니다.\")\n",
        "\n",
        "def load_model(filepath='digit_classifier.pth'):\n",
        "    \"\"\"\n",
        "    저장된 모델 불러오기\n",
        "\n",
        "    Args:\n",
        "        filepath: 모델 파일 경로\n",
        "\n",
        "    Returns:\n",
        "        loaded_model: 불러온 모델\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(filepath)\n",
        "    arch = checkpoint['model_architecture']\n",
        "\n",
        "    # 모델 재생성\n",
        "    loaded_model = AdvancedClassifier(\n",
        "        arch['input_size'],\n",
        "        arch['hidden1_size'],\n",
        "        arch['hidden2_size'],\n",
        "        arch['num_classes'],\n",
        "        arch['dropout_rate']\n",
        "    )\n",
        "\n",
        "    # 가중치 로드\n",
        "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    loaded_model.eval()\n",
        "\n",
        "    print(f\"\\n모델이 '{filepath}'에서 불러와졌습니다.\")\n",
        "    return loaded_model\n",
        "\n",
        "# 모델 저장\n",
        "save_model(model, 'digit_classifier.pth')\n",
        "\n",
        "# 모델 불러오기 테스트\n",
        "loaded_model = load_model('digit_classifier.pth')\n",
        "\n",
        "# 불러온 모델로 테스트\n",
        "test_loss_loaded, test_acc_loaded, _ = evaluate(loaded_model, test_inputs, test_labels)\n",
        "print(f\"\\n불러온 모델의 테스트 정확도: {test_acc_loaded:.4f} ({test_acc_loaded*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Ukuj_YBWaD"
      },
      "source": [
        "## 16. 실전 예측 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeEezjwbBWaD"
      },
      "outputs": [],
      "source": [
        "def predict_digit(model, scaler, digit_image):\n",
        "    \"\"\"\n",
        "    새로운 손글씨 숫자 이미지를 예측하는 함수\n",
        "\n",
        "    Args:\n",
        "        model: 학습된 모델\n",
        "        scaler: 표준화에 사용한 scaler\n",
        "        digit_image: 8x8 픽셀 이미지 (NumPy 배열)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (predicted_digit, probabilities)\n",
        "    \"\"\"\n",
        "    # 이미지를 1D 벡터로 변환\n",
        "    digit_vector = digit_image.flatten().reshape(1, -1)\n",
        "\n",
        "    # 표준화\n",
        "    digit_scaled = scaler.transform(digit_vector)\n",
        "\n",
        "    # 텐서 변환\n",
        "    digit_tensor = torch.FloatTensor(digit_scaled)\n",
        "\n",
        "    # 예측\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(digit_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)[0]\n",
        "        predicted_digit = torch.argmax(probabilities).item()\n",
        "\n",
        "    return predicted_digit, probabilities.numpy()\n",
        "\n",
        "# 테스트 샘플로 예측 테스트\n",
        "sample_idx = np.random.randint(0, len(X_test))\n",
        "sample_image = X_test[sample_idx].reshape(8, 8)\n",
        "true_digit = y_test[sample_idx]\n",
        "\n",
        "# 예측\n",
        "predicted_digit, probs = predict_digit(model, scaler, sample_image)\n",
        "\n",
        "# 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# 이미지 표시\n",
        "axes[0].imshow(sample_image, cmap='gray')\n",
        "axes[0].set_title(f'True: {true_digit} | Predicted: {predicted_digit}',\n",
        "                  fontsize=13, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# 확률 분포\n",
        "axes[1].bar(range(10), probs, color='steelblue', alpha=0.7)\n",
        "axes[1].set_xlabel('Digit', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Prediction Probabilities', fontsize=13, fontweight='bold')\n",
        "axes[1].set_xticks(range(10))\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n각 숫자별 예측 확률:\")\n",
        "for i, prob in enumerate(probs):\n",
        "    print(f\"  숫자 {i}: {prob:.4f} ({prob*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA89aKDBBWaD"
      },
      "source": [
        "## 17. 핵심 개념 정리\n",
        "\n",
        "### 1. Batch Normalization\n",
        "```python\n",
        "# 각 층의 출력을 정규화하여 학습 안정화\n",
        "# 장점:\n",
        "# - 더 높은 학습률 사용 가능\n",
        "# - 초기 가중치에 덜 민감\n",
        "# - 정규화 효과 (Dropout과 유사)\n",
        "```\n",
        "\n",
        "### 2. Learning Rate Scheduler\n",
        "```python\n",
        "# 학습 중 학습률을 동적으로 조정\n",
        "# ReduceLROnPlateau: 검증 손실 개선이 멈추면 학습률 감소\n",
        "# 효과: 세밀한 최적화 가능, 로컬 미니멈 탈출\n",
        "```\n",
        "\n",
        "### 3. Early Stopping\n",
        "```python\n",
        "# 검증 손실이 개선되지 않으면 학습 조기 종료\n",
        "# 장점:\n",
        "# - 과적합 방지\n",
        "# - 학습 시간 절약\n",
        "# - 최적 모델 자동 선택\n",
        "```\n",
        "\n",
        "### 4. 혼동 행렬 해석\n",
        "```python\n",
        "# 대각선: 올바른 예측\n",
        "# 비대각선: 잘못된 예측\n",
        "#\n",
        "# 예시: [실제: 8, 예측: 3]이 많다면?\n",
        "# → 8과 3이 시각적으로 유사할 가능성\n",
        "```\n",
        "\n",
        "### 5. Precision vs Recall\n",
        "```python\n",
        "# Precision (정밀도):\n",
        "# \"예측이 얼마나 정확한가?\"\n",
        "# 스팸 필터: 정상 메일을 스팸으로 잘못 분류하면 안 됨\n",
        "#\n",
        "# Recall (재현율):\n",
        "# \"실제 양성을 얼마나 잘 찾아내는가?\"\n",
        "# 질병 진단: 환자를 놓치면 안 됨\n",
        "```\n",
        "\n",
        "### 6. F1-Score\n",
        "```python\n",
        "# Precision과 Recall의 균형\n",
        "# 불균형 데이터셋에서 유용\n",
        "# 1에 가까울수록 좋은 성능\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}