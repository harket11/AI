{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ],
      "metadata": {
        "id": "KHSXxYuKwt6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì„¤ì¹˜ í›„ ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘"
      ],
      "metadata": {
        "id": "8eljo2pJxI1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# í°íŠ¸ ê´€ë ¨ ìš©ë„\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# ë‚˜ëˆ” ê³ ë”• í°íŠ¸ì˜ ê²½ë¡œ ëª…ì‹œ\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()"
      ],
      "metadata": {
        "id": "mDJo07qGwvFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ë³¸ ì„¤ì •ê°’ ë³€ê²½\n",
        "\n",
        "# ê¸°ë³¸ í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = font_name\n",
        "\n",
        "# ê¸°ë³¸ í°íŠ¸ ì‚¬ì´ì¦ˆ ë³€ê²½\n",
        "# í•„ìš”ì— ë”°ë¼ ì„¤ì •í•  ë•ŒëŠ”, plt.legend(fontsize=14)\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# ê¸°ë³¸ ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ ë³€ê²½\n",
        "# í•„ìš”ì— ë”°ë¼ ì„¤ì •í•  ë•ŒëŠ”, plt.figure(figsize=(6,6))\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# ê¸°ë³¸ ê·¸ë¦¬ë“œ í‘œì‹œ\n",
        "# í•„ìš”ì— ë”°ë¼ ì„¤ì •í•  ë•ŒëŠ”, plt.grid()\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ì •ìƒ ì¶œë ¥\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "U6fJdjZ5w1jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.eye(20)"
      ],
      "metadata": {
        "id": "5b8yeQKAkdit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.ones(20, 1)\n",
        "torch.ones(1) * 1.5"
      ],
      "metadata": {
        "id": "VvFgbAeOqXQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "10ì°¨ìˆ˜: ê³ ê¸‰ í‰ê°€ì§€í‘œ ë° í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
        "- í˜¼ë™í–‰ë ¬ í•´ì„\n",
        "- Precision, Recall, F1 (í´ë˜ìŠ¤ë³„/ë§ˆì´í¬ë¡œ/ë§¤í¬ë¡œ)\n",
        "- ROC-AUC (One-vs-Rest)\n",
        "- Calibration & ì˜¨ë„ ìŠ¤ì¼€ì¼ë§\n",
        "- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    roc_curve, auc,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from collections import Counter\n",
        "\n",
        "# ì¬í˜„ì„± ì„¤ì •\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ===================================================================\n",
        "# 1. ë¶ˆê· í˜• ë°ì´í„°ì…‹\n",
        "# ===================================================================\n",
        "class ImbalancedDataset(Dataset):\n",
        "    def __init__(self, n_samples=2000, n_features=20, n_classes=4,\n",
        "                 imbalance_ratio=[0.5, 0.3, 0.15, 0.05]):\n",
        "        self.n_classes = n_classes\n",
        "        samples_per_class = [int(n_samples * ratio) for ratio in imbalance_ratio]\n",
        "\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "\n",
        "        for class_idx in range(n_classes):\n",
        "            n = samples_per_class[class_idx]\n",
        "            mean = np.random.randn(n_features) * (class_idx + 1)\n",
        "            cov = np.eye(n_features) * (0.5 + class_idx * 0.2)\n",
        "            X_class = np.random.multivariate_normal(mean, cov, n)\n",
        "            y_class = np.full(n, class_idx)\n",
        "\n",
        "            X_list.append(X_class)\n",
        "            y_list.append(y_class)\n",
        "\n",
        "        self.X = torch.FloatTensor(np.vstack(X_list))\n",
        "        self.y = torch.LongTensor(np.hstack(y_list))\n",
        "\n",
        "        class_counts = Counter(self.y.numpy())\n",
        "        print(f\"\\nì „ì²´ í´ë˜ìŠ¤ ë¶„í¬: {dict(sorted(class_counts.items()))}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ===================================================================\n",
        "# 2. ëª¨ë¸ ì •ì˜\n",
        "# ===================================================================\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=20, hidden_dim=64, n_classes=4):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# ===================================================================\n",
        "# 3. ì˜¨ë„ ìŠ¤ì¼€ì¼ë§\n",
        "# ===================================================================\n",
        "class TemperatureScaling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, logits):\n",
        "        return logits / self.temperature\n",
        "\n",
        "    def calibrate(self, model, val_loader, device, max_iter=50):\n",
        "        nll_criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.LBFGS([self.temperature], lr=0.01, max_iter=max_iter)\n",
        "        # LBFGS (Limited Memory Broyden Fletcher Goldfarb Shanno optimization\n",
        "        # 2ì°¨ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ : ë‰´í„´ ë°©ë²•ì˜ ê·¼ì°¨ í˜•íƒœ (ê·¼ì‚¬ì¹˜)\n",
        "        # >> ì´ì „ ë‹¨ê³„ ë³€í™”ëŸ‰ì„ ì‚¬ìš©, í—¤ì‹œì•ˆ(Hesian) ê·¼ì‚¬ì¹˜\n",
        "        # >> ì‹¤ì œ ìˆ˜ì¹˜í•´ì„ì— ë“¤ì–´ê°€ëŠ” í—¤ì‹œì•ˆì„ ì§ì ‘ êµ¬í•˜ì§€ ì•Šê³  ì ì§„ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë‚˜ê°€ì„œ ê·¼ì‚¬ì¹˜ êµ¬í•œë‹¤\n",
        "        # >> ìµœê·¼ 10ë‹¨ê³„ ì—…ë°ì´íŠ¸ëœ ì •ë³´ë§Œ ì €ì¥í•´ì„œ ê·¼ì‚¬ì¹˜ë¥¼ êµ¬í•¨ >> ì œí•œëœ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "        # (ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì— ì‚¬ìš©í•˜ëŠ” Adam, SGD 1ì°¨ ë¯¸ë¶„: gradient)\n",
        "\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                logits = model(inputs)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(labels)\n",
        "\n",
        "        logits = torch.cat(logits_list)\n",
        "        labels = torch.cat(labels_list)\n",
        "\n",
        "        def eval_loss():\n",
        "            optimizer.zero_grad()\n",
        "            loss = nll_criterion(self.forward(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "\n",
        "        optimizer.step(eval_loss)\n",
        "\n",
        "        print(f\"ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: T = {self.temperature.item():.3f}\")\n",
        "        return self.temperature.item()\n",
        "\n",
        "# ===================================================================\n",
        "# 4. í˜¼ë™í–‰ë ¬ ì‹œê°í™”\n",
        "# ===================================================================\n",
        "def plot_confusion_matrix_with_analysis(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # í˜¼ë™í–‰ë ¬\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                ax=axes[0])\n",
        "    axes[0].set_title('í˜¼ë™í–‰ë ¬ (Confusion Matrix)', fontsize=14, pad=10)\n",
        "    axes[0].set_ylabel('ì‹¤ì œ í´ë˜ìŠ¤', fontsize=11)\n",
        "    axes[0].set_xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤', fontsize=11)\n",
        "\n",
        "    # ì˜¤ë¥˜ ë¶„ì„\n",
        "    cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
        "\n",
        "    error_analysis = []\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            if i != j and cm[i, j] > 0:\n",
        "                error_analysis.append({\n",
        "                    'True': class_names[i],\n",
        "                    'Pred': class_names[j],\n",
        "                    'Count': cm[i, j],\n",
        "                    'Rate': cm_normalized[i, j]\n",
        "                })\n",
        "\n",
        "    if len(error_analysis) > 0:\n",
        "        error_analysis.sort(key=lambda x: x['Rate'], reverse=True)\n",
        "        top_errors = error_analysis[:min(5, len(error_analysis))]\n",
        "        error_labels = [f\"{e['True']}â†’{e['Pred']}\" for e in top_errors]\n",
        "        error_rates = [e['Rate'] * 100 for e in top_errors]\n",
        "\n",
        "        axes[1].barh(error_labels, error_rates, color='coral')\n",
        "        axes[1].set_xlabel('ì˜¤ë¥˜ìœ¨ (%)', fontsize=11)\n",
        "        axes[1].set_title('ì£¼ìš” ì˜¤ë¥˜ ìœ í˜•', fontsize=14, pad=10)\n",
        "        axes[1].grid(axis='x', alpha=0.3)\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'ì™„ë²½í•œ ë¶„ë¥˜!',\n",
        "                    transform=axes[1].transAxes, ha='center', va='center',\n",
        "                    fontsize=16)\n",
        "        axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return cm\n",
        "\n",
        "# ===================================================================\n",
        "# 5. ìƒì„¸ í‰ê°€ì§€í‘œ\n",
        "# ===================================================================\n",
        "def calculate_detailed_metrics(y_true, y_pred, y_proba, class_names):\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    metrics_avg = {\n",
        "        'macro': precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[:3],\n",
        "        'micro': precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)[:3],\n",
        "        'weighted': precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[:3]\n",
        "    }\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # (1) í´ë˜ìŠ¤ë³„ ì§€í‘œ\n",
        "    x = np.arange(len(class_names))\n",
        "    width = 0.25\n",
        "\n",
        "    axes[0, 0].bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
        "    axes[0, 0].bar(x, recall, width, label='Recall', alpha=0.8)\n",
        "    axes[0, 0].bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
        "    axes[0, 0].set_xlabel('í´ë˜ìŠ¤', fontsize=11)\n",
        "    axes[0, 0].set_ylabel('ì ìˆ˜', fontsize=11)\n",
        "    axes[0, 0].set_title('í´ë˜ìŠ¤ë³„ í‰ê°€ì§€í‘œ', fontsize=13, pad=10)\n",
        "    axes[0, 0].set_xticks(x)\n",
        "    axes[0, 0].set_xticklabels(class_names)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    axes[0, 0].set_ylim([0, 1.1])\n",
        "\n",
        "    # (2) í‰ê·  ë°©ì‹ ë¹„êµ\n",
        "    avg_types = ['Macro', 'Micro', 'Weighted']\n",
        "    avg_precisions = [metrics_avg['macro'][0], metrics_avg['micro'][0], metrics_avg['weighted'][0]]\n",
        "    avg_recalls = [metrics_avg['macro'][1], metrics_avg['micro'][1], metrics_avg['weighted'][1]]\n",
        "    avg_f1s = [metrics_avg['macro'][2], metrics_avg['micro'][2], metrics_avg['weighted'][2]]\n",
        "\n",
        "    x_avg = np.arange(len(avg_types))\n",
        "    axes[0, 1].bar(x_avg - width, avg_precisions, width, label='Precision', alpha=0.8)\n",
        "    axes[0, 1].bar(x_avg, avg_recalls, width, label='Recall', alpha=0.8)\n",
        "    axes[0, 1].bar(x_avg + width, avg_f1s, width, label='F1-Score', alpha=0.8)\n",
        "    axes[0, 1].set_xlabel('í‰ê·  ë°©ì‹', fontsize=11)\n",
        "    axes[0, 1].set_ylabel('ì ìˆ˜', fontsize=11)\n",
        "    axes[0, 1].set_title('í‰ê·  ë°©ì‹ë³„ ë¹„êµ', fontsize=13, pad=10)\n",
        "    axes[0, 1].set_xticks(x_avg)\n",
        "    axes[0, 1].set_xticklabels(avg_types)\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "    axes[0, 1].set_ylim([0, 1.1])\n",
        "\n",
        "    # (3) Support vs F1\n",
        "    axes[1, 0].scatter(support, f1, s=100, alpha=0.6, c=range(len(class_names)), cmap='viridis')\n",
        "    for i, name in enumerate(class_names):\n",
        "        axes[1, 0].annotate(name, (support[i], f1[i]),\n",
        "                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "    axes[1, 0].set_xlabel('ìƒ˜í”Œ ìˆ˜', fontsize=11)\n",
        "    axes[1, 0].set_ylabel('F1-Score', fontsize=11)\n",
        "    axes[1, 0].set_title('í´ë˜ìŠ¤ ë¶ˆê· í˜•ê³¼ ì„±ëŠ¥', fontsize=13, pad=10)\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "    # (4) ì„¤ëª…\n",
        "    explanation = (\n",
        "        \"ğŸ“Š í‰ê·  ë°©ì‹:\\n\\n\"\n",
        "        \"â€¢ Macro: í´ë˜ìŠ¤ë³„ í‰ê· \\n\"\n",
        "        \"  ëª¨ë“  í´ë˜ìŠ¤ ë™ë“±\\n\\n\"\n",
        "        \"â€¢ Micro: ì „ì²´ ìƒ˜í”Œ ê¸°ì¤€\\n\"\n",
        "        \"  ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì˜í–¥\\n\\n\"\n",
        "        \"â€¢ Weighted: ê°€ì¤‘ í‰ê· \\n\"\n",
        "        \"  ì‹¤ì œ ë¶„í¬ ë°˜ì˜\"\n",
        "    )\n",
        "    axes[1, 1].text(0.1, 0.5, explanation, transform=axes[1, 1].transAxes,\n",
        "                   fontsize=11, verticalalignment='center',\n",
        "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ë¶„ë¥˜ ë¦¬í¬íŠ¸\")\n",
        "    print(\"=\"*60)\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names,\n",
        "                               digits=3, zero_division=0))\n",
        "\n",
        "    return metrics_avg\n",
        "\n",
        "# ===================================================================\n",
        "# 6. ROC-AUC\n",
        "# ===================================================================\n",
        "def plot_roc_curves_multiclass(y_true, y_proba, class_names):\n",
        "    n_classes = len(class_names)\n",
        "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_proba[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_proba.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= n_classes\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # í´ë˜ìŠ¤ë³„ ROC\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, n_classes))\n",
        "    for i, color in enumerate(colors):\n",
        "        axes[0].plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                    label=f'{class_names[i]} (AUC={roc_auc[i]:.3f})')\n",
        "\n",
        "    axes[0].plot([0, 1], [0, 1], 'k--', lw=1, label='Random')\n",
        "    axes[0].set_xlim([0.0, 1.0])\n",
        "    axes[0].set_ylim([0.0, 1.05])\n",
        "    axes[0].set_xlabel('False Positive Rate', fontsize=11)\n",
        "    axes[0].set_ylabel('True Positive Rate', fontsize=11)\n",
        "    axes[0].set_title('í´ë˜ìŠ¤ë³„ ROC (One-vs-Rest)', fontsize=13, pad=10)\n",
        "    axes[0].legend(loc=\"lower right\", fontsize=9)\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Macro/Micro\n",
        "    axes[1].plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                label=f'Micro-avg (AUC={roc_auc[\"micro\"]:.3f})',\n",
        "                color='deeppink', linestyle=':', linewidth=3)\n",
        "    axes[1].plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "                label=f'Macro-avg (AUC={roc_auc[\"macro\"]:.3f})',\n",
        "                color='navy', linestyle=':', linewidth=3)\n",
        "    axes[1].plot([0, 1], [0, 1], 'k--', lw=1, label='Random')\n",
        "\n",
        "    axes[1].set_xlim([0.0, 1.0])\n",
        "    axes[1].set_ylim([0.0, 1.05])\n",
        "    axes[1].set_xlabel('False Positive Rate', fontsize=11)\n",
        "    axes[1].set_ylabel('True Positive Rate', fontsize=11)\n",
        "    axes[1].set_title('í‰ê·  ROC', fontsize=13, pad=10)\n",
        "    axes[1].legend(loc=\"lower right\", fontsize=10)\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ROC-AUC ì ìˆ˜\")\n",
        "    print(\"=\"*60)\n",
        "    for i, name in enumerate(class_names):\n",
        "        print(f\"{name:15s}: {roc_auc[i]:.4f}\")\n",
        "    print(f\"{'Micro-avg':15s}: {roc_auc['micro']:.4f}\")\n",
        "    print(f\"{'Macro-avg':15s}: {roc_auc['macro']:.4f}\")\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "# ===================================================================\n",
        "# 7. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (IndexError ì™„ì „ í•´ê²°)\n",
        "# ===================================================================\n",
        "def get_labels_from_loader(loader):\n",
        "    \"\"\"DataLoaderì—ì„œ ëª¨ë“  ë ˆì´ë¸” ì¶”ì¶œ\"\"\"\n",
        "    labels = []\n",
        "    for _, batch_labels in loader:\n",
        "        labels.extend(batch_labels.numpy().tolist())\n",
        "    return labels\n",
        "\n",
        "def get_class_weights(train_loader, n_classes):\n",
        "    \"\"\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\"\"\"\n",
        "    labels = get_labels_from_loader(train_loader)\n",
        "    class_counts = Counter(labels)\n",
        "    n_samples = len(labels)\n",
        "\n",
        "    weights = torch.FloatTensor([\n",
        "        n_samples / (n_classes * class_counts.get(i, 1))\n",
        "        for i in range(n_classes)\n",
        "    ])\n",
        "\n",
        "    print(f\"\\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬: {dict(sorted(class_counts.items()))}\")\n",
        "    print(f\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {weights.numpy()}\")\n",
        "    return weights\n",
        "\n",
        "def create_weighted_sampler(train_loader):\n",
        "    \"\"\"Oversamplingì„ ìœ„í•œ Sampler\"\"\"\n",
        "    labels = get_labels_from_loader(train_loader)\n",
        "    class_counts = Counter(labels)\n",
        "\n",
        "    sample_weights = [1.0 / class_counts[label] for label in labels]\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    return sampler\n",
        "\n",
        "class AugmentedWrapper(Dataset):\n",
        "    \"\"\"ë°ì´í„° ì¦ê°• Wrapper\"\"\"\n",
        "    def __init__(self, dataset, augment_ratio=0.5, noise_std=0.15):\n",
        "        self.dataset = dataset\n",
        "        self.base_len = len(dataset)\n",
        "        self.augment_len = int(self.base_len * augment_ratio)\n",
        "        self.total_len = self.base_len + self.augment_len\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < self.base_len:\n",
        "            return self.dataset[idx]\n",
        "        else:\n",
        "            # ì¦ê°• ìƒ˜í”Œ\n",
        "            base_idx = (idx - self.base_len) % self.base_len\n",
        "            x, y = self.dataset[base_idx]\n",
        "            noise = torch.randn_like(x) * self.noise_std\n",
        "            return x + noise, y\n",
        "\n",
        "# ===================================================================\n",
        "# 8. í•™ìŠµ ë° í‰ê°€\n",
        "# ===================================================================\n",
        "def train_model(model, train_loader, criterion, optimizer, device, epochs=30):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = epoch_loss / len(train_loader)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "            all_labels.extend(labels.numpy().tolist())\n",
        "            all_probs.extend(probs.cpu().numpy().tolist())\n",
        "\n",
        "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
        "\n",
        "# ===================================================================\n",
        "# 9. ë©”ì¸ ì‹¤í–‰\n",
        "# ===================================================================\n",
        "def main():\n",
        "    print(\"=\"*70)\n",
        "    print(\"10ì°¨ìˆ˜: ê³ ê¸‰ í‰ê°€ì§€í‘œ ë° í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\në””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "    # ë°ì´í„° ìƒì„±\n",
        "    full_dataset = ImbalancedDataset(\n",
        "        n_samples=2000, n_features=20, n_classes=4,\n",
        "        imbalance_ratio=[0.5, 0.3, 0.15, 0.05]\n",
        "    )\n",
        "\n",
        "    # ë¶„í• \n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        full_dataset, [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    class_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3']\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # ===============================================================\n",
        "    # ë°©ë²• 1: Weighted Loss\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ë°©ë²• 1: Weighted Loss\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    train_loader_normal = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    class_weights = get_class_weights(train_loader_normal, n_classes=4).to(device)\n",
        "\n",
        "    model1 = MultiClassClassifier(20, 64, 4).to(device)\n",
        "    criterion_weighted = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"\\n[í•™ìŠµ ì‹œì‘]\")\n",
        "    train_model(model1, train_loader_normal, criterion_weighted, optimizer1, device, 30)\n",
        "\n",
        "    print(\"\\n[í‰ê°€]\")\n",
        "    y_true, y_pred, y_proba = evaluate_model(model1, test_loader, device)\n",
        "\n",
        "    print(\"\\n1. í˜¼ë™í–‰ë ¬\")\n",
        "    plot_confusion_matrix_with_analysis(y_true, y_pred, class_names)\n",
        "\n",
        "    print(\"\\n2. ìƒì„¸ ì§€í‘œ\")\n",
        "    calculate_detailed_metrics(y_true, y_pred, y_proba, class_names)\n",
        "\n",
        "    print(\"\\n3. ROC-AUC\")\n",
        "    plot_roc_curves_multiclass(y_true, y_proba, class_names)\n",
        "\n",
        "    # ===============================================================\n",
        "    # ë°©ë²• 2: Oversampling\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ë°©ë²• 2: Oversampling\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ë¨¼ì € ì¼ë°˜ loaderë¡œ ë ˆì´ë¸” ìˆ˜ì§‘ í›„ sampler ìƒì„±\n",
        "    temp_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "    sampler = create_weighted_sampler(temp_loader)\n",
        "    train_loader_oversampled = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
        "\n",
        "    model2 = MultiClassClassifier(20, 64, 4).to(device)\n",
        "    criterion_normal = nn.CrossEntropyLoss()\n",
        "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"\\n[í•™ìŠµ ì‹œì‘]\")\n",
        "    train_model(model2, train_loader_oversampled, criterion_normal, optimizer2, device, 30)\n",
        "\n",
        "    print(\"\\n[í‰ê°€]\")\n",
        "    y_true2, y_pred2, y_proba2 = evaluate_model(model2, test_loader, device)\n",
        "\n",
        "    print(\"\\ní˜¼ë™í–‰ë ¬\")\n",
        "    plot_confusion_matrix_with_analysis(y_true2, y_pred2, class_names)\n",
        "\n",
        "    # ===============================================================\n",
        "    # ë°©ë²• 3: Data Augmentation\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ë°©ë²• 3: Data Augmentation\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    augmented_dataset = AugmentedWrapper(train_dataset, augment_ratio=0.5, noise_std=0.15)\n",
        "    train_loader_augmented = DataLoader(augmented_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    model3 = MultiClassClassifier(20, 64, 4).to(device)\n",
        "    optimizer3 = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
        "\n",
        "    print(f\"\\nì¦ê°• í›„ ë°ì´í„° í¬ê¸°: {len(augmented_dataset)} (ì›ë³¸: {len(train_dataset)})\")\n",
        "    print(\"\\n[í•™ìŠµ ì‹œì‘]\")\n",
        "    train_model(model3, train_loader_augmented, criterion_normal, optimizer3, device, 30)\n",
        "\n",
        "    print(\"\\n[í‰ê°€]\")\n",
        "    y_true3, y_pred3, y_proba3 = evaluate_model(model3, test_loader, device)\n",
        "\n",
        "    print(\"\\ní˜¼ë™í–‰ë ¬\")\n",
        "    plot_confusion_matrix_with_analysis(y_true3, y_pred3, class_names)\n",
        "\n",
        "    # ===============================================================\n",
        "    # 4. Temperature Scaling\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"4. Temperature Scaling\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    temp_scaler = TemperatureScaling().to(device)\n",
        "    temperature = temp_scaler.calibrate(model1, test_loader, device)\n",
        "\n",
        "    model1.eval()\n",
        "    all_probs_before = []\n",
        "    all_probs_after = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            logits = model1(inputs)\n",
        "\n",
        "            probs_before = F.softmax(logits, dim=1)\n",
        "            probs_after = F.softmax(temp_scaler(logits), dim=1)\n",
        "\n",
        "            all_probs_before.extend(probs_before.cpu().numpy().tolist())\n",
        "            all_probs_after.extend(probs_after.cpu().numpy().tolist())\n",
        "\n",
        "    all_probs_before = np.array(all_probs_before)\n",
        "    all_probs_after = np.array(all_probs_after)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    max_probs_before = all_probs_before.max(axis=1)\n",
        "    max_probs_after = all_probs_after.max(axis=1)\n",
        "\n",
        "    axes[0].hist(max_probs_before, bins=20, alpha=0.7, edgecolor='black')\n",
        "    axes[0].set_xlabel('ìµœëŒ€ í™•ë¥ ', fontsize=11)\n",
        "    axes[0].set_ylabel('ë¹ˆë„', fontsize=11)\n",
        "    axes[0].set_title(f'ë³´ì • ì „ (í‰ê· : {max_probs_before.mean():.3f})', fontsize=13)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    axes[1].hist(max_probs_after, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
        "    axes[1].set_xlabel('ìµœëŒ€ í™•ë¥ ', fontsize=11)\n",
        "    axes[1].set_ylabel('ë¹ˆë„', fontsize=11)\n",
        "    axes[1].set_title(f'ë³´ì • í›„ (í‰ê· : {max_probs_after.mean():.3f}, T={temperature:.3f})', fontsize=13)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ===============================================================\n",
        "    # 5. ë°©ë²• ë¹„êµ\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"5. ë°©ë²• ë¹„êµ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    _, _, f1_1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
        "    _, _, f1_2, _ = precision_recall_fscore_support(y_true2, y_pred2, average='macro', zero_division=0)\n",
        "    _, _, f1_3, _ = precision_recall_fscore_support(y_true3, y_pred3, average='macro', zero_division=0)\n",
        "\n",
        "    methods = ['Weighted Loss', 'Oversampling', 'Augmentation']\n",
        "    scores = [f1_1, f1_2, f1_3]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars = ax.bar(methods, scores, color=['skyblue', 'lightcoral', 'lightgreen'],\n",
        "                  edgecolor='black', alpha=0.8)\n",
        "\n",
        "    for bar, score in zip(bars, scores):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "               f'{score:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Macro F1-Score', fontsize=12)\n",
        "    ax.set_title('ë¶ˆê· í˜• ì²˜ë¦¬ ë°©ë²•ë³„ ì„±ëŠ¥', fontsize=14, pad=15)\n",
        "    ax.set_ylim([0, max(scores) * 1.2])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nìµœì¢… ë¹„êµ:\")\n",
        "    for method, score in zip(methods, scores):\n",
        "        print(f\"  {method:20s}: {score:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ê°•ì˜ ì™„ë£Œ! ğŸ“\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "s7Otfq2qd1yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}