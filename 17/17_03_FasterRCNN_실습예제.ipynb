{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 다운로드 (Penn-Fudan)\n",
        "import os, urllib.request, tarfile, numpy as np, torch, torchvision, matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "root = '/content/pennfudan'                     # 데이터 루트\n",
        "os.makedirs(root, exist_ok=True)                # 폴더 생성\n",
        "url = 'https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip'  # 공식 링크\n",
        "zip_path = os.path.join(root, 'PennFudanPed.zip')\n",
        "\n",
        "if not os.path.exists(zip_path):                # zip이 없으면 다운로드\n",
        "    urllib.request.urlretrieve(url, zip_path)   # 파일 다운로드\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:      # 압축 해제\n",
        "    zf.extractall(root)\n"
      ],
      "metadata": {
        "id": "F0cQz64PjAVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class PennFudanDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PennFudanPed/PNGImages\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PennFudanPed/PedMasks\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지/마스크 로드\n",
        "        img_path = os.path.join(self.root, \"PennFudanPed/PNGImages\", self.imgs[idx])\n",
        "        mask_path= os.path.join(self.root, \"PennFudanPed/PedMasks\", self.masks[idx])\n",
        "        img  = Image.open(img_path).convert(\"RGB\")     # RGB 이미지\n",
        "        mask = Image.open(mask_path)                   # 인스턴스별 다른 id\n",
        "\n",
        "        mask = np.array(mask)                          # 마스크를 배열로\n",
        "        obj_ids = np.unique(mask)[1:]                  # 배경 0 제외\n",
        "        boxes = []\n",
        "        for oid in obj_ids:\n",
        "            pos = np.where(mask == oid)                # 객체 픽셀 위치\n",
        "            xmin, xmax = np.min(pos[1]), np.max(pos[1])\n",
        "            ymin, ymax = np.min(pos[0]), np.max(pos[0])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "        labels = torch.ones((len(obj_ids),), dtype=torch.int64)  # 사람=1\n",
        "        masks  = torch.as_tensor(mask == obj_ids[:, None, None], dtype=torch.uint8)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:,1]) * (boxes[:, 2] - boxes[:,0])\n",
        "        iscrowd = torch.zeros((len(obj_ids),), dtype=torch.int64)\n",
        "\n",
        "        target = {\"boxes\": boxes, \"labels\": labels, \"masks\": masks,\n",
        "                  \"image_id\": image_id, \"area\": area, \"iscrowd\": iscrowd}\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "7TXNi1jtjC59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델: Faster R-CNN (사전학습) 미세튜닝\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
        "model = fasterrcnn_resnet50_fpn(weights=weights)      # 사전학습 모델\n",
        "# 분류기 헤드의 num_classes를 2로(배경+사람)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 2)\n",
        "\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tfm = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = PennFudanDataset(root, transforms=tfm)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "train_dataset = torch.utils.data.Subset(dataset, indices[:-20])\n",
        "test_dataset  = torch.utils.data.Subset(dataset, indices[-20:])\n",
        "\n",
        "def collate_fn(batch): return tuple(zip(*batch))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "AdZN1xsjjGDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  학습 루프\n",
        "import torch.optim as optim\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.train()\n",
        "for ep in range(2):   # 데모용 2에폭\n",
        "    for images, targets in train_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets= [{k:v.to(device) for k,v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)           # detection losses dict\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad(); losses.backward(); optimizer.step()\n",
        "    print(f\"Epoch {ep+1} done. total_loss={losses.item():.3f}\")"
      ],
      "metadata": {
        "id": "pYQbjHgzjIHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXGTwjd8UXcY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "boxes = pred['boxes'].cpu().numpy()\n",
        "scores= pred['scores'].cpu().numpy()\n",
        "\n",
        "thr = 0.6\n",
        "keep = scores >= thr\n",
        "boxes, scores = boxes[keep], scores[keep]\n",
        "\n",
        "# 텐서->이미지 변환 시 .copy() 추가\n",
        "vis_tensor_cpu = img.mul(torch.tensor([255,255,255]).view(3,1,1)).permute(1,2,0).byte().cpu()\n",
        "vis = np.array(vis_tensor_cpu).copy()  # <--- .copy()를 추가하여 메모리 레이아웃을 C-contiguous로 변경\n",
        "\n",
        "for (x1,y1,x2,y2), s in zip(boxes, scores):\n",
        "    cv2.rectangle(vis, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,255), 2)\n",
        "    cv2.putText(vis, f\"{s:.2f}\", (int(x1),int(y1)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "plt.figure(figsize=(6,8)); plt.imshow(vis); plt.axis('off'); plt.title('Penn-Fudan(FT)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GB7zz06kjwiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}