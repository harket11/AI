{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Faster R-CNN Fine-tuning 실무 [개념 / 구조 확인]\n",
        "\n"
      ],
      "metadata": {
        "id": "DzMpvqsCP8WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.transforms import v2 as transforms\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'TorchVision: {torchvision.__version__}')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "id": "scDtw9iSP-k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트 초기화(참고)\n",
        "# a = [1,2,3,4]\n",
        "\n",
        "# a = []\n",
        "# a"
      ],
      "metadata": {
        "id": "uYXlGJw2MBo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset 클래스 정의\n",
        "class CustomObjectDetectionDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    커스텀 객체 검출 데이터셋\n",
        "    COCO 형식의 annotation 지원\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, annotation_file, transforms=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Annotation 로드\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "\n",
        "        # 이미지 ID 리스트\n",
        "        self.image_ids = [img['id'] for img in self.coco_data['images']]\n",
        "\n",
        "        # 카테고리 매핑\n",
        "        self.categories = {cat['id']: cat['name']\n",
        "                          for cat in self.coco_data['categories']}\n",
        "        self.num_classes = len(self.categories) + 1  # +1 for background\n",
        "\n",
        "        # 이미지별 annotation 그룹화\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.img_to_anns:\n",
        "                self.img_to_anns[img_id] = []\n",
        "            self.img_to_anns[img_id].append(ann)\n",
        "\n",
        "        print(f\"Dataset 로드 완료: {len(self.image_ids)}개 이미지, {self.num_classes-1}개 클래스\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 로드(항목 가져오기 함수)\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = next(img for img in self.coco_data['images'] if img['id'] == img_id)\n",
        "        img_path = self.root_dir / img_info['file_name']\n",
        "        # 전체경로 (폴더 경로 / 파일명)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Annotation 가져오기\n",
        "        anns = self.img_to_anns.get(img_id, [])\n",
        "        # get() 함수는 없으면 None >> 여기서는 빈 리스트 반환\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        areas = []\n",
        "        iscrowd = []\n",
        "\n",
        "        for ann in anns:\n",
        "            # COCO bbox format: [x, y, width, height]\n",
        "            x, y, w, h = ann['bbox']\n",
        "            # Convert to [x1, y1, x2, y2]\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann['category_id'])\n",
        "            areas.append(ann['area'])\n",
        "            iscrowd.append(ann.get('iscrowd', 0))\n",
        "            # 겹치는 게 있으면 누적, 없으면 0 설정\n",
        "\n",
        "        # Tensor로 변환\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        image_id = torch.tensor([img_id])\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': image_id,\n",
        "            'area': areas,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        # Transform 적용\n",
        "        if self.transforms:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target"
      ],
      "metadata": {
        "id": "54gIdwvCQBQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform 정의\n",
        "def get_transform(train=True):\n",
        "    \"\"\"\n",
        "    학습/검증용 Transform\n",
        "    \"\"\"\n",
        "    transforms_list = []\n",
        "\n",
        "    # PIL Image를 Tensor로 변환\n",
        "    transforms_list.append(T.ToTensor())\n",
        "\n",
        "    if train:\n",
        "        # 학습 시 Data Augmentation\n",
        "        transforms_list.append(T.RandomHorizontalFlip(0.5))\n",
        "\n",
        "    return T.Compose(transforms_list)"
      ],
      "metadata": {
        "id": "ZpYHBZAIQIHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 함수\n",
        "def get_model(num_classes, pretrained=True):\n",
        "    \"\"\"\n",
        "    Faster R-CNN 모델 생성 및 커스터마이징\n",
        "    \"\"\"\n",
        "    # 사전학습된 모델 로드\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT' if pretrained else None)\n",
        "\n",
        "    # Classifier head 교체 (커스텀 클래스 수에 맞게)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "T2K2oiNUQO7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mAP 계산 함수 ================================\n",
        "def calculate_iou_batch(boxes1, boxes2):\n",
        "    \"\"\"\n",
        "    두 박스 세트 간의 IoU 계산 (벡터화)\n",
        "    area = (x2 - x1) * (y2 - y1) 가로 * 세로\n",
        "    [x1, y1, x2, y2]\n",
        "    \"\"\"\n",
        "    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n",
        "    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n",
        "\n",
        "    # 교집합 영역의 최상단 lt, 우하단 rb\n",
        "    # max : 교집합 상황에서 x1, x2 중 더 큰 x, y 좌표 선택\n",
        "    # min : 교집합 상황에서 x1, x2 중 더 작은 x, y 좌표 선택\n",
        "    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])\n",
        "    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n",
        "\n",
        "    wh = (rb - lt).clamp(min=0)\n",
        "    # rb : max값, lt: min 값\n",
        "    # (rb - lt) 교집합(intersection) 영역 내에 있는 (width, height) 계산\n",
        "    # clamp(min=0) : 교집합 없을 때, 음수가 나올 수 있어 이를 방지하기 위해 0으로 처리\n",
        "    inter = wh[:, :, 0] * wh[:, :, 1]\n",
        "\n",
        "    union = area1[:, None] + area2 - inter\n",
        "    iou = inter / union\n",
        "\n",
        "    return iou\n",
        "\n",
        "# area1[:, None] # (N, 1) 원래 Shape(N 개)\n",
        "# area2[None, :] # (1, M)\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "    \"\"\"\n",
        "    Average Precision 계산 (모델 성능 지표)\n",
        "    \"\"\"\n",
        "    # 11-point interpolation\n",
        "    ap = 0.\n",
        "    for t in np.arange(0., 1.1, 0.1):\n",
        "        if np.sum(recall >= t) == 0:\n",
        "            p = 0\n",
        "        else:\n",
        "            p = np.max(precision[recall >= t])\n",
        "            # 각 recall 지점(0.1 간격)에서 최대 precision 찾기\n",
        "        ap += p / 11.\n",
        "        # 11 개 지점의 평균\n",
        "    return ap\n",
        "\n",
        "def evaluate_map(model, data_loader, device, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    mAP(mean Average Precision: 모든 클래스의 AP 평균) 계산\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_detections = []\n",
        "    all_ground_truths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            images = [img.to(device) for img in images]\n",
        "            outputs = model(images)\n",
        "\n",
        "            for target, output in zip(targets, outputs):\n",
        "                all_ground_truths.append({\n",
        "                    'boxes': target['boxes'].cpu(),\n",
        "                    'labels': target['labels'].cpu()\n",
        "                })\n",
        "                all_detections.append({\n",
        "                    'boxes': output['boxes'].cpu(),\n",
        "                    'scores': output['scores'].cpu(),\n",
        "                    'labels': output['labels'].cpu()\n",
        "                })\n",
        "\n",
        "    # 클래스별 AP 계산\n",
        "    num_classes = max([max(gt['labels']) for gt in all_ground_truths]) + 1\n",
        "    aps = []\n",
        "\n",
        "    for cls in range(1, num_classes):\n",
        "        # Skip background(0번 배경) 건너 뛰기\n",
        "        # 해당 클래스만 필터링\n",
        "        cls_detections = []\n",
        "        cls_ground_truths = []\n",
        "\n",
        "        for det, gt in zip(all_detections, all_ground_truths):\n",
        "            det_mask = det['labels'] == cls\n",
        "            gt_mask = gt['labels'] == cls\n",
        "\n",
        "            # 해당 클래스 검출 결과 추가\n",
        "            if det_mask.sum() > 0:\n",
        "                cls_detections.append({\n",
        "                    'boxes': det['boxes'][det_mask],\n",
        "                    'scores': det['scores'][det_mask]\n",
        "                })\n",
        "            else:\n",
        "                cls_detections.append({'boxes': torch.empty(0, 4), 'scores': torch.empty(0)})\n",
        "                # 없다면, 빈 텐서 추가\n",
        "\n",
        "            cls_ground_truths.append(gt['boxes'][gt_mask])\n",
        "\n",
        "        # Score로 정렬\n",
        "        all_scores = []\n",
        "        all_tp = []\n",
        "        num_gt = sum([len(gt) for gt in cls_ground_truths])\n",
        "        # 정답 객체 총 개수\n",
        "\n",
        "        for det, gt in zip(cls_detections, cls_ground_truths):\n",
        "            if len(det['scores']) == 0:\n",
        "                continue\n",
        "\n",
        "            for score, box in zip(det['scores'], det['boxes']):\n",
        "                all_scores.append(score.item())\n",
        "\n",
        "                if len(gt) == 0:\n",
        "                    all_tp.append(0)\n",
        "                else:\n",
        "                    ious = calculate_iou_batch(box.unsqueeze(0), gt)\n",
        "                    max_iou = ious.max().item()\n",
        "                    all_tp.append(1 if max_iou >= iou_threshold else 0)\n",
        "                    # True Positive 판단\n",
        "                    # >> 정답인 박스와 IoU 비교, iou_threshold(0.5) 이상이면 1, 아니면 0\n",
        "\n",
        "        if len(all_scores) == 0 or num_gt == 0:\n",
        "            continue\n",
        "\n",
        "        # Precision-Recall 계산\n",
        "        indices = np.argsort(all_scores)[::-1] # 내림차순\n",
        "        tp = np.array(all_tp)[indices]\n",
        "        fp = 1 - tp  # false positive : 잘못 검츨한 것\n",
        "\n",
        "        tp_cumsum = np.cumsum(tp)\n",
        "        fp_cumsum = np.cumsum(fp)\n",
        "\n",
        "        recalls = tp_cumsum / num_gt\n",
        "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
        "\n",
        "        ap = compute_ap(recalls, precisions)\n",
        "        aps.append(ap)\n",
        "\n",
        "    mAP = np.mean(aps) if len(aps) > 0 else 0.0\n",
        "    return mAP, aps"
      ],
      "metadata": {
        "id": "-LG3p3sXQRNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    \"\"\"\n",
        "    1 에폭 학습\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch}\")\n",
        "    for images, targets in pbar:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "        pbar.set_postfix({'loss': f'{losses.item():.4f}'})\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "Sh_Id2DTQY1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 준비 (예시 - 실제 데이터로 교체 필요)\n",
        "\"\"\"\n",
        "실제 사용 시 아래와 같이 데이터셋을 준비하세요:\n",
        "\n",
        "# COCO 형식의 annotation 파일 예시 구조:\n",
        "{\n",
        "    \"images\": [\n",
        "        {\"id\": 1, \"file_name\": \"image1.jpg\", \"width\": 640, \"height\": 480}\n",
        "    ],\n",
        "    \"annotations\": [\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"image_id\": 1,\n",
        "            \"category_id\": 1,\n",
        "            \"bbox\": [x, y, width, height],\n",
        "            \"area\": width * height,\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "    ],\n",
        "    \"categories\": [\n",
        "        {\"id\": 1, \"name\": \"cat\"},\n",
        "        {\"id\": 2, \"name\": \"dog\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_dataset = CustomObjectDetectionDataset(\n",
        "    root_dir='path/to/images',\n",
        "    annotation_file='path/to/annotations.json',\n",
        "    transforms=get_transform(train=True)\n",
        ")\n",
        "\n",
        "val_dataset = CustomObjectDetectionDataset(\n",
        "    root_dir='path/to/images',\n",
        "    annotation_file='path/to/val_annotations.json',\n",
        "    transforms=get_transform(train=False)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# 더미 데이터로 시연 (실제 사용 시 삭제)\n",
        "print(\"\\실제 학습을 위해서는 CustomObjectDetectionDataset에 실제 데이터를 로드하세요.\")\n",
        "print(\"예제 코드는 구조 참고용입니다.\\n\")"
      ],
      "metadata": {
        "id": "PMYd79GRQk7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 파이프라인\n",
        "def train_model(num_classes, train_dataset, val_dataset,\n",
        "                num_epochs=10, batch_size=4, lr=0.005):\n",
        "    \"\"\"\n",
        "    전체 학습 파이프라인\n",
        "    \"\"\"\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        collate_fn=lambda x: tuple(zip(*x))\n",
        "        #collate_fn : batch 묶는 방법 지정\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        collate_fn=lambda x: tuple(zip(*x))\n",
        "    )\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = get_model(num_classes, pretrained=True)\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    # 3 epoch 마다 학습률 0.1배로 줄임\n",
        "\n",
        "    # 학습 기록\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_mAP': [],\n",
        "        'learning_rate': []\n",
        "    }\n",
        "\n",
        "    best_mAP = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # 학습\n",
        "        train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "\n",
        "        # 검증\n",
        "        val_mAP, _ = evaluate_map(model, val_loader, device)\n",
        "\n",
        "        # Scheduler step\n",
        "        lr_scheduler.step()\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # 기록\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_mAP'].append(val_mAP)\n",
        "        history['learning_rate'].append(current_lr)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val mAP: {val_mAP:.4f}\")\n",
        "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "        # Best model 저장\n",
        "        if val_mAP > best_mAP:\n",
        "            best_mAP = val_mAP\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'mAP': val_mAP,\n",
        "            }, 'best_model.pth')\n",
        "            print(f\"Best model saved! (mAP: {val_mAP:.4f})\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "RR6GW5WjQrmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 시각화 ================================\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    학습 히스토리 시각화\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(history['train_loss'], marker='o', label='Train Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # mAP\n",
        "    axes[1].plot(history['val_mAP'], marker='o', color='green', label='Val mAP')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('mAP')\n",
        "    axes[1].set_title('Validation mAP')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    # Learning Rate\n",
        "    axes[2].plot(history['learning_rate'], marker='o', color='orange', label='LR')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Learning Rate')\n",
        "    axes[2].set_title('Learning Rate Schedule')\n",
        "    axes[2].set_yscale('log')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8XSc34plQu1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론 및 시각화 함수 ================================\n",
        "def predict_and_visualize(model, image_path, device, conf_threshold=0.5,\n",
        "                         class_names=None):\n",
        "    \"\"\"\n",
        "    단일 이미지에 대한 추론 및 시각화\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 이미지 로드\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = T.ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # 추론\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        predictions = model(img_tensor)[0]\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "    # 필터링\n",
        "    boxes = predictions['boxes'].cpu().numpy()\n",
        "    scores = predictions['scores'].cpu().numpy()\n",
        "    labels = predictions['labels'].cpu().numpy()\n",
        "\n",
        "    mask = scores >= conf_threshold\n",
        "    boxes = boxes[mask]\n",
        "    scores = scores[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    # 시각화\n",
        "    img_np = np.array(img)\n",
        "    img_draw = img_np.copy()\n",
        "\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
        "\n",
        "    for box, score, label in zip(boxes, scores, labels):\n",
        "        x1, y1, x2, y2 = box.astype(int)\n",
        "        color = tuple((np.array(colors[label % 20][:3]) * 255).astype(int).tolist())\n",
        "\n",
        "        # 박스\n",
        "        cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        # 레이블\n",
        "        class_name = class_names[label] if class_names else f\"Class {label}\"\n",
        "        text = f'{class_name}: {score:.2f}'\n",
        "        cv2.putText(img_draw, text, (x1, y1 - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_draw)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'검출 결과 ({len(boxes)}개 객체, 추론 시간: {inference_time*1000:.1f}ms)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return boxes, scores, labels"
      ],
      "metadata": {
        "id": "AlZkHfM3QxTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB6X7ogDOnf1"
      },
      "outputs": [],
      "source": [
        "# 실무 팁 및 사용 예시\n",
        "print(\"\"\"\n",
        "=== Faster R-CNN Fine-tuning 실무 가이드 ===\n",
        "\n",
        "1. 데이터 준비\n",
        "   - COCO 형식의 annotation 권장\n",
        "   - 클래스당 최소 100개 이상의 샘플\n",
        "   - Train/Val split: 80/20\n",
        "\n",
        "2. Hyperparameter 튜닝\n",
        "   - Learning rate: 0.005 (초기값)\n",
        "   - Batch size: GPU 메모리에 따라 조정\n",
        "   - Epochs: 10-50 (early stopping 권장)\n",
        "   - IoU threshold: 0.5 (기본값)\n",
        "\n",
        "3. 성능 개선 전략\n",
        "   - Data Augmentation (flip, crop, color jitter)\n",
        "   - Anchor box 크기/비율 조정\n",
        "   - Backbone 변경 (ResNet50 → ResNet101)\n",
        "   - Learning rate scheduling\n",
        "   - Mixed precision training (FP16)\n",
        "\n",
        "4. 평가 및 디버깅\n",
        "   - mAP로 전체 성능 평가\n",
        "   - 클래스별 AP로 세부 분석\n",
        "   - False Positive/Negative 분석\n",
        "   - Confusion matrix 활용\n",
        "\n",
        "5. 배포 최적화\n",
        "   - TorchScript 변환\n",
        "   - ONNX 내보내기\n",
        "   - Quantization 적용\n",
        "   - TensorRT 가속\n",
        "\n",
        "사용 예시:\n",
        "\n",
        "# 1. 데이터셋 준비\n",
        "train_dataset = CustomObjectDetectionDataset(\n",
        "    root_dir='data/images',\n",
        "    annotation_file='data/train.json',\n",
        "    transforms=get_transform(train=True)\n",
        ")\n",
        "\n",
        "# 2. 학습\n",
        "model, history = train_model(\n",
        "    num_classes=3,  # background + 2 classes\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    num_epochs=20,\n",
        "    batch_size=4\n",
        ")\n",
        "\n",
        "# 3. 결과 시각화\n",
        "plot_training_history(history)\n",
        "\n",
        "# 4. 추론\n",
        "boxes, scores, labels = predict_and_visualize(\n",
        "    model, 'test.jpg', device,\n",
        "    class_names=['bg', 'cat', 'dog']\n",
        ")\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"학습 포인트:\")\n",
        "print(\"1. Custom Dataset 구축 및 COCO 형식 이해\")\n",
        "print(\"2. Faster R-CNN Fine-tuning 전체 파이프라인\")\n",
        "print(\"3. mAP 계산 및 모델 평가\")\n",
        "print(\"4. 실무 적용을 위한 최적화 전략\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eos"
      ],
      "metadata": {
        "id": "ESLuWJdxQ69b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zP7lKQ8VSQq4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}