{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15696654",
      "metadata": {
        "id": "15696654"
      },
      "source": [
        "# 세션 20 — Transformer (DistilBERT) 감정분석 — GLUE/SST-2 — 2025 버전"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d67896",
      "metadata": {
        "id": "b5d67896"
      },
      "outputs": [],
      "source": [
        "# torchvision과 torchaudio를 추가하여 torch 버전과 호환되도록 함께 업데이트합니다.\n",
        "!pip -q install -U \"torch>=2.2,<3.0\" \"torchvision\" \"torchaudio\" \"datasets>=3.0.1\" \"transformers>=4.45.2\" \"accelerate>=1.0.1\" \"evaluate>=0.4.2\"\n",
        "\n",
        "import torch, transformers, datasets, evaluate\n",
        "import numpy as np\n",
        "\n",
        "print(\"PyTorch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
        "print(\"Transformers:\", transformers.__version__, \"| Datasets:\", datasets.__version__)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f808341",
      "metadata": {
        "id": "1f808341"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"glue\", \"sst2\")\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aed7c5d",
      "metadata": {
        "id": "1aed7c5d"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "\n",
        "MODEL=\"distilbert-base-uncased\"\n",
        "tokenizer=AutoTokenizer.from_pretrained(MODEL,use_fast=True)\n",
        "def preprocess(ex): return tokenizer(ex[\"sentence\"], truncation=True, max_length=256)\n",
        "enc=ds.map(preprocess, batched=True, remove_columns=[\"sentence\",\"idx\"])\n",
        "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "model=AutoModelForSequenceClassification.from_pretrained(MODEL,num_labels=2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9d2362",
      "metadata": {
        "id": "ed9d2362"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "# 지표 로드\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def metrics(p):\n",
        "    predictions, labels = p\n",
        "    # predictions가 튜플로 나오는 경우(logits 외 다른 요소가 있는 경우)를 대비해 분기 처리하거나\n",
        "    # 일반적인 경우 predictions 자체가 logits입니다.\n",
        "    # 여기서는 numpy 배열이라고 가정하고 처리합니다.\n",
        "    preds = predictions.argmax(-1)\n",
        "\n",
        "    return {\n",
        "        \"acc\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "# TrainingArguments 설정\n",
        "# >> 학습 스케쥴(프로젝트 한다면 WBS(Work Breakdown Sheet))\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/sst2_2025\",\n",
        "    eval_strategy=\"epoch\",          # 수정됨: evaluation_strategy -> eval_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    # 학습이 끝난 가장 좋은 모델 자동 로드\n",
        "    fp16=torch.cuda.is_available(), # GPU가 있을 때만 fp16 사용\n",
        "    report_to=\"none\",\n",
        "    seed=2025\n",
        ")\n",
        "# fp16 : float precision(부동소수점 정밀도):\n",
        "# >> GPU가 있을 때만 fp16 사용 (16bit) 메모리 절약 >> 속도 향상\n",
        "\n",
        "# Trainer 초기화\n",
        "# 학습 스케쥴대로 자동화\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=enc[\"train\"],\n",
        "    eval_dataset=enc[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=metrics\n",
        ")\n",
        "# data_collator : 정렬 도구 (문장 길이 맞추기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f6e670",
      "metadata": {
        "id": "84f6e670"
      },
      "outputs": [],
      "source": [
        "txt=[\"This movie was amazing!\",\"Worst film ever.\"]\n",
        "inp=tokenizer(txt,return_tensors=\"pt\",padding=True,truncation=True,max_length=256).to(model.device)\n",
        "\n",
        "with torch.no_grad(): out=torch.softmax(model(**inp).logits,dim=-1).cpu().numpy()\n",
        "# **inp : input(입력된 인자 argument) 언패킹해서 전달\n",
        "# >>(dictionary 형태로 되어 있는 것을 키워드 인수로 풀어서 전달)\n",
        "# inp = {\"id\": [].....} >> model(input_id = .....)\n",
        "\n",
        "for t,p in zip(txt,out): print(f\"{t}\\n→ Negative={p[0]:.3f}, Positive={p[1]:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}